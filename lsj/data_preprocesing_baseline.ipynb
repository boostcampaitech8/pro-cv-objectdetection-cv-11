{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d41413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR exists: True\n",
      "TRAIN_JSON exists: True\n",
      "TEST_JSON exists: True\n",
      "images: 4883 annotations: 23144 categories: 10\n",
      "cat_id_to_idx: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
      "idx_to_name: {0: 'General trash', 1: 'Paper', 2: 'Paper pack', 3: 'Metal', 4: 'Glass', 5: 'Plastic', 6: 'Styrofoam', 7: 'Plastic bag', 8: 'Battery', 9: 'Clothing'}\n",
      "num_classes: 10\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# === ê²½ë¡œ ì„¤ì • ===\n",
    "BASE_DIR = Path(\"/data/ephemeral/home/pro-cv-objectdetection-cv-11-sj/dataset\").resolve()\n",
    "TRAIN_JSON = BASE_DIR / \"train.json\"\n",
    "TEST_JSON = BASE_DIR / \"test.json\"\n",
    "\n",
    "print(\"BASE_DIR exists:\", BASE_DIR.exists())\n",
    "print(\"TRAIN_JSON exists:\", TRAIN_JSON.exists())\n",
    "print(\"TEST_JSON exists:\", TEST_JSON.exists())\n",
    "\n",
    "# === train.json ë¡œë“œ ===\n",
    "with open(TRAIN_JSON, \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "print(\n",
    "    \"images:\", len(train_data[\"images\"]),\n",
    "    \"annotations:\", len(train_data[\"annotations\"]),\n",
    "    \"categories:\", len(train_data[\"categories\"])\n",
    ")\n",
    "\n",
    "# === category id -> index, index -> name ë§¤í•‘ ë§Œë“¤ê¸° ===\n",
    "categories = train_data[\"categories\"]\n",
    "cat_id_to_idx = {c[\"id\"]: i for i, c in enumerate(categories)}  # ì˜ˆ: {1:0, 2:1, ...}\n",
    "idx_to_name = {i: c[\"name\"] for i, c in enumerate(categories)}  # ì˜ˆ: {0:\"General trash\", ...}\n",
    "num_classes = len(categories)\n",
    "\n",
    "print(\"cat_id_to_idx:\", cat_id_to_idx)\n",
    "print(\"idx_to_name:\", idx_to_name)\n",
    "print(\"num_classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6e712f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: train_idx=18633, val_idx=4511\n",
      "\n",
      "Using fold 0\n",
      "train image ids: 3914\n",
      "val image ids: 969\n"
     ]
    }
   ],
   "source": [
    "# === StratifiedGroupKFold ì¤€ë¹„ ===\n",
    "annots = train_data[\"annotations\"]\n",
    "\n",
    "# (image_id, category_id) ìŒ\n",
    "var = [(ann[\"image_id\"], ann[\"category_id\"]) for ann in annots]\n",
    "X = np.ones((len(var), 1))  # ì˜ë¯¸ ì—†ëŠ” placeholder\n",
    "y = np.array([v[1] for v in var])       # category_id\n",
    "groups = np.array([v[0] for v in var])  # image_id\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=411)\n",
    "\n",
    "# í•œ ê°œ foldë§Œ ê³¨ë¼ì„œ ì‚¬ìš© (ì˜ˆ: fold 0)\n",
    "fold_to_use = 0\n",
    "train_ids = None\n",
    "val_ids = None\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X, y, groups)):\n",
    "    print(f\"Fold {fold_idx}: train_idx={len(train_idx)}, val_idx={len(val_idx)}\")\n",
    "    if fold_idx == fold_to_use:\n",
    "        train_ids = np.unique(groups[train_idx])\n",
    "        val_ids = np.unique(groups[val_idx])\n",
    "        break\n",
    "\n",
    "print(f\"\\nUsing fold {fold_to_use}\")\n",
    "print(\"train image ids:\", len(train_ids))\n",
    "print(\"val image ids:\", len(val_ids))\n",
    "\n",
    "train_id_set = set(train_ids.tolist())\n",
    "val_id_set = set(val_ids.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "398bb288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO_ROOT: /data/ephemeral/home/pro-cv-objectdetection-cv-11-sj/dataset/yolo_dataset\n"
     ]
    }
   ],
   "source": [
    "YOLO_ROOT = BASE_DIR / \"yolo_dataset\"   # ìƒˆë¡œ ë§Œë“¤ YOLOìš© ë£¨íŠ¸\n",
    "IMG_DIR = YOLO_ROOT / \"images\"\n",
    "LBL_DIR = YOLO_ROOT / \"labels\"\n",
    "\n",
    "# í•„ìš”í•œ ë””ë ‰í† ë¦¬ë“¤ ë¯¸ë¦¬ ìƒì„±\n",
    "for p in [\n",
    "    IMG_DIR / \"train\",\n",
    "    IMG_DIR / \"val\",\n",
    "    IMG_DIR / \"test\",\n",
    "    LBL_DIR / \"train\",\n",
    "    LBL_DIR / \"val\"\n",
    "]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"YOLO_ROOT:\", YOLO_ROOT)\n",
    "\n",
    "# image_id -> image_info\n",
    "images_by_id = {img[\"id\"]: img for img in train_data[\"images\"]}\n",
    "\n",
    "# image_idë³„ annotation ëª¨ìœ¼ê¸°\n",
    "annotations_by_image = defaultdict(list)\n",
    "for ann in annots:\n",
    "    annotations_by_image[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "# ì›ë³¸ íŒŒì¼ì„ symlinkë¡œ ì—°ê²° (ì•ˆ ë˜ë©´ copy)\n",
    "def link_or_copy(src: Path, dst: Path):\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if dst.exists():\n",
    "        return\n",
    "    try:\n",
    "        os.symlink(src, dst)\n",
    "    except (AttributeError, OSError, NotImplementedError):\n",
    "        shutil.copy2(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b29ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_split(split_name: str, image_ids):\n",
    "    \"\"\"\n",
    "    split_name: \"train\" or \"val\"\n",
    "    image_ids : í•´ë‹¹ splitì— í¬í•¨ë  image_id ë¦¬ìŠ¤íŠ¸/ë°°ì—´\n",
    "    \"\"\"\n",
    "    img_split_dir = IMG_DIR / split_name\n",
    "    lbl_split_dir = LBL_DIR / split_name\n",
    "    img_split_dir.mkdir(parents=True, exist_ok=True)\n",
    "    lbl_split_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    n_images = 0\n",
    "    n_labels = 0\n",
    "\n",
    "    for image_id in image_ids:\n",
    "        info = images_by_id[image_id]\n",
    "\n",
    "        # COCO í‘œì¤€ì€ \"file_name\" ì´ê³ , ë¬¸ì œ ì„¤ëª…ì€ \"filename\" ì´ë¼ì„œ ë‘˜ ë‹¤ ëŒ€ì‘\n",
    "        file_name = info.get(\"file_name\", info.get(\"filename\"))\n",
    "        if file_name is None:\n",
    "            raise KeyError(\"image entry missing 'file_name'/'filename'\")\n",
    "\n",
    "        # ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ (ì˜ˆ: train/002.jpg)\n",
    "        src_img = BASE_DIR / file_name\n",
    "        if not src_img.exists():\n",
    "            # í˜¹ì‹œ file_nameì´ \"002.jpg\" í˜•íƒœë¼ë©´\n",
    "            src_img = (BASE_DIR / \"train\" / Path(file_name).name)\n",
    "        if not src_img.exists():\n",
    "            print(f\"[{split_name}] WARNING: image not found for id {image_id}: {file_name}\")\n",
    "            continue\n",
    "\n",
    "        base_name = Path(file_name).name  # '002.jpg'\n",
    "        dst_img = img_split_dir / base_name\n",
    "        link_or_copy(src_img, dst_img)\n",
    "        n_images += 1\n",
    "\n",
    "        # ì´ë¯¸ì§€ í¬ê¸°\n",
    "        width = info.get(\"width\", 1024)\n",
    "        height = info.get(\"height\", 1024)\n",
    "\n",
    "        # ì´ ì´ë¯¸ì§€ì— ëŒ€í•œ annotationë“¤\n",
    "        anns = annotations_by_image.get(image_id, [])\n",
    "        if not anns:\n",
    "            # ê°ì²´ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ë¼ë²¨ íŒŒì¼ ì—†ì–´ë„ ë¨\n",
    "            continue\n",
    "\n",
    "        lines = []\n",
    "        for ann in anns:\n",
    "            cat_original = ann[\"category_id\"]\n",
    "            cls_idx = cat_id_to_idx[cat_original]   # 0~9 ë¡œ ë§¤í•‘\n",
    "\n",
    "            # COCO bbox: [x_min, y_min, w, h] (pixel ë‹¨ìœ„)\n",
    "            x_min, y_min, w, h = ann[\"bbox\"]\n",
    "            x_c = x_min + w / 2.0\n",
    "            y_c = y_min + h / 2.0\n",
    "\n",
    "            # ì •ê·œí™” (0~1)\n",
    "            x_c /= width\n",
    "            y_c /= height\n",
    "            w /= width\n",
    "            h /= height\n",
    "\n",
    "            # í˜¹ì‹œ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ê²½ìš° ì•ˆì „í•˜ê²Œ í´ë¦½\n",
    "            x_c = min(max(x_c, 0.0), 1.0)\n",
    "            y_c = min(max(y_c, 0.0), 1.0)\n",
    "            w = min(max(w, 0.0), 1.0)\n",
    "            h = min(max(h, 0.0), 1.0)\n",
    "\n",
    "            lines.append(f\"{cls_idx} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\")\n",
    "\n",
    "        label_path = lbl_split_dir / (Path(base_name).stem + \".txt\")\n",
    "        with open(label_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(lines))\n",
    "        n_labels += 1\n",
    "\n",
    "    print(f\"[{split_name}] wrote {n_images} images and {n_labels} label files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26fdeae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] wrote 3914 images and 3914 label files\n",
      "[val] wrote 969 images and 969 label files\n"
     ]
    }
   ],
   "source": [
    "convert_split(\"train\", train_ids)\n",
    "convert_split(\"val\", val_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cddd1c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied test images: 4871\n"
     ]
    }
   ],
   "source": [
    "# === test.json ë¡œë“œ í›„ images/test ë¡œ ë³µì‚¬ (ë¼ë²¨ì€ ì—†ìŒ) ===\n",
    "with open(TEST_JSON, \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "images_test = test_data[\"images\"]\n",
    "img_test_dir = IMG_DIR / \"test\"\n",
    "img_test_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "test_filename_to_id = {}\n",
    "\n",
    "for img in images_test:\n",
    "    file_name = img.get(\"file_name\", img.get(\"filename\"))\n",
    "    if file_name is None:\n",
    "        continue\n",
    "\n",
    "    src_img = BASE_DIR / file_name  # ë³´í†µ 'test/3105.jpg'\n",
    "    if not src_img.exists():\n",
    "        src_img = (BASE_DIR / \"test\" / Path(file_name).name)\n",
    "    if not src_img.exists():\n",
    "        print(f\"[test] WARNING: image not found: {file_name}\")\n",
    "        continue\n",
    "\n",
    "    dst_img = img_test_dir / Path(file_name).name  # '3105.jpg'\n",
    "    link_or_copy(src_img, dst_img)\n",
    "\n",
    "    # ë‚˜ì¤‘ì— submission ë§Œë“¤ ë•Œ image_idë¥¼ ì°¾ê¸° ìœ„í•œ ë§¤í•‘ (ì˜ˆ: 'test/3105.jpg' -> id)\n",
    "    test_filename_to_id[file_name] = img[\"id\"]\n",
    "\n",
    "print(\"Copied test images:\", len(list(img_test_dir.glob(\"*.*\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b35ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== trash10.yaml ===\n",
      "path: /data/ephemeral/home/pro-cv-objectdetection-cv-11-sj/dataset/yolo_dataset\n",
      "train: images/train\n",
      "val: images/val\n",
      "test: images/test\n",
      "names:\n",
      "  0: General trash\n",
      "  1: Paper\n",
      "  2: Paper pack\n",
      "  3: Metal\n",
      "  4: Glass\n",
      "  5: Plastic\n",
      "  6: Styrofoam\n",
      "  7: Plastic bag\n",
      "  8: Battery\n",
      "  9: Clothing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_yaml_path = YOLO_ROOT / \"trash10.yaml\"\n",
    "\n",
    "names = [\n",
    "    \"General trash\",\n",
    "    \"Paper\",\n",
    "    \"Paper pack\",\n",
    "    \"Metal\",\n",
    "    \"Glass\",\n",
    "    \"Plastic\",\n",
    "    \"Styrofoam\",\n",
    "    \"Plastic bag\",\n",
    "    \"Battery\",\n",
    "    \"Clothing\",\n",
    "]\n",
    "\n",
    "with open(data_yaml_path, \"w\") as f:\n",
    "    f.write(f\"path: {YOLO_ROOT}\\n\")\n",
    "    f.write(\"train: images/train\\n\")\n",
    "    f.write(\"val: images/val\\n\")\n",
    "    f.write(\"test: images/test\\n\")  # testëŠ” ë¼ë²¨ ì—†ì´ inferenceìš©\n",
    "    f.write(\"names:\\n\")\n",
    "    for i, name in enumerate(names):\n",
    "        f.write(f\"  {i}: {name}\\n\")\n",
    "\n",
    "print(\"=== trash10.yaml ===\")\n",
    "print(data_yaml_path.read_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ed3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.235 ğŸš€ Python-3.10.13 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,584,102 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1822.7Â±866.3 MB/s, size: 169.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /data/ephemeral/home/pro-cv-objectdetection-cv-11-sj/dataset/yolo_dataset/labels/val.cache... 969 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 969/969 1.4Mit/s 0.0s0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 61/61 4.5it/s 13.6s0.1s\n",
      "                   all        969       4511      0.587      0.489      0.513      0.418\n",
      "         General trash        438        805      0.475      0.272      0.292      0.229\n",
      "                 Paper        335       1237      0.579      0.417      0.474      0.314\n",
      "            Paper pack        130        191      0.557      0.381      0.417      0.351\n",
      "                 Metal        109        167       0.52      0.312      0.354      0.324\n",
      "                 Glass         55        147      0.563      0.619      0.591      0.467\n",
      "               Plastic        285        593      0.537      0.379      0.418      0.321\n",
      "             Styrofoam         89        237      0.548      0.506      0.514      0.399\n",
      "           Plastic bag        377       1027      0.705      0.616      0.672      0.547\n",
      "               Battery          7         16      0.747      0.925      0.906      0.867\n",
      "              Clothing         42         91      0.636      0.461       0.49      0.355\n",
      "Speed: 4.1ms preprocess, 4.0ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1m/data/ephemeral/home/pro-cv-objectdetection-cv-11-sj/lsj/ultralytics/runs/detect/val\u001b[0m\n",
      "mAP50-95: 0.41761263395192794\n",
      "mAP50: 0.5128597515122814\n",
      "mAP75: 0.43858352641273396\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ì½”ë“œì…ë‹ˆë‹¤.\n",
    "# metrics = model.val()  # train ë•Œ ì‚¬ìš©í•œ data/imgsz ë“±ì„ ê¸°ì–µí•˜ê³  ìˆìŒ\n",
    "# print(\"mAP50-95:\", metrics.box.map)\n",
    "# print(\"mAP50:\", metrics.box.map50)\n",
    "# print(\"mAP75:\", metrics.box.map75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ea811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (sj)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
