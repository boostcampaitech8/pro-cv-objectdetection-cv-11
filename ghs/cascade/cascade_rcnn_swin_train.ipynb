{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkkhs4988\u001b[0m (\u001b[33mcv_11\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m api \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241m.\u001b[39mApi()\n\u001b[1;32m      2\u001b[0m me \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mviewer\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsername:\u001b[39m\u001b[38;5;124m\"\u001b[39m, me\u001b[38;5;241m.\u001b[39musername)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "me = api.viewer\n",
    "\n",
    "print(\"Username:\", me.username)\n",
    "print(\"Teams:\", me.teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 import\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmdet.registry import DATASETS\n",
    "from mmdet.utils import register_all_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom 설정\n",
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\",\n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "root = \"../../dataset/\"\n",
    "train_ann = \"train.json\"\n",
    "test_ann  = \"test.json\"\n",
    "\n",
    "# config file 들고오기\n",
    "cfg = Config.fromfile(\"configs/my_model/cascade_rcnn_swin_tiny.py\")\n",
    "register_all_modules(init_default_scope=True)\n",
    "cfg.default_scope = \"mmdet\"\n",
    "\n",
    "#### dataset config 수정 ####\n",
    "for ds_key in [\"train_dataloader\", \"test_dataloader\"]:\n",
    "    if ds_key not in cfg:\n",
    "        continue\n",
    "    ds = cfg[ds_key][\"dataset\"] if \"dataset\" in cfg[ds_key] else cfg[ds_key]\n",
    "    ds.metainfo = dict(classes=classes)\n",
    "    ds.data_root = root\n",
    "    ds.ann_file = train_ann if ds_key == \"train_dataloader\" else test_ann\n",
    "    ds.data_prefix = dict(img=\"\")\n",
    "\n",
    "cfg.train_dataloader.batch_size = 4\n",
    "cfg.train_dataloader.num_workers = max(2, cfg.train_dataloader.get(\"num_workers\", 2))\n",
    "\n",
    "cfg.test_dataloader.batch_size = 1\n",
    "cfg.test_dataloader.num_workers = max(2, cfg.test_dataloader.get(\"num_workers\", 2))\n",
    "\n",
    "#### 데이터 증강 ####\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(\n",
    "        type='PhotoMetricDistortion',\n",
    "        brightness_delta=20,\n",
    "        contrast_range=(0.8, 1.2),\n",
    "        saturation_range=(0.8, 1.2),\n",
    "        hue_delta=10\n",
    "    ),\n",
    "    dict(type='Resize', scale=(512, 512), keep_ratio=False),\n",
    "    dict(type='PackDetInputs')\n",
    "]\n",
    "\n",
    "## 테스트는 기본 ##\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', scale=(512, 512), keep_ratio=False),\n",
    "    dict(type='PackDetInputs')\n",
    "]\n",
    "cfg.train_dataloader.dataset.pipeline = train_pipeline\n",
    "cfg.test_dataloader.dataset.pipeline = test_pipeline\n",
    "\n",
    "\n",
    "#### validate 비활성화 ####\n",
    "for k in (\"val_dataloader\", \"val_evaluator\", \"val_cfg\", \"val_loop\"):\n",
    "    cfg.pop(k, None)\n",
    "cfg.train_cfg = cfg.get(\"train_cfg\", {})\n",
    "cfg.train_cfg[\"val_interval\"] = 0\n",
    "\n",
    "\n",
    "#### 학습 config 수정 ####\n",
    "cfg.device = \"cuda\"\n",
    "cfg.gpu_ids = [0]\n",
    "cfg.randomness = dict(seed=2025, deterministic=False)\n",
    "cfg.work_dir = \"./work_dirs/cascade_rcnn_swin_trash\"\n",
    "\n",
    "for i in range(3):\n",
    "    cfg.model.roi_head.bbox_head[i].num_classes = len(classes)\n",
    "\n",
    "\n",
    "#### Adam ####\n",
    "cfg.optim_wrapper = dict(\n",
    "    optimizer=dict(\n",
    "        type='AdamW',\n",
    "        lr=0.0001,               # Swin 권장 learning rate\n",
    "        weight_decay=0.05,     # Transformer는 WD 크게 줌\n",
    "        betas=(0.9, 0.999),\n",
    "    ),\n",
    "    paramwise_cfg=dict(\n",
    "        norm_decay_mult=0.0,     # LayerNorm WD 제거\n",
    "        bias_decay_mult=0.0\n",
    "    ),\n",
    "    clip_grad=dict(max_norm=35, norm_type=2)\n",
    ")\n",
    "\n",
    "cfg.param_scheduler = [\n",
    "    dict(\n",
    "        type='LinearLR', start_factor=0.001, by_epoch=False, begin=0, end=500),\n",
    "\n",
    "    # Cosine Annealing (부드럽게 LR 감소)\n",
    "    dict(\n",
    "        type='CosineAnnealingLR',\n",
    "        by_epoch=True,\n",
    "        begin=0,\n",
    "        end=cfg.train_cfg.max_epochs,\n",
    "        eta_min=1e-6   # 최종 learning rate\n",
    "    ),\n",
    "]\n",
    "\n",
    "cfg.train_cfg.max_epochs = 18\n",
    "cfg.default_hooks[\"checkpoint\"][\"max_keep_ckpts\"] = 3\n",
    "cfg.default_hooks[\"checkpoint\"][\"interval\"] = 1\n",
    "\n",
    "\n",
    "vis_backends = [\n",
    "    dict(type='LocalVisBackend'),\n",
    "        dict(\n",
    "        type='WandbVisBackend',\n",
    "        init_kwargs=dict(\n",
    "            project='cv_11_OD',     # 너가 보고 싶은 프로젝트\n",
    "            entity='cv_11',      # 팀 이름\n",
    "            name='cascade_rcnn_swin_test'\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "cfg.visualizer = dict(\n",
    "    type='DetLocalVisualizer',\n",
    "    vis_backends=vis_backends,\n",
    "    name='visualizer'\n",
    ")\n",
    "\n",
    "cfg.log_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      " [Info] CocoDataset Train dataset with number of images 4883, and instance counts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 [General trash]</td>\n",
       "      <td>3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 [Paper]</td>\n",
       "      <td>6352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 [Paper pack]</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 [Metal]</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 [Glass]</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5 [Plastic]</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6 [Styrofoam]</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7 [Plastic bag]</td>\n",
       "      <td>5178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8 [Battery]</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9 [Clothing]</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            category  count\n",
       "0  0 [General trash]   3965\n",
       "1          1 [Paper]   6352\n",
       "2     2 [Paper pack]    897\n",
       "3          3 [Metal]    936\n",
       "4          4 [Glass]    982\n",
       "5        5 [Plastic]   2943\n",
       "6      6 [Styrofoam]   1263\n",
       "7    7 [Plastic bag]   5178\n",
       "8        8 [Battery]    159\n",
       "9       9 [Clothing]    468"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset summarization 확인\n",
    "train_ds_cfg = cfg.train_dataloader.dataset\n",
    "train_ds = DATASETS.build(train_ds_cfg)\n",
    "\n",
    "def summarize_dataset(ds):\n",
    "    ds.full_init()\n",
    "    num_images = len(ds)\n",
    "    classes = list(ds.metainfo.get(\"classes\", []))\n",
    "\n",
    "    counts = Counter()\n",
    "    for i in range(num_images):\n",
    "        info = ds.get_data_info(i)\n",
    "        for inst in info.get(\"instances\", []):\n",
    "            lbl = inst.get(\"bbox_label\", None)\n",
    "            if lbl is not None:\n",
    "                counts[lbl] += 1\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"category\": [f\"{i} [{c}]\" for i, c in enumerate(classes)],\n",
    "        \"count\": [counts.get(i, 0) for i in range(len(classes))]\n",
    "    })\n",
    "\n",
    "    print(f\"\\n [Info] CocoDataset Train dataset with number of images {num_images}, and instance counts:\")\n",
    "    display(df)\n",
    "\n",
    "summarize_dataset(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/09 04:08:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 2025\n",
      "    GPU 0: Tesla V100-SXM2-32GB\n",
      "    CUDA_HOME: None\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 2.1.0+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.0+cu118\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 2025\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "12/09 04:08:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/coco/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=3, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "device = 'cuda'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "gpu_ids = [\n",
      "    0,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        convert_weights=True,\n",
      "        depths=[\n",
      "            2,\n",
      "            2,\n",
      "            6,\n",
      "            2,\n",
      "        ],\n",
      "        drop_path_rate=0.2,\n",
      "        embed_dims=96,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth',\n",
      "            type='Pretrained'),\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            3,\n",
      "            6,\n",
      "            12,\n",
      "            24,\n",
      "        ],\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_norm=True,\n",
      "        qkv_bias=True,\n",
      "        type='SwinTransformer',\n",
      "        window_size=7,\n",
      "        with_cp=False),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=1,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            96,\n",
      "            192,\n",
      "            384,\n",
      "            768,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=10,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.05,\n",
      "                        0.05,\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=10,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.033,\n",
      "                        0.033,\n",
      "                        0.067,\n",
      "                        0.067,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=10,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "        ],\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            0.5,\n",
      "            0.25,\n",
      "        ],\n",
      "        type='CascadeRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(\n",
      "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.05),\n",
      "        rpn=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=1000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    pos_iou_thr=0.5,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    pos_iou_thr=0.6,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    pos_iou_thr=0.7,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "        ],\n",
      "        rpn=dict(\n",
      "            allowed_border=0,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='CascadeRCNN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=35, norm_type=2),\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=0.0001, type='AdamW', weight_decay=0.05),\n",
      "    paramwise_cfg=dict(bias_decay_mult=0.0, norm_decay_mult=0.0))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=12,\n",
      "        eta_min=1e-06,\n",
      "        type='CosineAnnealingLR'),\n",
      "]\n",
      "pretrained = 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'\n",
      "randomness = dict(deterministic=False, seed=2025)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='test.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='../../dataset/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=18, type='EpochBasedTrainLoop', val_interval=0)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file='train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='../../dataset/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                brightness_delta=20,\n",
      "                contrast_range=(\n",
      "                    0.8,\n",
      "                    1.2,\n",
      "                ),\n",
      "                hue_delta=10,\n",
      "                saturation_range=(\n",
      "                    0.8,\n",
      "                    1.2,\n",
      "                ),\n",
      "                type='PhotoMetricDistortion'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(\n",
      "            init_kwargs=dict(\n",
      "                entity='cv_11',\n",
      "                name='cascade_rcnn_swin_test',\n",
      "                project='cv_11_OD'),\n",
      "            type='WandbVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/cascade_rcnn_swin_trash'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/kkhs/mmdetection/work_dirs/cascade_rcnn_swin_trash/20251209_040843/vis_data/wandb/run-20251209_040856-gwdr7pww</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cv_11/cv_11_OD/runs/gwdr7pww' target=\"_blank\">cascade_rcnn_swin_test</a></strong> to <a href='https://wandb.ai/cv_11/cv_11_OD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cv_11/cv_11_OD' target=\"_blank\">https://wandb.ai/cv_11/cv_11_OD</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cv_11/cv_11_OD/runs/gwdr7pww' target=\"_blank\">https://wandb.ai/cv_11/cv_11_OD/runs/gwdr7pww</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/09 04:09:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "12/09 04:09:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.34s)\n",
      "creating index...\n",
      "index created!\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.0\n",
      "12/09 04:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm0.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm0.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm1.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm2.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm2.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm3.weight:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm3.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.lateral_convs.0.conv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.lateral_convs.1.conv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.lateral_convs.2.conv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.lateral_convs.3.conv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.fpn_convs.0.conv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.fpn_convs.1.conv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.fpn_convs.2.conv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.fpn_convs.3.conv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- rpn_head.rpn_conv.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- rpn_head.rpn_cls.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- rpn_head.rpn_reg.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- roi_head.bbox_head.0.fc_cls.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- roi_head.bbox_head.0.fc_reg.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- roi_head.bbox_head.0.shared_fcs.0.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- roi_head.bbox_head.0.shared_fcs.1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- roi_head.bbox_head.1.fc_cls.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- roi_head.bbox_head.1.fc_reg.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- roi_head.bbox_head.1.shared_fcs.0.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- roi_head.bbox_head.1.shared_fcs.1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- roi_head.bbox_head.2.fc_cls.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- roi_head.bbox_head.2.fc_reg.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- roi_head.bbox_head.2.shared_fcs.0.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- roi_head.bbox_head.2.shared_fcs.1.bias:weight_decay=0.0\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by http backend from path: https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth\n",
      "12/09 04:09:07 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "12/09 04:09:07 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "12/09 04:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /data/ephemeral/home/kkhs/mmdetection/work_dirs/cascade_rcnn_swin_trash.\n",
      "12/09 04:09:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  50/1221]  base_lr: 9.9098e-06 lr: 9.9098e-06  eta: 2:17:16  time: 0.3756  data_time: 0.0160  memory: 4053  grad_norm: 21.5193  loss: 2.6122  loss_rpn_cls: 0.6373  loss_rpn_bbox: 0.0515  s0.loss_cls: 0.9587  s0.acc: 93.7988  s0.loss_bbox: 0.0887  s1.loss_cls: 0.5111  s1.acc: 97.3633  s1.loss_bbox: 0.0253  s2.loss_cls: 0.3358  s2.acc: 98.3887  s2.loss_bbox: 0.0037\n",
      "12/09 04:09:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 100/1221]  base_lr: 1.9920e-05 lr: 1.9920e-05  eta: 2:14:52  time: 0.3642  data_time: 0.0102  memory: 4053  grad_norm: 3.9292  loss: 0.9742  loss_rpn_cls: 0.3252  loss_rpn_bbox: 0.0431  s0.loss_cls: 0.3116  s0.acc: 94.9219  s0.loss_bbox: 0.1335  s1.loss_cls: 0.0872  s1.acc: 98.1445  s1.loss_bbox: 0.0398  s2.loss_cls: 0.0281  s2.acc: 98.9746  s2.loss_bbox: 0.0057\n",
      "12/09 04:10:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 150/1221]  base_lr: 2.9930e-05 lr: 2.9930e-05  eta: 2:13:46  time: 0.3633  data_time: 0.0100  memory: 4053  grad_norm: 3.1278  loss: 0.7721  loss_rpn_cls: 0.1492  loss_rpn_bbox: 0.0383  s0.loss_cls: 0.2886  s0.acc: 91.7969  s0.loss_bbox: 0.1457  s1.loss_cls: 0.0777  s1.acc: 96.0938  s1.loss_bbox: 0.0430  s2.loss_cls: 0.0233  s2.acc: 98.2910  s2.loss_bbox: 0.0064\n",
      "12/09 04:10:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 200/1221]  base_lr: 3.9940e-05 lr: 3.9940e-05  eta: 2:13:19  time: 0.3661  data_time: 0.0101  memory: 4053  grad_norm: 3.4500  loss: 0.8328  loss_rpn_cls: 0.1264  loss_rpn_bbox: 0.0440  s0.loss_cls: 0.3168  s0.acc: 96.3379  s0.loss_bbox: 0.1704  s1.loss_cls: 0.0878  s1.acc: 98.1934  s1.loss_bbox: 0.0545  s2.loss_cls: 0.0251  s2.acc: 99.3164  s2.loss_bbox: 0.0078\n",
      "12/09 04:10:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 250/1221]  base_lr: 4.9950e-05 lr: 4.9950e-05  eta: 2:12:58  time: 0.3667  data_time: 0.0107  memory: 4053  grad_norm: 3.6814  loss: 0.7679  loss_rpn_cls: 0.0964  loss_rpn_bbox: 0.0405  s0.loss_cls: 0.2999  s0.acc: 95.3125  s0.loss_bbox: 0.1586  s1.loss_cls: 0.0856  s1.acc: 97.7051  s1.loss_bbox: 0.0554  s2.loss_cls: 0.0234  s2.acc: 98.6816  s2.loss_bbox: 0.0081\n",
      "12/09 04:10:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 300/1221]  base_lr: 5.9960e-05 lr: 5.9960e-05  eta: 2:12:47  time: 0.3695  data_time: 0.0103  memory: 4053  grad_norm: 3.6230  loss: 0.7166  loss_rpn_cls: 0.0904  loss_rpn_bbox: 0.0397  s0.loss_cls: 0.2637  s0.acc: 91.5039  s0.loss_bbox: 0.1393  s1.loss_cls: 0.0856  s1.acc: 95.1172  s1.loss_bbox: 0.0616  s2.loss_cls: 0.0250  s2.acc: 97.9004  s2.loss_bbox: 0.0113\n",
      "12/09 04:11:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 350/1221]  base_lr: 6.9970e-05 lr: 6.9970e-05  eta: 2:12:18  time: 0.3640  data_time: 0.0104  memory: 4053  grad_norm: 3.8923  loss: 0.8067  loss_rpn_cls: 0.0867  loss_rpn_bbox: 0.0387  s0.loss_cls: 0.2894  s0.acc: 95.8496  s0.loss_bbox: 0.1502  s1.loss_cls: 0.1071  s1.acc: 96.3379  s1.loss_bbox: 0.0824  s2.loss_cls: 0.0330  s2.acc: 98.1445  s2.loss_bbox: 0.0192\n",
      "12/09 04:11:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 400/1221]  base_lr: 7.9980e-05 lr: 7.9980e-05  eta: 2:11:54  time: 0.3649  data_time: 0.0103  memory: 4053  grad_norm: 5.2597  loss: 0.8682  loss_rpn_cls: 0.0969  loss_rpn_bbox: 0.0397  s0.loss_cls: 0.2994  s0.acc: 89.2578  s0.loss_bbox: 0.1495  s1.loss_cls: 0.1209  s1.acc: 90.6738  s1.loss_bbox: 0.0915  s2.loss_cls: 0.0416  s2.acc: 93.6035  s2.loss_bbox: 0.0286\n",
      "12/09 04:11:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 450/1221]  base_lr: 8.9990e-05 lr: 8.9990e-05  eta: 2:11:24  time: 0.3620  data_time: 0.0098  memory: 4053  grad_norm: 4.0056  loss: 0.7969  loss_rpn_cls: 0.0854  loss_rpn_bbox: 0.0386  s0.loss_cls: 0.2646  s0.acc: 92.3340  s0.loss_bbox: 0.1307  s1.loss_cls: 0.1119  s1.acc: 93.5547  s1.loss_bbox: 0.0886  s2.loss_cls: 0.0435  s2.acc: 95.1660  s2.loss_bbox: 0.0335\n",
      "12/09 04:12:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 500/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:10:59  time: 0.3630  data_time: 0.0102  memory: 4053  grad_norm: 4.4069  loss: 0.9578  loss_rpn_cls: 0.0971  loss_rpn_bbox: 0.0425  s0.loss_cls: 0.3203  s0.acc: 95.5566  s0.loss_bbox: 0.1612  s1.loss_cls: 0.1356  s1.acc: 95.3125  s1.loss_bbox: 0.1071  s2.loss_cls: 0.0528  s2.acc: 97.0703  s2.loss_bbox: 0.0412\n",
      "12/09 04:12:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 550/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:10:42  time: 0.3665  data_time: 0.0093  memory: 4053  grad_norm: 4.2109  loss: 0.8355  loss_rpn_cls: 0.0714  loss_rpn_bbox: 0.0319  s0.loss_cls: 0.2747  s0.acc: 91.2598  s0.loss_bbox: 0.1353  s1.loss_cls: 0.1240  s1.acc: 92.6758  s1.loss_bbox: 0.1014  s2.loss_cls: 0.0524  s2.acc: 91.9922  s2.loss_bbox: 0.0444\n",
      "12/09 04:12:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 600/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:10:20  time: 0.3640  data_time: 0.0097  memory: 4053  grad_norm: 4.7205  loss: 0.9569  loss_rpn_cls: 0.0885  loss_rpn_bbox: 0.0419  s0.loss_cls: 0.3134  s0.acc: 88.2812  s0.loss_bbox: 0.1569  s1.loss_cls: 0.1367  s1.acc: 90.6738  s1.loss_bbox: 0.1175  s2.loss_cls: 0.0541  s2.acc: 92.1387  s2.loss_bbox: 0.0478\n",
      "12/09 04:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 650/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:10:00  time: 0.3648  data_time: 0.0099  memory: 4053  grad_norm: 4.7942  loss: 0.9762  loss_rpn_cls: 0.0832  loss_rpn_bbox: 0.0420  s0.loss_cls: 0.3135  s0.acc: 88.4277  s0.loss_bbox: 0.1610  s1.loss_cls: 0.1427  s1.acc: 90.9668  s1.loss_bbox: 0.1224  s2.loss_cls: 0.0593  s2.acc: 93.6523  s2.loss_bbox: 0.0521\n",
      "12/09 04:13:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 700/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:09:39  time: 0.3643  data_time: 0.0095  memory: 4054  grad_norm: 4.5984  loss: 0.9078  loss_rpn_cls: 0.0749  loss_rpn_bbox: 0.0354  s0.loss_cls: 0.3070  s0.acc: 96.2891  s0.loss_bbox: 0.1469  s1.loss_cls: 0.1341  s1.acc: 96.5820  s1.loss_bbox: 0.1091  s2.loss_cls: 0.0537  s2.acc: 96.7285  s2.loss_bbox: 0.0467\n",
      "12/09 04:13:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 750/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:09:18  time: 0.3631  data_time: 0.0098  memory: 4054  grad_norm: 4.6923  loss: 0.8144  loss_rpn_cls: 0.0776  loss_rpn_bbox: 0.0337  s0.loss_cls: 0.2687  s0.acc: 89.6484  s0.loss_bbox: 0.1275  s1.loss_cls: 0.1198  s1.acc: 93.5547  s1.loss_bbox: 0.0957  s2.loss_cls: 0.0493  s2.acc: 95.9473  s2.loss_bbox: 0.0421\n",
      "12/09 04:13:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 800/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:08:54  time: 0.3615  data_time: 0.0093  memory: 4053  grad_norm: 4.6451  loss: 0.8535  loss_rpn_cls: 0.0733  loss_rpn_bbox: 0.0331  s0.loss_cls: 0.2783  s0.acc: 87.4023  s0.loss_bbox: 0.1340  s1.loss_cls: 0.1251  s1.acc: 88.7695  s1.loss_bbox: 0.1081  s2.loss_cls: 0.0517  s2.acc: 93.9453  s2.loss_bbox: 0.0499\n",
      "12/09 04:14:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 850/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:08:33  time: 0.3626  data_time: 0.0099  memory: 4053  grad_norm: 4.7281  loss: 0.9884  loss_rpn_cls: 0.0899  loss_rpn_bbox: 0.0397  s0.loss_cls: 0.3157  s0.acc: 87.4023  s0.loss_bbox: 0.1572  s1.loss_cls: 0.1418  s1.acc: 88.8672  s1.loss_bbox: 0.1269  s2.loss_cls: 0.0603  s2.acc: 91.7969  s2.loss_bbox: 0.0569\n",
      "12/09 04:14:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 900/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:08:22  time: 0.3716  data_time: 0.0095  memory: 4053  grad_norm: 4.5531  loss: 0.9398  loss_rpn_cls: 0.0653  loss_rpn_bbox: 0.0345  s0.loss_cls: 0.3036  s0.acc: 94.5312  s0.loss_bbox: 0.1540  s1.loss_cls: 0.1416  s1.acc: 95.8496  s1.loss_bbox: 0.1246  s2.loss_cls: 0.0594  s2.acc: 97.2168  s2.loss_bbox: 0.0567\n",
      "12/09 04:14:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 950/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:08:02  time: 0.3635  data_time: 0.0093  memory: 4054  grad_norm: 5.0947  loss: 0.9953  loss_rpn_cls: 0.0900  loss_rpn_bbox: 0.0461  s0.loss_cls: 0.3205  s0.acc: 97.1680  s0.loss_bbox: 0.1541  s1.loss_cls: 0.1456  s1.acc: 97.6074  s1.loss_bbox: 0.1211  s2.loss_cls: 0.0616  s2.acc: 97.9492  s2.loss_bbox: 0.0562\n",
      "12/09 04:15:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:15:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1000/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:07:42  time: 0.3642  data_time: 0.0095  memory: 4054  grad_norm: 4.3294  loss: 0.8859  loss_rpn_cls: 0.0620  loss_rpn_bbox: 0.0328  s0.loss_cls: 0.2880  s0.acc: 92.3828  s0.loss_bbox: 0.1390  s1.loss_cls: 0.1343  s1.acc: 92.8223  s1.loss_bbox: 0.1157  s2.loss_cls: 0.0576  s2.acc: 95.6055  s2.loss_bbox: 0.0565\n",
      "12/09 04:15:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1050/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:07:20  time: 0.3617  data_time: 0.0094  memory: 4054  grad_norm: 4.7090  loss: 0.8192  loss_rpn_cls: 0.0551  loss_rpn_bbox: 0.0304  s0.loss_cls: 0.2696  s0.acc: 89.2578  s0.loss_bbox: 0.1265  s1.loss_cls: 0.1249  s1.acc: 90.4785  s1.loss_bbox: 0.1053  s2.loss_cls: 0.0555  s2.acc: 91.4062  s2.loss_bbox: 0.0519\n",
      "12/09 04:15:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1100/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:06:57  time: 0.3603  data_time: 0.0094  memory: 4054  grad_norm: 4.7822  loss: 0.9042  loss_rpn_cls: 0.0615  loss_rpn_bbox: 0.0308  s0.loss_cls: 0.2919  s0.acc: 92.8711  s0.loss_bbox: 0.1436  s1.loss_cls: 0.1379  s1.acc: 92.2852  s1.loss_bbox: 0.1208  s2.loss_cls: 0.0600  s2.acc: 93.2129  s2.loss_bbox: 0.0577\n",
      "12/09 04:16:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1150/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:06:36  time: 0.3609  data_time: 0.0091  memory: 4053  grad_norm: 4.7697  loss: 0.9633  loss_rpn_cls: 0.0640  loss_rpn_bbox: 0.0388  s0.loss_cls: 0.3170  s0.acc: 88.0371  s0.loss_bbox: 0.1551  s1.loss_cls: 0.1451  s1.acc: 87.6953  s1.loss_bbox: 0.1232  s2.loss_cls: 0.0617  s2.acc: 89.2578  s2.loss_bbox: 0.0584\n",
      "12/09 04:16:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1200/1221]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2:06:14  time: 0.3610  data_time: 0.0097  memory: 4054  grad_norm: 5.1584  loss: 0.9936  loss_rpn_cls: 0.0664  loss_rpn_bbox: 0.0351  s0.loss_cls: 0.3242  s0.acc: 95.1172  s0.loss_bbox: 0.1623  s1.loss_cls: 0.1493  s1.acc: 95.8496  s1.loss_bbox: 0.1309  s2.loss_cls: 0.0640  s2.acc: 96.3379  s2.loss_bbox: 0.0614\n",
      "12/09 04:16:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:16:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "12/09 04:16:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][  50/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:05:42  time: 0.3603  data_time: 0.0124  memory: 4053  grad_norm: 4.5797  loss: 0.8591  loss_rpn_cls: 0.0553  loss_rpn_bbox: 0.0273  s0.loss_cls: 0.2853  s0.acc: 86.4746  s0.loss_bbox: 0.1347  s1.loss_cls: 0.1294  s1.acc: 88.3301  s1.loss_bbox: 0.1147  s2.loss_cls: 0.0555  s2.acc: 91.4551  s2.loss_bbox: 0.0570\n",
      "12/09 04:17:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 100/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:05:20  time: 0.3588  data_time: 0.0094  memory: 4053  grad_norm: 4.4127  loss: 0.8319  loss_rpn_cls: 0.0592  loss_rpn_bbox: 0.0286  s0.loss_cls: 0.2706  s0.acc: 93.7012  s0.loss_bbox: 0.1284  s1.loss_cls: 0.1255  s1.acc: 92.7734  s1.loss_bbox: 0.1093  s2.loss_cls: 0.0553  s2.acc: 91.7480  s2.loss_bbox: 0.0552\n",
      "12/09 04:17:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 150/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:04:59  time: 0.3610  data_time: 0.0097  memory: 4053  grad_norm: 4.9492  loss: 0.8961  loss_rpn_cls: 0.0764  loss_rpn_bbox: 0.0312  s0.loss_cls: 0.2833  s0.acc: 87.8906  s0.loss_bbox: 0.1294  s1.loss_cls: 0.1358  s1.acc: 89.5996  s1.loss_bbox: 0.1187  s2.loss_cls: 0.0624  s2.acc: 92.4316  s2.loss_bbox: 0.0588\n",
      "12/09 04:17:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 200/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:04:37  time: 0.3581  data_time: 0.0096  memory: 4054  grad_norm: 4.6103  loss: 0.7811  loss_rpn_cls: 0.0465  loss_rpn_bbox: 0.0284  s0.loss_cls: 0.2487  s0.acc: 91.7480  s0.loss_bbox: 0.1182  s1.loss_cls: 0.1213  s1.acc: 92.4853  s1.loss_bbox: 0.1079  s2.loss_cls: 0.0544  s2.acc: 93.1829  s2.loss_bbox: 0.0558\n",
      "12/09 04:18:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 250/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:04:17  time: 0.3614  data_time: 0.0096  memory: 4054  grad_norm: 4.3788  loss: 0.7812  loss_rpn_cls: 0.0537  loss_rpn_bbox: 0.0288  s0.loss_cls: 0.2439  s0.acc: 93.0176  s0.loss_bbox: 0.1234  s1.loss_cls: 0.1169  s1.acc: 93.3594  s1.loss_bbox: 0.1093  s2.loss_cls: 0.0521  s2.acc: 94.2871  s2.loss_bbox: 0.0531\n",
      "12/09 04:18:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 300/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:03:55  time: 0.3579  data_time: 0.0101  memory: 4054  grad_norm: 4.6302  loss: 0.8437  loss_rpn_cls: 0.0549  loss_rpn_bbox: 0.0324  s0.loss_cls: 0.2619  s0.acc: 91.6504  s0.loss_bbox: 0.1367  s1.loss_cls: 0.1248  s1.acc: 91.1133  s1.loss_bbox: 0.1195  s2.loss_cls: 0.0551  s2.acc: 91.2598  s2.loss_bbox: 0.0583\n",
      "12/09 04:18:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 350/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:03:35  time: 0.3601  data_time: 0.0100  memory: 4054  grad_norm: 4.8076  loss: 0.8590  loss_rpn_cls: 0.0585  loss_rpn_bbox: 0.0307  s0.loss_cls: 0.2736  s0.acc: 94.1406  s0.loss_bbox: 0.1323  s1.loss_cls: 0.1310  s1.acc: 94.4824  s1.loss_bbox: 0.1174  s2.loss_cls: 0.0563  s2.acc: 91.9922  s2.loss_bbox: 0.0591\n",
      "12/09 04:18:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 400/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:03:13  time: 0.3574  data_time: 0.0091  memory: 4054  grad_norm: 4.6020  loss: 0.9104  loss_rpn_cls: 0.0588  loss_rpn_bbox: 0.0293  s0.loss_cls: 0.2987  s0.acc: 95.8008  s0.loss_bbox: 0.1440  s1.loss_cls: 0.1383  s1.acc: 95.2637  s1.loss_bbox: 0.1218  s2.loss_cls: 0.0601  s2.acc: 95.1172  s2.loss_bbox: 0.0594\n",
      "12/09 04:19:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 450/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:02:52  time: 0.3584  data_time: 0.0094  memory: 4054  grad_norm: 4.7573  loss: 0.9141  loss_rpn_cls: 0.0561  loss_rpn_bbox: 0.0343  s0.loss_cls: 0.2877  s0.acc: 89.6484  s0.loss_bbox: 0.1503  s1.loss_cls: 0.1365  s1.acc: 89.7461  s1.loss_bbox: 0.1275  s2.loss_cls: 0.0598  s2.acc: 93.7500  s2.loss_bbox: 0.0618\n",
      "12/09 04:19:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 500/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:02:32  time: 0.3598  data_time: 0.0093  memory: 4053  grad_norm: 4.9038  loss: 0.8983  loss_rpn_cls: 0.0590  loss_rpn_bbox: 0.0352  s0.loss_cls: 0.2786  s0.acc: 90.8203  s0.loss_bbox: 0.1503  s1.loss_cls: 0.1314  s1.acc: 91.0705  s1.loss_bbox: 0.1272  s2.loss_cls: 0.0569  s2.acc: 92.7058  s2.loss_bbox: 0.0598\n",
      "12/09 04:19:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 550/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:02:13  time: 0.3617  data_time: 0.0095  memory: 4054  grad_norm: 4.5691  loss: 0.7690  loss_rpn_cls: 0.0456  loss_rpn_bbox: 0.0315  s0.loss_cls: 0.2450  s0.acc: 93.4082  s0.loss_bbox: 0.1172  s1.loss_cls: 0.1157  s1.acc: 94.5312  s1.loss_bbox: 0.1047  s2.loss_cls: 0.0528  s2.acc: 95.4102  s2.loss_bbox: 0.0565\n",
      "12/09 04:20:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 600/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:01:53  time: 0.3602  data_time: 0.0095  memory: 4054  grad_norm: 5.5298  loss: 0.7662  loss_rpn_cls: 0.0569  loss_rpn_bbox: 0.0318  s0.loss_cls: 0.2358  s0.acc: 96.6797  s0.loss_bbox: 0.1179  s1.loss_cls: 0.1149  s1.acc: 97.8516  s1.loss_bbox: 0.1046  s2.loss_cls: 0.0515  s2.acc: 97.7051  s2.loss_bbox: 0.0528\n",
      "12/09 04:20:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 650/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:01:34  time: 0.3610  data_time: 0.0092  memory: 4054  grad_norm: 4.5653  loss: 0.7645  loss_rpn_cls: 0.0502  loss_rpn_bbox: 0.0298  s0.loss_cls: 0.2485  s0.acc: 97.9492  s0.loss_bbox: 0.1164  s1.loss_cls: 0.1171  s1.acc: 98.2422  s1.loss_bbox: 0.1007  s2.loss_cls: 0.0523  s2.acc: 98.5352  s2.loss_bbox: 0.0494\n",
      "12/09 04:20:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 700/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:01:19  time: 0.3680  data_time: 0.0097  memory: 4053  grad_norm: 5.0607  loss: 0.8689  loss_rpn_cls: 0.0623  loss_rpn_bbox: 0.0368  s0.loss_cls: 0.2735  s0.acc: 89.5020  s0.loss_bbox: 0.1358  s1.loss_cls: 0.1284  s1.acc: 90.8203  s1.loss_bbox: 0.1157  s2.loss_cls: 0.0565  s2.acc: 91.6504  s2.loss_bbox: 0.0599\n",
      "12/09 04:21:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 750/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:01:01  time: 0.3640  data_time: 0.0093  memory: 4054  grad_norm: 4.8884  loss: 0.8261  loss_rpn_cls: 0.0584  loss_rpn_bbox: 0.0332  s0.loss_cls: 0.2602  s0.acc: 96.6797  s0.loss_bbox: 0.1301  s1.loss_cls: 0.1226  s1.acc: 97.7051  s1.loss_bbox: 0.1116  s2.loss_cls: 0.0540  s2.acc: 96.3379  s2.loss_bbox: 0.0561\n",
      "12/09 04:21:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:21:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 800/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:00:43  time: 0.3643  data_time: 0.0095  memory: 4054  grad_norm: 4.9729  loss: 0.9035  loss_rpn_cls: 0.0649  loss_rpn_bbox: 0.0339  s0.loss_cls: 0.2893  s0.acc: 90.6250  s0.loss_bbox: 0.1416  s1.loss_cls: 0.1368  s1.acc: 91.2109  s1.loss_bbox: 0.1177  s2.loss_cls: 0.0601  s2.acc: 92.7246  s2.loss_bbox: 0.0591\n",
      "12/09 04:21:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 850/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:00:24  time: 0.3599  data_time: 0.0098  memory: 4054  grad_norm: 4.8475  loss: 0.8661  loss_rpn_cls: 0.0526  loss_rpn_bbox: 0.0313  s0.loss_cls: 0.2836  s0.acc: 87.6465  s0.loss_bbox: 0.1321  s1.loss_cls: 0.1354  s1.acc: 89.6973  s1.loss_bbox: 0.1144  s2.loss_cls: 0.0596  s2.acc: 93.7012  s2.loss_bbox: 0.0569\n",
      "12/09 04:22:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 900/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 2:00:04  time: 0.3602  data_time: 0.0096  memory: 4053  grad_norm: 5.2503  loss: 0.8473  loss_rpn_cls: 0.0665  loss_rpn_bbox: 0.0323  s0.loss_cls: 0.2723  s0.acc: 91.9434  s0.loss_bbox: 0.1260  s1.loss_cls: 0.1302  s1.acc: 92.2397  s1.loss_bbox: 0.1091  s2.loss_cls: 0.0575  s2.acc: 93.5753  s2.loss_bbox: 0.0534\n",
      "12/09 04:22:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 950/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 1:59:46  time: 0.3619  data_time: 0.0098  memory: 4054  grad_norm: 4.5184  loss: 0.7265  loss_rpn_cls: 0.0500  loss_rpn_bbox: 0.0247  s0.loss_cls: 0.2318  s0.acc: 88.6230  s0.loss_bbox: 0.1081  s1.loss_cls: 0.1112  s1.acc: 89.6484  s1.loss_bbox: 0.0987  s2.loss_cls: 0.0512  s2.acc: 92.4805  s2.loss_bbox: 0.0506\n",
      "12/09 04:22:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1000/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 1:59:28  time: 0.3636  data_time: 0.0098  memory: 4054  grad_norm: 4.6737  loss: 0.8693  loss_rpn_cls: 0.0607  loss_rpn_bbox: 0.0298  s0.loss_cls: 0.2748  s0.acc: 91.0156  s0.loss_bbox: 0.1313  s1.loss_cls: 0.1350  s1.acc: 91.2109  s1.loss_bbox: 0.1164  s2.loss_cls: 0.0622  s2.acc: 92.9688  s2.loss_bbox: 0.0590\n",
      "12/09 04:22:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1050/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 1:59:09  time: 0.3616  data_time: 0.0095  memory: 4053  grad_norm: 4.4896  loss: 0.7536  loss_rpn_cls: 0.0548  loss_rpn_bbox: 0.0267  s0.loss_cls: 0.2424  s0.acc: 92.3340  s0.loss_bbox: 0.1106  s1.loss_cls: 0.1158  s1.acc: 93.4570  s1.loss_bbox: 0.0996  s2.loss_cls: 0.0527  s2.acc: 94.6289  s2.loss_bbox: 0.0511\n",
      "12/09 04:23:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1100/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 1:58:50  time: 0.3600  data_time: 0.0099  memory: 4053  grad_norm: 4.4653  loss: 0.7693  loss_rpn_cls: 0.0515  loss_rpn_bbox: 0.0263  s0.loss_cls: 0.2497  s0.acc: 91.5527  s0.loss_bbox: 0.1180  s1.loss_cls: 0.1168  s1.acc: 90.6738  s1.loss_bbox: 0.1033  s2.loss_cls: 0.0512  s2.acc: 90.9668  s2.loss_bbox: 0.0527\n",
      "12/09 04:23:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1150/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 1:58:30  time: 0.3589  data_time: 0.0091  memory: 4054  grad_norm: 4.3498  loss: 0.6967  loss_rpn_cls: 0.0425  loss_rpn_bbox: 0.0233  s0.loss_cls: 0.2216  s0.acc: 92.6270  s0.loss_bbox: 0.1074  s1.loss_cls: 0.1083  s1.acc: 92.4805  s1.loss_bbox: 0.0952  s2.loss_cls: 0.0501  s2.acc: 92.7246  s2.loss_bbox: 0.0484\n",
      "12/09 04:23:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1200/1221]  base_lr: 9.8313e-05 lr: 9.8313e-05  eta: 1:58:11  time: 0.3605  data_time: 0.0096  memory: 4053  grad_norm: 4.8245  loss: 0.9522  loss_rpn_cls: 0.0730  loss_rpn_bbox: 0.0428  s0.loss_cls: 0.2958  s0.acc: 89.4043  s0.loss_bbox: 0.1493  s1.loss_cls: 0.1407  s1.acc: 92.1387  s1.loss_bbox: 0.1269  s2.loss_cls: 0.0624  s2.acc: 94.0430  s2.loss_bbox: 0.0612\n",
      "12/09 04:23:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:23:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "12/09 04:24:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][  50/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:57:46  time: 0.3676  data_time: 0.0137  memory: 4053  grad_norm: 4.7121  loss: 0.7812  loss_rpn_cls: 0.0451  loss_rpn_bbox: 0.0292  s0.loss_cls: 0.2430  s0.acc: 88.6719  s0.loss_bbox: 0.1207  s1.loss_cls: 0.1196  s1.acc: 89.0250  s1.loss_bbox: 0.1094  s2.loss_cls: 0.0549  s2.acc: 90.9580  s2.loss_bbox: 0.0594\n",
      "12/09 04:24:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 100/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:57:26  time: 0.3582  data_time: 0.0094  memory: 4053  grad_norm: 4.5088  loss: 0.7705  loss_rpn_cls: 0.0452  loss_rpn_bbox: 0.0312  s0.loss_cls: 0.2390  s0.acc: 91.9922  s0.loss_bbox: 0.1248  s1.loss_cls: 0.1140  s1.acc: 93.5059  s1.loss_bbox: 0.1082  s2.loss_cls: 0.0526  s2.acc: 92.5781  s2.loss_bbox: 0.0555\n",
      "12/09 04:24:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 150/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:57:07  time: 0.3591  data_time: 0.0096  memory: 4054  grad_norm: 4.7807  loss: 0.7335  loss_rpn_cls: 0.0420  loss_rpn_bbox: 0.0245  s0.loss_cls: 0.2283  s0.acc: 96.0938  s0.loss_bbox: 0.1168  s1.loss_cls: 0.1116  s1.acc: 95.6543  s1.loss_bbox: 0.1050  s2.loss_cls: 0.0509  s2.acc: 93.4570  s2.loss_bbox: 0.0542\n",
      "12/09 04:25:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 200/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:56:50  time: 0.3656  data_time: 0.0091  memory: 4054  grad_norm: 4.6957  loss: 0.7476  loss_rpn_cls: 0.0438  loss_rpn_bbox: 0.0277  s0.loss_cls: 0.2353  s0.acc: 89.2578  s0.loss_bbox: 0.1127  s1.loss_cls: 0.1140  s1.acc: 90.0344  s1.loss_bbox: 0.1049  s2.loss_cls: 0.0520  s2.acc: 91.3108  s2.loss_bbox: 0.0573\n",
      "12/09 04:25:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 250/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:56:30  time: 0.3581  data_time: 0.0095  memory: 4054  grad_norm: 4.6614  loss: 0.7320  loss_rpn_cls: 0.0444  loss_rpn_bbox: 0.0288  s0.loss_cls: 0.2301  s0.acc: 96.3867  s0.loss_bbox: 0.1116  s1.loss_cls: 0.1116  s1.acc: 96.0938  s1.loss_bbox: 0.1017  s2.loss_cls: 0.0511  s2.acc: 96.4844  s2.loss_bbox: 0.0526\n",
      "12/09 04:25:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 300/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:56:10  time: 0.3562  data_time: 0.0092  memory: 4054  grad_norm: 4.8932  loss: 0.7847  loss_rpn_cls: 0.0489  loss_rpn_bbox: 0.0279  s0.loss_cls: 0.2518  s0.acc: 97.9492  s0.loss_bbox: 0.1182  s1.loss_cls: 0.1201  s1.acc: 97.2168  s1.loss_bbox: 0.1070  s2.loss_cls: 0.0545  s2.acc: 96.9727  s2.loss_bbox: 0.0563\n",
      "12/09 04:26:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 350/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:55:50  time: 0.3593  data_time: 0.0094  memory: 4053  grad_norm: 5.3179  loss: 0.7575  loss_rpn_cls: 0.0481  loss_rpn_bbox: 0.0266  s0.loss_cls: 0.2441  s0.acc: 91.8945  s0.loss_bbox: 0.1164  s1.loss_cls: 0.1168  s1.acc: 90.5392  s1.loss_bbox: 0.1020  s2.loss_cls: 0.0528  s2.acc: 88.6330  s2.loss_bbox: 0.0507\n",
      "12/09 04:26:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 400/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:55:30  time: 0.3567  data_time: 0.0093  memory: 4054  grad_norm: 5.0747  loss: 0.7791  loss_rpn_cls: 0.0563  loss_rpn_bbox: 0.0281  s0.loss_cls: 0.2426  s0.acc: 94.9707  s0.loss_bbox: 0.1193  s1.loss_cls: 0.1192  s1.acc: 95.6308  s1.loss_bbox: 0.1056  s2.loss_cls: 0.0536  s2.acc: 95.3386  s2.loss_bbox: 0.0543\n",
      "12/09 04:26:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 450/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:55:12  time: 0.3612  data_time: 0.0093  memory: 4053  grad_norm: 5.3007  loss: 0.7846  loss_rpn_cls: 0.0430  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.2486  s0.acc: 90.0391  s0.loss_bbox: 0.1228  s1.loss_cls: 0.1202  s1.acc: 90.3320  s1.loss_bbox: 0.1113  s2.loss_cls: 0.0551  s2.acc: 90.3320  s2.loss_bbox: 0.0561\n",
      "12/09 04:26:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 500/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:54:54  time: 0.3623  data_time: 0.0096  memory: 4054  grad_norm: 4.9286  loss: 0.7348  loss_rpn_cls: 0.0415  loss_rpn_bbox: 0.0261  s0.loss_cls: 0.2292  s0.acc: 84.7656  s0.loss_bbox: 0.1140  s1.loss_cls: 0.1088  s1.acc: 87.0278  s1.loss_bbox: 0.1073  s2.loss_cls: 0.0494  s2.acc: 89.4240  s2.loss_bbox: 0.0585\n",
      "12/09 04:27:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 550/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:54:35  time: 0.3596  data_time: 0.0096  memory: 4053  grad_norm: 4.5398  loss: 0.6664  loss_rpn_cls: 0.0449  loss_rpn_bbox: 0.0254  s0.loss_cls: 0.2059  s0.acc: 89.9902  s0.loss_bbox: 0.1024  s1.loss_cls: 0.0994  s1.acc: 90.5273  s1.loss_bbox: 0.0921  s2.loss_cls: 0.0465  s2.acc: 91.9434  s2.loss_bbox: 0.0497\n",
      "12/09 04:27:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:27:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 600/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:54:18  time: 0.3658  data_time: 0.0095  memory: 4054  grad_norm: 4.9044  loss: 0.8105  loss_rpn_cls: 0.0503  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.2583  s0.acc: 90.6250  s0.loss_bbox: 0.1278  s1.loss_cls: 0.1241  s1.acc: 89.6484  s1.loss_bbox: 0.1106  s2.loss_cls: 0.0569  s2.acc: 91.2598  s2.loss_bbox: 0.0568\n",
      "12/09 04:27:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 650/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:54:00  time: 0.3615  data_time: 0.0098  memory: 4054  grad_norm: 5.1689  loss: 0.8244  loss_rpn_cls: 0.0486  loss_rpn_bbox: 0.0299  s0.loss_cls: 0.2552  s0.acc: 97.8516  s0.loss_bbox: 0.1316  s1.loss_cls: 0.1205  s1.acc: 98.1445  s1.loss_bbox: 0.1198  s2.loss_cls: 0.0561  s2.acc: 97.8027  s2.loss_bbox: 0.0625\n",
      "12/09 04:28:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 700/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:53:41  time: 0.3614  data_time: 0.0091  memory: 4054  grad_norm: 4.7248  loss: 0.7900  loss_rpn_cls: 0.0499  loss_rpn_bbox: 0.0295  s0.loss_cls: 0.2478  s0.acc: 93.7988  s0.loss_bbox: 0.1248  s1.loss_cls: 0.1187  s1.acc: 92.3340  s1.loss_bbox: 0.1104  s2.loss_cls: 0.0536  s2.acc: 93.1641  s2.loss_bbox: 0.0553\n",
      "12/09 04:28:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 750/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:53:23  time: 0.3606  data_time: 0.0092  memory: 4053  grad_norm: 4.9061  loss: 0.7019  loss_rpn_cls: 0.0478  loss_rpn_bbox: 0.0224  s0.loss_cls: 0.2254  s0.acc: 93.7988  s0.loss_bbox: 0.1023  s1.loss_cls: 0.1086  s1.acc: 94.5562  s1.loss_bbox: 0.0945  s2.loss_cls: 0.0492  s2.acc: 94.7523  s2.loss_bbox: 0.0517\n",
      "12/09 04:28:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 800/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:53:04  time: 0.3606  data_time: 0.0092  memory: 4054  grad_norm: 4.6402  loss: 0.7876  loss_rpn_cls: 0.0487  loss_rpn_bbox: 0.0286  s0.loss_cls: 0.2539  s0.acc: 96.0449  s0.loss_bbox: 0.1187  s1.loss_cls: 0.1206  s1.acc: 95.2148  s1.loss_bbox: 0.1047  s2.loss_cls: 0.0554  s2.acc: 94.8242  s2.loss_bbox: 0.0569\n",
      "12/09 04:29:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 850/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:52:45  time: 0.3592  data_time: 0.0093  memory: 4054  grad_norm: 4.4956  loss: 0.7226  loss_rpn_cls: 0.0437  loss_rpn_bbox: 0.0321  s0.loss_cls: 0.2283  s0.acc: 93.5547  s0.loss_bbox: 0.1085  s1.loss_cls: 0.1106  s1.acc: 94.9169  s1.loss_bbox: 0.0958  s2.loss_cls: 0.0516  s2.acc: 94.8192  s2.loss_bbox: 0.0521\n",
      "12/09 04:29:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 900/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:52:27  time: 0.3605  data_time: 0.0093  memory: 4054  grad_norm: 4.6359  loss: 0.7850  loss_rpn_cls: 0.0454  loss_rpn_bbox: 0.0258  s0.loss_cls: 0.2447  s0.acc: 91.1621  s0.loss_bbox: 0.1212  s1.loss_cls: 0.1193  s1.acc: 92.1875  s1.loss_bbox: 0.1136  s2.loss_cls: 0.0543  s2.acc: 92.6758  s2.loss_bbox: 0.0608\n",
      "12/09 04:29:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 950/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:52:08  time: 0.3589  data_time: 0.0095  memory: 4054  grad_norm: 5.1553  loss: 0.8130  loss_rpn_cls: 0.0431  loss_rpn_bbox: 0.0320  s0.loss_cls: 0.2540  s0.acc: 83.5449  s0.loss_bbox: 0.1276  s1.loss_cls: 0.1242  s1.acc: 83.6914  s1.loss_bbox: 0.1148  s2.loss_cls: 0.0564  s2.acc: 84.8633  s2.loss_bbox: 0.0609\n",
      "12/09 04:29:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1000/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:51:49  time: 0.3588  data_time: 0.0093  memory: 4053  grad_norm: 4.5470  loss: 0.7410  loss_rpn_cls: 0.0527  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.2300  s0.acc: 95.0684  s0.loss_bbox: 0.1162  s1.loss_cls: 0.1101  s1.acc: 94.0918  s1.loss_bbox: 0.1015  s2.loss_cls: 0.0511  s2.acc: 94.8730  s2.loss_bbox: 0.0532\n",
      "12/09 04:30:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1050/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:51:30  time: 0.3585  data_time: 0.0094  memory: 4053  grad_norm: 4.7197  loss: 0.7487  loss_rpn_cls: 0.0463  loss_rpn_bbox: 0.0249  s0.loss_cls: 0.2354  s0.acc: 87.5488  s0.loss_bbox: 0.1151  s1.loss_cls: 0.1147  s1.acc: 87.3039  s1.loss_bbox: 0.1033  s2.loss_cls: 0.0524  s2.acc: 91.7279  s2.loss_bbox: 0.0567\n",
      "12/09 04:30:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1100/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:51:10  time: 0.3575  data_time: 0.0095  memory: 4053  grad_norm: 4.7228  loss: 0.7914  loss_rpn_cls: 0.0513  loss_rpn_bbox: 0.0280  s0.loss_cls: 0.2525  s0.acc: 91.1133  s0.loss_bbox: 0.1171  s1.loss_cls: 0.1226  s1.acc: 91.9844  s1.loss_bbox: 0.1065  s2.loss_cls: 0.0570  s2.acc: 94.2731  s2.loss_bbox: 0.0564\n",
      "12/09 04:30:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1150/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:50:52  time: 0.3596  data_time: 0.0094  memory: 4054  grad_norm: 4.8974  loss: 0.7312  loss_rpn_cls: 0.0504  loss_rpn_bbox: 0.0273  s0.loss_cls: 0.2238  s0.acc: 91.6992  s0.loss_bbox: 0.1123  s1.loss_cls: 0.1119  s1.acc: 91.1894  s1.loss_bbox: 0.1001  s2.loss_cls: 0.0526  s2.acc: 92.4694  s2.loss_bbox: 0.0527\n",
      "12/09 04:31:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1200/1221]  base_lr: 9.3368e-05 lr: 9.3368e-05  eta: 1:50:32  time: 0.3564  data_time: 0.0096  memory: 4054  grad_norm: 4.5963  loss: 0.7606  loss_rpn_cls: 0.0527  loss_rpn_bbox: 0.0272  s0.loss_cls: 0.2441  s0.acc: 93.2617  s0.loss_bbox: 0.1170  s1.loss_cls: 0.1166  s1.acc: 93.6035  s1.loss_bbox: 0.0994  s2.loss_cls: 0.0529  s2.acc: 94.7266  s2.loss_bbox: 0.0508\n",
      "12/09 04:31:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:31:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "12/09 04:31:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][  50/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:50:07  time: 0.3642  data_time: 0.0130  memory: 4054  grad_norm: 4.7263  loss: 0.6846  loss_rpn_cls: 0.0402  loss_rpn_bbox: 0.0303  s0.loss_cls: 0.2113  s0.acc: 93.8965  s0.loss_bbox: 0.1089  s1.loss_cls: 0.1002  s1.acc: 93.5547  s1.loss_bbox: 0.0960  s2.loss_cls: 0.0451  s2.acc: 95.4102  s2.loss_bbox: 0.0526\n",
      "12/09 04:31:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 100/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:49:48  time: 0.3578  data_time: 0.0098  memory: 4054  grad_norm: 4.3933  loss: 0.6606  loss_rpn_cls: 0.0370  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.1994  s0.acc: 97.3145  s0.loss_bbox: 0.1072  s1.loss_cls: 0.0961  s1.acc: 98.2910  s1.loss_bbox: 0.0959  s2.loss_cls: 0.0471  s2.acc: 97.6074  s2.loss_bbox: 0.0522\n",
      "12/09 04:32:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 150/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:49:28  time: 0.3570  data_time: 0.0092  memory: 4054  grad_norm: 4.7234  loss: 0.6869  loss_rpn_cls: 0.0379  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.2062  s0.acc: 93.5059  s0.loss_bbox: 0.1084  s1.loss_cls: 0.0987  s1.acc: 94.1292  s1.loss_bbox: 0.1054  s2.loss_cls: 0.0458  s2.acc: 93.1607  s2.loss_bbox: 0.0595\n",
      "12/09 04:32:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 200/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:49:09  time: 0.3559  data_time: 0.0091  memory: 4053  grad_norm: 4.3286  loss: 0.5785  loss_rpn_cls: 0.0312  loss_rpn_bbox: 0.0200  s0.loss_cls: 0.1810  s0.acc: 95.6543  s0.loss_bbox: 0.0881  s1.loss_cls: 0.0895  s1.acc: 95.9473  s1.loss_bbox: 0.0816  s2.loss_cls: 0.0427  s2.acc: 96.2402  s2.loss_bbox: 0.0444\n",
      "12/09 04:32:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 250/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:48:50  time: 0.3574  data_time: 0.0091  memory: 4053  grad_norm: 4.7777  loss: 0.6634  loss_rpn_cls: 0.0472  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.2034  s0.acc: 85.6934  s0.loss_bbox: 0.1053  s1.loss_cls: 0.0967  s1.acc: 86.6798  s1.loss_bbox: 0.0911  s2.loss_cls: 0.0451  s2.acc: 88.0000  s2.loss_bbox: 0.0494\n",
      "12/09 04:33:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 300/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:48:31  time: 0.3575  data_time: 0.0094  memory: 4054  grad_norm: 4.4812  loss: 0.6970  loss_rpn_cls: 0.0352  loss_rpn_bbox: 0.0235  s0.loss_cls: 0.2191  s0.acc: 93.4570  s0.loss_bbox: 0.1108  s1.loss_cls: 0.1054  s1.acc: 93.5059  s1.loss_bbox: 0.1010  s2.loss_cls: 0.0490  s2.acc: 93.0176  s2.loss_bbox: 0.0530\n",
      "12/09 04:33:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:33:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 350/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:48:13  time: 0.3601  data_time: 0.0100  memory: 4054  grad_norm: 4.4526  loss: 0.6573  loss_rpn_cls: 0.0360  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.2011  s0.acc: 94.6777  s0.loss_bbox: 0.1026  s1.loss_cls: 0.0987  s1.acc: 93.1641  s1.loss_bbox: 0.0948  s2.loss_cls: 0.0457  s2.acc: 93.5547  s2.loss_bbox: 0.0533\n",
      "12/09 04:33:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 400/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:47:54  time: 0.3599  data_time: 0.0095  memory: 4054  grad_norm: 5.4962  loss: 0.6998  loss_rpn_cls: 0.0426  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.2155  s0.acc: 93.0664  s0.loss_bbox: 0.1058  s1.loss_cls: 0.1064  s1.acc: 93.9891  s1.loss_bbox: 0.0999  s2.loss_cls: 0.0493  s2.acc: 94.7395  s2.loss_bbox: 0.0552\n",
      "12/09 04:34:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 450/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:47:35  time: 0.3548  data_time: 0.0090  memory: 4054  grad_norm: 4.7660  loss: 0.7045  loss_rpn_cls: 0.0443  loss_rpn_bbox: 0.0269  s0.loss_cls: 0.2132  s0.acc: 90.0391  s0.loss_bbox: 0.1152  s1.loss_cls: 0.1012  s1.acc: 90.5138  s1.loss_bbox: 0.1018  s2.loss_cls: 0.0463  s2.acc: 89.6552  s2.loss_bbox: 0.0557\n",
      "12/09 04:34:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 500/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:47:16  time: 0.3561  data_time: 0.0093  memory: 4053  grad_norm: 5.0749  loss: 0.7156  loss_rpn_cls: 0.0413  loss_rpn_bbox: 0.0246  s0.loss_cls: 0.2184  s0.acc: 91.3574  s0.loss_bbox: 0.1124  s1.loss_cls: 0.1059  s1.acc: 91.3108  s1.loss_bbox: 0.1060  s2.loss_cls: 0.0493  s2.acc: 92.7104  s2.loss_bbox: 0.0576\n",
      "12/09 04:34:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 550/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:46:56  time: 0.3558  data_time: 0.0096  memory: 4054  grad_norm: 5.1113  loss: 0.7275  loss_rpn_cls: 0.0434  loss_rpn_bbox: 0.0228  s0.loss_cls: 0.2316  s0.acc: 94.8242  s0.loss_bbox: 0.1097  s1.loss_cls: 0.1114  s1.acc: 95.5566  s1.loss_bbox: 0.1007  s2.loss_cls: 0.0523  s2.acc: 96.7773  s2.loss_bbox: 0.0556\n",
      "12/09 04:34:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 600/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:46:38  time: 0.3606  data_time: 0.0098  memory: 4054  grad_norm: 4.9324  loss: 0.7695  loss_rpn_cls: 0.0496  loss_rpn_bbox: 0.0280  s0.loss_cls: 0.2319  s0.acc: 94.2383  s0.loss_bbox: 0.1238  s1.loss_cls: 0.1115  s1.acc: 94.2871  s1.loss_bbox: 0.1126  s2.loss_cls: 0.0522  s2.acc: 93.9941  s2.loss_bbox: 0.0598\n",
      "12/09 04:35:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 650/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:46:20  time: 0.3604  data_time: 0.0098  memory: 4053  grad_norm: 4.8981  loss: 0.7168  loss_rpn_cls: 0.0399  loss_rpn_bbox: 0.0255  s0.loss_cls: 0.2268  s0.acc: 91.7969  s0.loss_bbox: 0.1159  s1.loss_cls: 0.1071  s1.acc: 92.1387  s1.loss_bbox: 0.1011  s2.loss_cls: 0.0479  s2.acc: 92.0410  s2.loss_bbox: 0.0527\n",
      "12/09 04:35:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 700/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:46:01  time: 0.3569  data_time: 0.0092  memory: 4054  grad_norm: 4.6159  loss: 0.6155  loss_rpn_cls: 0.0339  loss_rpn_bbox: 0.0204  s0.loss_cls: 0.1936  s0.acc: 95.2637  s0.loss_bbox: 0.0930  s1.loss_cls: 0.0958  s1.acc: 95.1172  s1.loss_bbox: 0.0867  s2.loss_cls: 0.0453  s2.acc: 94.8730  s2.loss_bbox: 0.0469\n",
      "12/09 04:35:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 750/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:45:42  time: 0.3566  data_time: 0.0093  memory: 4053  grad_norm: 4.4874  loss: 0.6338  loss_rpn_cls: 0.0378  loss_rpn_bbox: 0.0221  s0.loss_cls: 0.1969  s0.acc: 94.4824  s0.loss_bbox: 0.0988  s1.loss_cls: 0.0934  s1.acc: 94.3683  s1.loss_bbox: 0.0909  s2.loss_cls: 0.0433  s2.acc: 92.6543  s2.loss_bbox: 0.0507\n",
      "12/09 04:36:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 800/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:45:23  time: 0.3563  data_time: 0.0093  memory: 4054  grad_norm: 4.8513  loss: 0.7359  loss_rpn_cls: 0.0399  loss_rpn_bbox: 0.0273  s0.loss_cls: 0.2295  s0.acc: 89.3066  s0.loss_bbox: 0.1229  s1.loss_cls: 0.1092  s1.acc: 90.7216  s1.loss_bbox: 0.1058  s2.loss_cls: 0.0489  s2.acc: 92.0510  s2.loss_bbox: 0.0525\n",
      "12/09 04:36:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 850/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:45:04  time: 0.3570  data_time: 0.0096  memory: 4054  grad_norm: 4.5788  loss: 0.7360  loss_rpn_cls: 0.0456  loss_rpn_bbox: 0.0272  s0.loss_cls: 0.2307  s0.acc: 96.3379  s0.loss_bbox: 0.1178  s1.loss_cls: 0.1088  s1.acc: 96.5332  s1.loss_bbox: 0.1039  s2.loss_cls: 0.0494  s2.acc: 95.9961  s2.loss_bbox: 0.0527\n",
      "12/09 04:36:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 900/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:44:46  time: 0.3598  data_time: 0.0094  memory: 4054  grad_norm: 4.5778  loss: 0.6337  loss_rpn_cls: 0.0355  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.1991  s0.acc: 96.2402  s0.loss_bbox: 0.0958  s1.loss_cls: 0.0951  s1.acc: 96.8262  s1.loss_bbox: 0.0859  s2.loss_cls: 0.0454  s2.acc: 97.1177  s2.loss_bbox: 0.0497\n",
      "12/09 04:37:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 950/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:44:28  time: 0.3601  data_time: 0.0094  memory: 4054  grad_norm: 4.7959  loss: 0.7511  loss_rpn_cls: 0.0449  loss_rpn_bbox: 0.0283  s0.loss_cls: 0.2329  s0.acc: 90.8203  s0.loss_bbox: 0.1177  s1.loss_cls: 0.1117  s1.acc: 91.4820  s1.loss_bbox: 0.1062  s2.loss_cls: 0.0519  s2.acc: 91.6831  s2.loss_bbox: 0.0574\n",
      "12/09 04:37:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1000/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:44:09  time: 0.3597  data_time: 0.0100  memory: 4054  grad_norm: 4.6998  loss: 0.6491  loss_rpn_cls: 0.0375  loss_rpn_bbox: 0.0221  s0.loss_cls: 0.2078  s0.acc: 93.9941  s0.loss_bbox: 0.0972  s1.loss_cls: 0.0984  s1.acc: 94.2383  s1.loss_bbox: 0.0899  s2.loss_cls: 0.0458  s2.acc: 93.9453  s2.loss_bbox: 0.0503\n",
      "12/09 04:37:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1050/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:43:52  time: 0.3623  data_time: 0.0098  memory: 4054  grad_norm: 4.5306  loss: 0.6575  loss_rpn_cls: 0.0370  loss_rpn_bbox: 0.0241  s0.loss_cls: 0.2080  s0.acc: 95.8984  s0.loss_bbox: 0.1018  s1.loss_cls: 0.0997  s1.acc: 96.3379  s1.loss_bbox: 0.0912  s2.loss_cls: 0.0467  s2.acc: 97.5586  s2.loss_bbox: 0.0492\n",
      "12/09 04:37:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1100/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:43:33  time: 0.3571  data_time: 0.0092  memory: 4054  grad_norm: 4.7319  loss: 0.7077  loss_rpn_cls: 0.0459  loss_rpn_bbox: 0.0317  s0.loss_cls: 0.2151  s0.acc: 94.0918  s0.loss_bbox: 0.1146  s1.loss_cls: 0.1013  s1.acc: 93.4570  s1.loss_bbox: 0.1005  s2.loss_cls: 0.0463  s2.acc: 93.4082  s2.loss_bbox: 0.0523\n",
      "12/09 04:38:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1150/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:43:15  time: 0.3599  data_time: 0.0097  memory: 4054  grad_norm: 4.9245  loss: 0.7436  loss_rpn_cls: 0.0446  loss_rpn_bbox: 0.0321  s0.loss_cls: 0.2322  s0.acc: 96.8750  s0.loss_bbox: 0.1192  s1.loss_cls: 0.1084  s1.acc: 96.6370  s1.loss_bbox: 0.1020  s2.loss_cls: 0.0501  s2.acc: 96.3783  s2.loss_bbox: 0.0551\n",
      "12/09 04:38:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1200/1221]  base_lr: 8.5502e-05 lr: 8.5502e-05  eta: 1:42:56  time: 0.3546  data_time: 0.0091  memory: 4054  grad_norm: 4.5605  loss: 0.6928  loss_rpn_cls: 0.0473  loss_rpn_bbox: 0.0271  s0.loss_cls: 0.2198  s0.acc: 93.7500  s0.loss_bbox: 0.1026  s1.loss_cls: 0.1044  s1.acc: 94.3925  s1.loss_bbox: 0.0928  s2.loss_cls: 0.0484  s2.acc: 96.3109  s2.loss_bbox: 0.0503\n",
      "12/09 04:38:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:38:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
      "12/09 04:39:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][  50/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:42:30  time: 0.3639  data_time: 0.0139  memory: 4053  grad_norm: 4.5183  loss: 0.6087  loss_rpn_cls: 0.0267  loss_rpn_bbox: 0.0211  s0.loss_cls: 0.1882  s0.acc: 97.4121  s0.loss_bbox: 0.1001  s1.loss_cls: 0.0873  s1.acc: 97.5586  s1.loss_bbox: 0.0931  s2.loss_cls: 0.0400  s2.acc: 97.7539  s2.loss_bbox: 0.0523\n",
      "12/09 04:39:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 100/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:42:12  time: 0.3614  data_time: 0.0095  memory: 4053  grad_norm: 4.7745  loss: 0.6910  loss_rpn_cls: 0.0387  loss_rpn_bbox: 0.0254  s0.loss_cls: 0.2122  s0.acc: 90.5273  s0.loss_bbox: 0.1135  s1.loss_cls: 0.1000  s1.acc: 91.3278  s1.loss_bbox: 0.1011  s2.loss_cls: 0.0464  s2.acc: 93.0916  s2.loss_bbox: 0.0537\n",
      "12/09 04:39:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:39:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 150/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:41:54  time: 0.3591  data_time: 0.0099  memory: 4054  grad_norm: 4.7693  loss: 0.6659  loss_rpn_cls: 0.0426  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.2092  s0.acc: 91.1621  s0.loss_bbox: 0.1035  s1.loss_cls: 0.0997  s1.acc: 91.1089  s1.loss_bbox: 0.0899  s2.loss_cls: 0.0465  s2.acc: 93.2617  s2.loss_bbox: 0.0493\n",
      "12/09 04:39:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 200/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:41:35  time: 0.3555  data_time: 0.0094  memory: 4054  grad_norm: 4.7765  loss: 0.6295  loss_rpn_cls: 0.0410  loss_rpn_bbox: 0.0240  s0.loss_cls: 0.1906  s0.acc: 89.7461  s0.loss_bbox: 0.1052  s1.loss_cls: 0.0869  s1.acc: 90.3620  s1.loss_bbox: 0.0917  s2.loss_cls: 0.0405  s2.acc: 92.1944  s2.loss_bbox: 0.0496\n",
      "12/09 04:40:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 250/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:41:16  time: 0.3552  data_time: 0.0092  memory: 4053  grad_norm: 4.4601  loss: 0.6078  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0210  s0.loss_cls: 0.1907  s0.acc: 95.0684  s0.loss_bbox: 0.0960  s1.loss_cls: 0.0895  s1.acc: 95.0690  s1.loss_bbox: 0.0883  s2.loss_cls: 0.0423  s2.acc: 96.2926  s2.loss_bbox: 0.0494\n",
      "12/09 04:40:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 300/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:40:57  time: 0.3585  data_time: 0.0092  memory: 4054  grad_norm: 4.7494  loss: 0.6335  loss_rpn_cls: 0.0329  loss_rpn_bbox: 0.0244  s0.loss_cls: 0.1895  s0.acc: 91.9434  s0.loss_bbox: 0.1035  s1.loss_cls: 0.0923  s1.acc: 94.4336  s1.loss_bbox: 0.0947  s2.loss_cls: 0.0435  s2.acc: 95.7520  s2.loss_bbox: 0.0528\n",
      "12/09 04:40:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 350/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:40:40  time: 0.3636  data_time: 0.0093  memory: 4054  grad_norm: 4.7970  loss: 0.6833  loss_rpn_cls: 0.0359  loss_rpn_bbox: 0.0281  s0.loss_cls: 0.2076  s0.acc: 92.9688  s0.loss_bbox: 0.1112  s1.loss_cls: 0.1000  s1.acc: 94.2703  s1.loss_bbox: 0.1002  s2.loss_cls: 0.0467  s2.acc: 94.5642  s2.loss_bbox: 0.0537\n",
      "12/09 04:41:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 400/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:40:22  time: 0.3604  data_time: 0.0102  memory: 4054  grad_norm: 4.9116  loss: 0.5843  loss_rpn_cls: 0.0351  loss_rpn_bbox: 0.0233  s0.loss_cls: 0.1764  s0.acc: 96.6309  s0.loss_bbox: 0.0935  s1.loss_cls: 0.0833  s1.acc: 94.6777  s1.loss_bbox: 0.0846  s2.loss_cls: 0.0402  s2.acc: 94.2383  s2.loss_bbox: 0.0479\n",
      "12/09 04:41:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 450/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:40:03  time: 0.3578  data_time: 0.0095  memory: 4053  grad_norm: 4.4571  loss: 0.5737  loss_rpn_cls: 0.0301  loss_rpn_bbox: 0.0210  s0.loss_cls: 0.1772  s0.acc: 99.3652  s0.loss_bbox: 0.0879  s1.loss_cls: 0.0849  s1.acc: 99.4629  s1.loss_bbox: 0.0848  s2.loss_cls: 0.0410  s2.acc: 99.5605  s2.loss_bbox: 0.0468\n",
      "12/09 04:41:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 500/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:39:45  time: 0.3561  data_time: 0.0095  memory: 4054  grad_norm: 4.5173  loss: 0.5970  loss_rpn_cls: 0.0307  loss_rpn_bbox: 0.0209  s0.loss_cls: 0.1805  s0.acc: 96.2402  s0.loss_bbox: 0.0992  s1.loss_cls: 0.0857  s1.acc: 97.0215  s1.loss_bbox: 0.0894  s2.loss_cls: 0.0402  s2.acc: 96.5332  s2.loss_bbox: 0.0504\n",
      "12/09 04:42:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 550/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:39:26  time: 0.3561  data_time: 0.0094  memory: 4053  grad_norm: 4.5792  loss: 0.6702  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.2070  s0.acc: 92.7734  s0.loss_bbox: 0.1055  s1.loss_cls: 0.1000  s1.acc: 92.0098  s1.loss_bbox: 0.0951  s2.loss_cls: 0.0469  s2.acc: 92.0962  s2.loss_bbox: 0.0511\n",
      "12/09 04:42:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 600/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:39:07  time: 0.3559  data_time: 0.0095  memory: 4054  grad_norm: 4.5475  loss: 0.6454  loss_rpn_cls: 0.0374  loss_rpn_bbox: 0.0240  s0.loss_cls: 0.1965  s0.acc: 96.0449  s0.loss_bbox: 0.1026  s1.loss_cls: 0.0923  s1.acc: 96.0101  s1.loss_bbox: 0.0948  s2.loss_cls: 0.0428  s2.acc: 96.8270  s2.loss_bbox: 0.0551\n",
      "12/09 04:42:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 650/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:38:48  time: 0.3553  data_time: 0.0093  memory: 4054  grad_norm: 4.3970  loss: 0.6517  loss_rpn_cls: 0.0380  loss_rpn_bbox: 0.0242  s0.loss_cls: 0.1974  s0.acc: 84.3750  s0.loss_bbox: 0.1041  s1.loss_cls: 0.0942  s1.acc: 84.8411  s1.loss_bbox: 0.0981  s2.loss_cls: 0.0433  s2.acc: 87.2985  s2.loss_bbox: 0.0523\n",
      "12/09 04:42:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 700/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:38:29  time: 0.3526  data_time: 0.0091  memory: 4053  grad_norm: 4.4049  loss: 0.6187  loss_rpn_cls: 0.0387  loss_rpn_bbox: 0.0246  s0.loss_cls: 0.1878  s0.acc: 96.5332  s0.loss_bbox: 0.0959  s1.loss_cls: 0.0909  s1.acc: 97.2656  s1.loss_bbox: 0.0874  s2.loss_cls: 0.0435  s2.acc: 96.2402  s2.loss_bbox: 0.0500\n",
      "12/09 04:43:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 750/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:38:11  time: 0.3607  data_time: 0.0093  memory: 4054  grad_norm: 4.5838  loss: 0.6368  loss_rpn_cls: 0.0299  loss_rpn_bbox: 0.0248  s0.loss_cls: 0.1974  s0.acc: 90.9668  s0.loss_bbox: 0.0983  s1.loss_cls: 0.0950  s1.acc: 90.4785  s1.loss_bbox: 0.0936  s2.loss_cls: 0.0448  s2.acc: 89.8926  s2.loss_bbox: 0.0530\n",
      "12/09 04:43:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 800/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:37:53  time: 0.3625  data_time: 0.0097  memory: 4054  grad_norm: 5.0247  loss: 0.6696  loss_rpn_cls: 0.0345  loss_rpn_bbox: 0.0223  s0.loss_cls: 0.2082  s0.acc: 91.9434  s0.loss_bbox: 0.1040  s1.loss_cls: 0.0999  s1.acc: 91.7969  s1.loss_bbox: 0.0977  s2.loss_cls: 0.0477  s2.acc: 92.0898  s2.loss_bbox: 0.0553\n",
      "12/09 04:43:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 850/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:37:35  time: 0.3584  data_time: 0.0095  memory: 4053  grad_norm: 5.6385  loss: 0.6620  loss_rpn_cls: 0.0412  loss_rpn_bbox: 0.0245  s0.loss_cls: 0.2007  s0.acc: 89.8926  s0.loss_bbox: 0.1073  s1.loss_cls: 0.0930  s1.acc: 92.7558  s1.loss_bbox: 0.0973  s2.loss_cls: 0.0433  s2.acc: 94.5152  s2.loss_bbox: 0.0546\n",
      "12/09 04:44:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 900/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:37:17  time: 0.3578  data_time: 0.0092  memory: 4054  grad_norm: 4.7491  loss: 0.6907  loss_rpn_cls: 0.0439  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.2111  s0.acc: 96.6797  s0.loss_bbox: 0.1101  s1.loss_cls: 0.0998  s1.acc: 95.8008  s1.loss_bbox: 0.0998  s2.loss_cls: 0.0458  s2.acc: 95.4590  s2.loss_bbox: 0.0529\n",
      "12/09 04:44:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 950/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:36:58  time: 0.3593  data_time: 0.0093  memory: 4054  grad_norm: 4.7791  loss: 0.6527  loss_rpn_cls: 0.0382  loss_rpn_bbox: 0.0276  s0.loss_cls: 0.1894  s0.acc: 93.9453  s0.loss_bbox: 0.1077  s1.loss_cls: 0.0899  s1.acc: 95.7905  s1.loss_bbox: 0.1000  s2.loss_cls: 0.0424  s2.acc: 95.6458  s2.loss_bbox: 0.0576\n",
      "12/09 04:44:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1000/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:36:40  time: 0.3586  data_time: 0.0092  memory: 4053  grad_norm: 5.0956  loss: 0.6173  loss_rpn_cls: 0.0298  loss_rpn_bbox: 0.0191  s0.loss_cls: 0.1905  s0.acc: 94.8730  s0.loss_bbox: 0.0988  s1.loss_cls: 0.0914  s1.acc: 94.5801  s1.loss_bbox: 0.0920  s2.loss_cls: 0.0435  s2.acc: 96.1426  s2.loss_bbox: 0.0522\n",
      "12/09 04:44:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1050/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:36:22  time: 0.3597  data_time: 0.0094  memory: 4053  grad_norm: 4.6953  loss: 0.6331  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0260  s0.loss_cls: 0.1958  s0.acc: 95.4590  s0.loss_bbox: 0.1013  s1.loss_cls: 0.0948  s1.acc: 93.9453  s1.loss_bbox: 0.0903  s2.loss_cls: 0.0438  s2.acc: 94.2871  s2.loss_bbox: 0.0491\n",
      "12/09 04:45:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1100/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:36:04  time: 0.3622  data_time: 0.0097  memory: 4054  grad_norm: 4.9946  loss: 0.6067  loss_rpn_cls: 0.0290  loss_rpn_bbox: 0.0189  s0.loss_cls: 0.1927  s0.acc: 97.1191  s0.loss_bbox: 0.0925  s1.loss_cls: 0.0938  s1.acc: 97.0215  s1.loss_bbox: 0.0864  s2.loss_cls: 0.0442  s2.acc: 97.5098  s2.loss_bbox: 0.0492\n",
      "12/09 04:45:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:45:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1150/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:35:46  time: 0.3603  data_time: 0.0097  memory: 4053  grad_norm: 5.1476  loss: 0.7746  loss_rpn_cls: 0.0485  loss_rpn_bbox: 0.0289  s0.loss_cls: 0.2306  s0.acc: 90.5273  s0.loss_bbox: 0.1241  s1.loss_cls: 0.1143  s1.acc: 89.7665  s1.loss_bbox: 0.1135  s2.loss_cls: 0.0543  s2.acc: 91.0314  s2.loss_bbox: 0.0606\n",
      "12/09 04:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1200/1221]  base_lr: 7.5250e-05 lr: 7.5250e-05  eta: 1:35:28  time: 0.3599  data_time: 0.0093  memory: 4054  grad_norm: 4.7138  loss: 0.5908  loss_rpn_cls: 0.0293  loss_rpn_bbox: 0.0230  s0.loss_cls: 0.1763  s0.acc: 90.0879  s0.loss_bbox: 0.0979  s1.loss_cls: 0.0851  s1.acc: 89.6973  s1.loss_bbox: 0.0889  s2.loss_cls: 0.0403  s2.acc: 90.1855  s2.loss_bbox: 0.0498\n",
      "12/09 04:46:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:46:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
      "12/09 04:46:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][  50/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:35:02  time: 0.3588  data_time: 0.0129  memory: 4054  grad_norm: 4.3819  loss: 0.5418  loss_rpn_cls: 0.0289  loss_rpn_bbox: 0.0199  s0.loss_cls: 0.1604  s0.acc: 90.1367  s0.loss_bbox: 0.0906  s1.loss_cls: 0.0748  s1.acc: 90.2716  s1.loss_bbox: 0.0830  s2.loss_cls: 0.0354  s2.acc: 92.5307  s2.loss_bbox: 0.0489\n",
      "12/09 04:46:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 100/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:34:44  time: 0.3586  data_time: 0.0096  memory: 4054  grad_norm: 4.7292  loss: 0.6267  loss_rpn_cls: 0.0325  loss_rpn_bbox: 0.0266  s0.loss_cls: 0.1821  s0.acc: 92.3340  s0.loss_bbox: 0.1073  s1.loss_cls: 0.0823  s1.acc: 93.5386  s1.loss_bbox: 0.0999  s2.loss_cls: 0.0388  s2.acc: 93.9165  s2.loss_bbox: 0.0572\n",
      "12/09 04:46:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 150/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:34:26  time: 0.3589  data_time: 0.0095  memory: 4054  grad_norm: 4.8293  loss: 0.5835  loss_rpn_cls: 0.0289  loss_rpn_bbox: 0.0218  s0.loss_cls: 0.1753  s0.acc: 92.4805  s0.loss_bbox: 0.0979  s1.loss_cls: 0.0813  s1.acc: 92.5037  s1.loss_bbox: 0.0893  s2.loss_cls: 0.0379  s2.acc: 91.5686  s2.loss_bbox: 0.0511\n",
      "12/09 04:47:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 200/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:34:07  time: 0.3552  data_time: 0.0094  memory: 4053  grad_norm: 4.9281  loss: 0.5942  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0228  s0.loss_cls: 0.1767  s0.acc: 96.5332  s0.loss_bbox: 0.0992  s1.loss_cls: 0.0802  s1.acc: 96.7157  s1.loss_bbox: 0.0944  s2.loss_cls: 0.0370  s2.acc: 96.8075  s2.loss_bbox: 0.0533\n",
      "12/09 04:47:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 250/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:33:48  time: 0.3552  data_time: 0.0094  memory: 4053  grad_norm: 5.0017  loss: 0.6806  loss_rpn_cls: 0.0308  loss_rpn_bbox: 0.0263  s0.loss_cls: 0.2017  s0.acc: 90.2344  s0.loss_bbox: 0.1196  s1.loss_cls: 0.0919  s1.acc: 90.4644  s1.loss_bbox: 0.1079  s2.loss_cls: 0.0433  s2.acc: 89.4815  s2.loss_bbox: 0.0591\n",
      "12/09 04:47:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 300/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:33:30  time: 0.3547  data_time: 0.0089  memory: 4053  grad_norm: 4.6797  loss: 0.5569  loss_rpn_cls: 0.0269  loss_rpn_bbox: 0.0207  s0.loss_cls: 0.1684  s0.acc: 90.2344  s0.loss_bbox: 0.0905  s1.loss_cls: 0.0819  s1.acc: 91.6957  s1.loss_bbox: 0.0824  s2.loss_cls: 0.0397  s2.acc: 92.0060  s2.loss_bbox: 0.0466\n",
      "12/09 04:48:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 350/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:33:11  time: 0.3558  data_time: 0.0093  memory: 4054  grad_norm: 5.4270  loss: 0.5617  loss_rpn_cls: 0.0273  loss_rpn_bbox: 0.0205  s0.loss_cls: 0.1719  s0.acc: 95.2637  s0.loss_bbox: 0.0874  s1.loss_cls: 0.0825  s1.acc: 95.0836  s1.loss_bbox: 0.0853  s2.loss_cls: 0.0387  s2.acc: 95.2358  s2.loss_bbox: 0.0481\n",
      "12/09 04:48:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 400/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:32:53  time: 0.3562  data_time: 0.0093  memory: 4054  grad_norm: 4.8650  loss: 0.5456  loss_rpn_cls: 0.0313  loss_rpn_bbox: 0.0221  s0.loss_cls: 0.1641  s0.acc: 92.3340  s0.loss_bbox: 0.0879  s1.loss_cls: 0.0755  s1.acc: 92.3828  s1.loss_bbox: 0.0811  s2.loss_cls: 0.0365  s2.acc: 93.3594  s2.loss_bbox: 0.0471\n",
      "12/09 04:48:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 450/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:32:34  time: 0.3546  data_time: 0.0093  memory: 4054  grad_norm: 4.3919  loss: 0.5376  loss_rpn_cls: 0.0255  loss_rpn_bbox: 0.0204  s0.loss_cls: 0.1589  s0.acc: 94.2871  s0.loss_bbox: 0.0917  s1.loss_cls: 0.0734  s1.acc: 94.4824  s1.loss_bbox: 0.0835  s2.loss_cls: 0.0349  s2.acc: 95.7031  s2.loss_bbox: 0.0494\n",
      "12/09 04:49:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 500/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:32:15  time: 0.3553  data_time: 0.0095  memory: 4053  grad_norm: 4.8099  loss: 0.5825  loss_rpn_cls: 0.0323  loss_rpn_bbox: 0.0213  s0.loss_cls: 0.1761  s0.acc: 95.8984  s0.loss_bbox: 0.0931  s1.loss_cls: 0.0837  s1.acc: 96.4110  s1.loss_bbox: 0.0862  s2.loss_cls: 0.0400  s2.acc: 96.3654  s2.loss_bbox: 0.0497\n",
      "12/09 04:49:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 550/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:31:57  time: 0.3576  data_time: 0.0097  memory: 4053  grad_norm: 4.7331  loss: 0.5873  loss_rpn_cls: 0.0321  loss_rpn_bbox: 0.0225  s0.loss_cls: 0.1754  s0.acc: 89.9414  s0.loss_bbox: 0.0944  s1.loss_cls: 0.0809  s1.acc: 89.9559  s1.loss_bbox: 0.0911  s2.loss_cls: 0.0388  s2.acc: 91.3320  s2.loss_bbox: 0.0520\n",
      "12/09 04:49:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 600/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:31:39  time: 0.3559  data_time: 0.0095  memory: 4054  grad_norm: 4.6099  loss: 0.5524  loss_rpn_cls: 0.0280  loss_rpn_bbox: 0.0214  s0.loss_cls: 0.1707  s0.acc: 93.7988  s0.loss_bbox: 0.0855  s1.loss_cls: 0.0823  s1.acc: 91.5271  s1.loss_bbox: 0.0807  s2.loss_cls: 0.0386  s2.acc: 91.5354  s2.loss_bbox: 0.0452\n",
      "12/09 04:49:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 650/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:31:20  time: 0.3593  data_time: 0.0095  memory: 4054  grad_norm: 4.7443  loss: 0.6855  loss_rpn_cls: 0.0362  loss_rpn_bbox: 0.0264  s0.loss_cls: 0.2076  s0.acc: 90.2344  s0.loss_bbox: 0.1136  s1.loss_cls: 0.0966  s1.acc: 91.5975  s1.loss_bbox: 0.1011  s2.loss_cls: 0.0458  s2.acc: 92.0371  s2.loss_bbox: 0.0581\n",
      "12/09 04:50:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 700/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:31:02  time: 0.3572  data_time: 0.0096  memory: 4053  grad_norm: 4.8192  loss: 0.6477  loss_rpn_cls: 0.0350  loss_rpn_bbox: 0.0287  s0.loss_cls: 0.1911  s0.acc: 98.1934  s0.loss_bbox: 0.1083  s1.loss_cls: 0.0899  s1.acc: 97.3145  s1.loss_bbox: 0.0991  s2.loss_cls: 0.0420  s2.acc: 96.7773  s2.loss_bbox: 0.0536\n",
      "12/09 04:50:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 750/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:30:44  time: 0.3578  data_time: 0.0098  memory: 4053  grad_norm: 4.9789  loss: 0.5786  loss_rpn_cls: 0.0279  loss_rpn_bbox: 0.0213  s0.loss_cls: 0.1741  s0.acc: 95.8984  s0.loss_bbox: 0.0960  s1.loss_cls: 0.0826  s1.acc: 94.5801  s1.loss_bbox: 0.0891  s2.loss_cls: 0.0388  s2.acc: 92.4316  s2.loss_bbox: 0.0489\n",
      "12/09 04:50:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 800/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:30:25  time: 0.3556  data_time: 0.0095  memory: 4053  grad_norm: 4.5955  loss: 0.5859  loss_rpn_cls: 0.0303  loss_rpn_bbox: 0.0219  s0.loss_cls: 0.1748  s0.acc: 94.5312  s0.loss_bbox: 0.0994  s1.loss_cls: 0.0801  s1.acc: 96.1809  s1.loss_bbox: 0.0901  s2.loss_cls: 0.0382  s2.acc: 96.4718  s2.loss_bbox: 0.0511\n",
      "12/09 04:51:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 850/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:30:07  time: 0.3588  data_time: 0.0097  memory: 4053  grad_norm: 4.7719  loss: 0.6802  loss_rpn_cls: 0.0354  loss_rpn_bbox: 0.0267  s0.loss_cls: 0.2081  s0.acc: 92.8223  s0.loss_bbox: 0.1102  s1.loss_cls: 0.0984  s1.acc: 92.9676  s1.loss_bbox: 0.0996  s2.loss_cls: 0.0460  s2.acc: 91.2525  s2.loss_bbox: 0.0557\n",
      "12/09 04:51:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:51:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 900/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:29:49  time: 0.3579  data_time: 0.0097  memory: 4054  grad_norm: 4.6204  loss: 0.5840  loss_rpn_cls: 0.0349  loss_rpn_bbox: 0.0237  s0.loss_cls: 0.1736  s0.acc: 97.0703  s0.loss_bbox: 0.0968  s1.loss_cls: 0.0800  s1.acc: 97.0215  s1.loss_bbox: 0.0876  s2.loss_cls: 0.0379  s2.acc: 96.2891  s2.loss_bbox: 0.0495\n",
      "12/09 04:51:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 950/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:29:31  time: 0.3574  data_time: 0.0094  memory: 4053  grad_norm: 4.7599  loss: 0.5225  loss_rpn_cls: 0.0241  loss_rpn_bbox: 0.0188  s0.loss_cls: 0.1574  s0.acc: 95.4102  s0.loss_bbox: 0.0889  s1.loss_cls: 0.0722  s1.acc: 95.1172  s1.loss_bbox: 0.0802  s2.loss_cls: 0.0351  s2.acc: 95.8008  s2.loss_bbox: 0.0460\n",
      "12/09 04:52:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1000/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:29:13  time: 0.3640  data_time: 0.0095  memory: 4054  grad_norm: 5.0473  loss: 0.6661  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0238  s0.loss_cls: 0.2035  s0.acc: 91.1133  s0.loss_bbox: 0.1084  s1.loss_cls: 0.0979  s1.acc: 89.6484  s1.loss_bbox: 0.0996  s2.loss_cls: 0.0464  s2.acc: 89.5020  s2.loss_bbox: 0.0544\n",
      "12/09 04:52:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1050/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:28:55  time: 0.3551  data_time: 0.0091  memory: 4054  grad_norm: 4.4497  loss: 0.5509  loss_rpn_cls: 0.0277  loss_rpn_bbox: 0.0210  s0.loss_cls: 0.1630  s0.acc: 94.4824  s0.loss_bbox: 0.0894  s1.loss_cls: 0.0780  s1.acc: 94.7728  s1.loss_bbox: 0.0846  s2.loss_cls: 0.0369  s2.acc: 95.3125  s2.loss_bbox: 0.0503\n",
      "12/09 04:52:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1100/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:28:37  time: 0.3578  data_time: 0.0095  memory: 4054  grad_norm: 4.6381  loss: 0.5948  loss_rpn_cls: 0.0274  loss_rpn_bbox: 0.0207  s0.loss_cls: 0.1864  s0.acc: 97.8027  s0.loss_bbox: 0.0917  s1.loss_cls: 0.0882  s1.acc: 96.3379  s1.loss_bbox: 0.0862  s2.loss_cls: 0.0425  s2.acc: 96.5332  s2.loss_bbox: 0.0517\n",
      "12/09 04:52:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1150/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:28:19  time: 0.3638  data_time: 0.0099  memory: 4054  grad_norm: 4.6698  loss: 0.5336  loss_rpn_cls: 0.0268  loss_rpn_bbox: 0.0187  s0.loss_cls: 0.1620  s0.acc: 99.0723  s0.loss_bbox: 0.0847  s1.loss_cls: 0.0765  s1.acc: 99.4141  s1.loss_bbox: 0.0807  s2.loss_cls: 0.0367  s2.acc: 99.7070  s2.loss_bbox: 0.0475\n",
      "12/09 04:53:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1200/1221]  base_lr: 6.3312e-05 lr: 6.3312e-05  eta: 1:28:01  time: 0.3582  data_time: 0.0095  memory: 4054  grad_norm: 4.9909  loss: 0.5861  loss_rpn_cls: 0.0284  loss_rpn_bbox: 0.0238  s0.loss_cls: 0.1771  s0.acc: 96.8750  s0.loss_bbox: 0.0924  s1.loss_cls: 0.0829  s1.acc: 97.2656  s1.loss_bbox: 0.0881  s2.loss_cls: 0.0397  s2.acc: 97.5098  s2.loss_bbox: 0.0537\n",
      "12/09 04:53:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:53:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
      "12/09 04:53:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][  50/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:27:35  time: 0.3623  data_time: 0.0136  memory: 4054  grad_norm: 4.3256  loss: 0.5800  loss_rpn_cls: 0.0305  loss_rpn_bbox: 0.0246  s0.loss_cls: 0.1689  s0.acc: 97.2656  s0.loss_bbox: 0.0982  s1.loss_cls: 0.0806  s1.acc: 97.1527  s1.loss_bbox: 0.0896  s2.loss_cls: 0.0387  s2.acc: 97.7418  s2.loss_bbox: 0.0489\n",
      "12/09 04:53:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 100/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:27:17  time: 0.3623  data_time: 0.0094  memory: 4054  grad_norm: 4.4187  loss: 0.5684  loss_rpn_cls: 0.0309  loss_rpn_bbox: 0.0210  s0.loss_cls: 0.1676  s0.acc: 91.8945  s0.loss_bbox: 0.0958  s1.loss_cls: 0.0761  s1.acc: 94.9729  s1.loss_bbox: 0.0889  s2.loss_cls: 0.0361  s2.acc: 94.4444  s2.loss_bbox: 0.0520\n",
      "12/09 04:54:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 150/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:26:59  time: 0.3593  data_time: 0.0098  memory: 4053  grad_norm: 4.1471  loss: 0.5113  loss_rpn_cls: 0.0255  loss_rpn_bbox: 0.0210  s0.loss_cls: 0.1527  s0.acc: 98.2910  s0.loss_bbox: 0.0874  s1.loss_cls: 0.0674  s1.acc: 98.9258  s1.loss_bbox: 0.0797  s2.loss_cls: 0.0318  s2.acc: 98.9258  s2.loss_bbox: 0.0460\n",
      "12/09 04:54:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 200/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:26:41  time: 0.3547  data_time: 0.0094  memory: 4054  grad_norm: 4.9345  loss: 0.5681  loss_rpn_cls: 0.0283  loss_rpn_bbox: 0.0204  s0.loss_cls: 0.1689  s0.acc: 93.3594  s0.loss_bbox: 0.0968  s1.loss_cls: 0.0757  s1.acc: 92.8887  s1.loss_bbox: 0.0880  s2.loss_cls: 0.0359  s2.acc: 93.6796  s2.loss_bbox: 0.0541\n",
      "12/09 04:54:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 250/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:26:23  time: 0.3584  data_time: 0.0094  memory: 4053  grad_norm: 4.9678  loss: 0.5903  loss_rpn_cls: 0.0312  loss_rpn_bbox: 0.0223  s0.loss_cls: 0.1738  s0.acc: 95.0684  s0.loss_bbox: 0.0986  s1.loss_cls: 0.0783  s1.acc: 95.1039  s1.loss_bbox: 0.0937  s2.loss_cls: 0.0369  s2.acc: 94.8807  s2.loss_bbox: 0.0555\n",
      "12/09 04:55:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 300/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:26:05  time: 0.3598  data_time: 0.0096  memory: 4054  grad_norm: 4.7550  loss: 0.5175  loss_rpn_cls: 0.0272  loss_rpn_bbox: 0.0212  s0.loss_cls: 0.1529  s0.acc: 99.2188  s0.loss_bbox: 0.0850  s1.loss_cls: 0.0700  s1.acc: 99.3652  s1.loss_bbox: 0.0796  s2.loss_cls: 0.0335  s2.acc: 99.7559  s2.loss_bbox: 0.0481\n",
      "12/09 04:55:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 350/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:25:47  time: 0.3583  data_time: 0.0094  memory: 4053  grad_norm: 4.9604  loss: 0.5102  loss_rpn_cls: 0.0225  loss_rpn_bbox: 0.0208  s0.loss_cls: 0.1457  s0.acc: 89.1113  s0.loss_bbox: 0.0867  s1.loss_cls: 0.0688  s1.acc: 89.1892  s1.loss_bbox: 0.0840  s2.loss_cls: 0.0338  s2.acc: 90.8198  s2.loss_bbox: 0.0479\n",
      "12/09 04:55:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 400/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:25:28  time: 0.3571  data_time: 0.0096  memory: 4054  grad_norm: 5.1010  loss: 0.5760  loss_rpn_cls: 0.0250  loss_rpn_bbox: 0.0207  s0.loss_cls: 0.1708  s0.acc: 98.3887  s0.loss_bbox: 0.0943  s1.loss_cls: 0.0800  s1.acc: 97.8516  s1.loss_bbox: 0.0924  s2.loss_cls: 0.0380  s2.acc: 97.6562  s2.loss_bbox: 0.0548\n",
      "12/09 04:56:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 450/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:25:10  time: 0.3560  data_time: 0.0096  memory: 4054  grad_norm: 4.6235  loss: 0.5057  loss_rpn_cls: 0.0223  loss_rpn_bbox: 0.0211  s0.loss_cls: 0.1440  s0.acc: 96.9727  s0.loss_bbox: 0.0885  s1.loss_cls: 0.0659  s1.acc: 96.2891  s1.loss_bbox: 0.0824  s2.loss_cls: 0.0312  s2.acc: 97.1191  s2.loss_bbox: 0.0503\n",
      "12/09 04:56:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 500/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:24:51  time: 0.3542  data_time: 0.0092  memory: 4054  grad_norm: 4.3480  loss: 0.4799  loss_rpn_cls: 0.0213  loss_rpn_bbox: 0.0183  s0.loss_cls: 0.1374  s0.acc: 95.5566  s0.loss_bbox: 0.0815  s1.loss_cls: 0.0629  s1.acc: 97.3633  s1.loss_bbox: 0.0809  s2.loss_cls: 0.0302  s2.acc: 96.8262  s2.loss_bbox: 0.0474\n",
      "12/09 04:56:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 550/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:24:33  time: 0.3553  data_time: 0.0098  memory: 4053  grad_norm: 4.4491  loss: 0.4925  loss_rpn_cls: 0.0240  loss_rpn_bbox: 0.0209  s0.loss_cls: 0.1428  s0.acc: 95.5566  s0.loss_bbox: 0.0829  s1.loss_cls: 0.0652  s1.acc: 95.3125  s1.loss_bbox: 0.0798  s2.loss_cls: 0.0314  s2.acc: 96.3379  s2.loss_bbox: 0.0455\n",
      "12/09 04:56:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 600/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:24:15  time: 0.3548  data_time: 0.0096  memory: 4054  grad_norm: 4.5630  loss: 0.5486  loss_rpn_cls: 0.0295  loss_rpn_bbox: 0.0229  s0.loss_cls: 0.1588  s0.acc: 95.8008  s0.loss_bbox: 0.0951  s1.loss_cls: 0.0724  s1.acc: 96.0449  s1.loss_bbox: 0.0873  s2.loss_cls: 0.0339  s2.acc: 96.8262  s2.loss_bbox: 0.0487\n",
      "12/09 04:57:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 650/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:23:56  time: 0.3567  data_time: 0.0095  memory: 4054  grad_norm: 4.7539  loss: 0.5496  loss_rpn_cls: 0.0263  loss_rpn_bbox: 0.0189  s0.loss_cls: 0.1613  s0.acc: 87.9883  s0.loss_bbox: 0.0971  s1.loss_cls: 0.0730  s1.acc: 91.5385  s1.loss_bbox: 0.0887  s2.loss_cls: 0.0340  s2.acc: 92.5090  s2.loss_bbox: 0.0502\n",
      "12/09 04:57:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 04:57:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 700/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:23:38  time: 0.3573  data_time: 0.0098  memory: 4053  grad_norm: 4.5595  loss: 0.5344  loss_rpn_cls: 0.0247  loss_rpn_bbox: 0.0226  s0.loss_cls: 0.1560  s0.acc: 89.5996  s0.loss_bbox: 0.0905  s1.loss_cls: 0.0725  s1.acc: 89.3564  s1.loss_bbox: 0.0849  s2.loss_cls: 0.0347  s2.acc: 90.3114  s2.loss_bbox: 0.0486\n",
      "12/09 04:57:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 750/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:23:20  time: 0.3532  data_time: 0.0094  memory: 4054  grad_norm: 4.4998  loss: 0.5274  loss_rpn_cls: 0.0244  loss_rpn_bbox: 0.0213  s0.loss_cls: 0.1512  s0.acc: 97.4609  s0.loss_bbox: 0.0906  s1.loss_cls: 0.0688  s1.acc: 96.6309  s1.loss_bbox: 0.0864  s2.loss_cls: 0.0329  s2.acc: 96.1426  s2.loss_bbox: 0.0518\n",
      "12/09 04:58:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 800/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:23:01  time: 0.3549  data_time: 0.0096  memory: 4054  grad_norm: 4.9328  loss: 0.5853  loss_rpn_cls: 0.0299  loss_rpn_bbox: 0.0210  s0.loss_cls: 0.1748  s0.acc: 93.6523  s0.loss_bbox: 0.0976  s1.loss_cls: 0.0797  s1.acc: 93.5547  s1.loss_bbox: 0.0909  s2.loss_cls: 0.0376  s2.acc: 93.9453  s2.loss_bbox: 0.0538\n",
      "12/09 04:58:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 850/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:22:43  time: 0.3581  data_time: 0.0099  memory: 4053  grad_norm: 4.2142  loss: 0.4687  loss_rpn_cls: 0.0249  loss_rpn_bbox: 0.0181  s0.loss_cls: 0.1411  s0.acc: 96.0449  s0.loss_bbox: 0.0779  s1.loss_cls: 0.0638  s1.acc: 96.6766  s1.loss_bbox: 0.0717  s2.loss_cls: 0.0293  s2.acc: 96.7790  s2.loss_bbox: 0.0419\n",
      "12/09 04:58:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 900/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:22:25  time: 0.3552  data_time: 0.0097  memory: 4054  grad_norm: 4.4542  loss: 0.5283  loss_rpn_cls: 0.0307  loss_rpn_bbox: 0.0237  s0.loss_cls: 0.1563  s0.acc: 91.0645  s0.loss_bbox: 0.0867  s1.loss_cls: 0.0707  s1.acc: 90.9180  s1.loss_bbox: 0.0798  s2.loss_cls: 0.0332  s2.acc: 90.6250  s2.loss_bbox: 0.0471\n",
      "12/09 04:59:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 950/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:22:07  time: 0.3576  data_time: 0.0101  memory: 4053  grad_norm: 4.6690  loss: 0.5152  loss_rpn_cls: 0.0268  loss_rpn_bbox: 0.0206  s0.loss_cls: 0.1506  s0.acc: 95.1660  s0.loss_bbox: 0.0883  s1.loss_cls: 0.0683  s1.acc: 96.3867  s1.loss_bbox: 0.0815  s2.loss_cls: 0.0321  s2.acc: 94.9219  s2.loss_bbox: 0.0469\n",
      "12/09 04:59:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1000/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:21:48  time: 0.3557  data_time: 0.0099  memory: 4054  grad_norm: 4.6204  loss: 0.5251  loss_rpn_cls: 0.0250  loss_rpn_bbox: 0.0191  s0.loss_cls: 0.1564  s0.acc: 91.1133  s0.loss_bbox: 0.0854  s1.loss_cls: 0.0733  s1.acc: 91.4809  s1.loss_bbox: 0.0814  s2.loss_cls: 0.0349  s2.acc: 92.1782  s2.loss_bbox: 0.0495\n",
      "12/09 04:59:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1050/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:21:30  time: 0.3568  data_time: 0.0097  memory: 4053  grad_norm: 4.5450  loss: 0.4868  loss_rpn_cls: 0.0239  loss_rpn_bbox: 0.0178  s0.loss_cls: 0.1396  s0.acc: 96.6309  s0.loss_bbox: 0.0824  s1.loss_cls: 0.0638  s1.acc: 95.9473  s1.loss_bbox: 0.0798  s2.loss_cls: 0.0310  s2.acc: 95.6543  s2.loss_bbox: 0.0483\n",
      "12/09 04:59:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1100/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:21:12  time: 0.3548  data_time: 0.0093  memory: 4053  grad_norm: 4.6633  loss: 0.5101  loss_rpn_cls: 0.0239  loss_rpn_bbox: 0.0219  s0.loss_cls: 0.1486  s0.acc: 98.6328  s0.loss_bbox: 0.0873  s1.loss_cls: 0.0694  s1.acc: 98.9746  s1.loss_bbox: 0.0791  s2.loss_cls: 0.0331  s2.acc: 99.1211  s2.loss_bbox: 0.0468\n",
      "12/09 05:00:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1150/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:20:54  time: 0.3561  data_time: 0.0096  memory: 4054  grad_norm: 4.3781  loss: 0.5406  loss_rpn_cls: 0.0289  loss_rpn_bbox: 0.0219  s0.loss_cls: 0.1591  s0.acc: 95.1172  s0.loss_bbox: 0.0920  s1.loss_cls: 0.0712  s1.acc: 96.1084  s1.loss_bbox: 0.0843  s2.loss_cls: 0.0332  s2.acc: 95.8580  s2.loss_bbox: 0.0500\n",
      "12/09 05:00:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1200/1221]  base_lr: 5.0500e-05 lr: 5.0500e-05  eta: 1:20:36  time: 0.3592  data_time: 0.0095  memory: 4054  grad_norm: 4.6042  loss: 0.6119  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0259  s0.loss_cls: 0.1731  s0.acc: 89.0137  s0.loss_bbox: 0.1082  s1.loss_cls: 0.0793  s1.acc: 88.5040  s1.loss_bbox: 0.0995  s2.loss_cls: 0.0385  s2.acc: 90.8726  s2.loss_bbox: 0.0553\n",
      "12/09 05:00:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:00:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 7 epochs\n",
      "12/09 05:01:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][  50/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:20:10  time: 0.3617  data_time: 0.0126  memory: 4054  grad_norm: 4.5005  loss: 0.5559  loss_rpn_cls: 0.0282  loss_rpn_bbox: 0.0224  s0.loss_cls: 0.1612  s0.acc: 94.8242  s0.loss_bbox: 0.0989  s1.loss_cls: 0.0719  s1.acc: 95.8984  s1.loss_bbox: 0.0900  s2.loss_cls: 0.0332  s2.acc: 96.2402  s2.loss_bbox: 0.0500\n",
      "12/09 05:01:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 100/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:19:52  time: 0.3586  data_time: 0.0096  memory: 4053  grad_norm: 4.5749  loss: 0.4888  loss_rpn_cls: 0.0243  loss_rpn_bbox: 0.0185  s0.loss_cls: 0.1418  s0.acc: 94.5312  s0.loss_bbox: 0.0842  s1.loss_cls: 0.0622  s1.acc: 95.8167  s1.loss_bbox: 0.0803  s2.loss_cls: 0.0294  s2.acc: 95.8707  s2.loss_bbox: 0.0481\n",
      "12/09 05:01:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 150/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:19:34  time: 0.3562  data_time: 0.0093  memory: 4054  grad_norm: 4.3828  loss: 0.4769  loss_rpn_cls: 0.0230  loss_rpn_bbox: 0.0196  s0.loss_cls: 0.1409  s0.acc: 98.1934  s0.loss_bbox: 0.0824  s1.loss_cls: 0.0620  s1.acc: 98.6159  s1.loss_bbox: 0.0773  s2.loss_cls: 0.0286  s2.acc: 99.7515  s2.loss_bbox: 0.0430\n",
      "12/09 05:01:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 200/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:19:16  time: 0.3585  data_time: 0.0092  memory: 4054  grad_norm: 3.9227  loss: 0.4398  loss_rpn_cls: 0.0246  loss_rpn_bbox: 0.0182  s0.loss_cls: 0.1286  s0.acc: 97.1680  s0.loss_bbox: 0.0729  s1.loss_cls: 0.0570  s1.acc: 97.2168  s1.loss_bbox: 0.0696  s2.loss_cls: 0.0269  s2.acc: 97.8027  s2.loss_bbox: 0.0421\n",
      "12/09 05:02:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 250/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:18:58  time: 0.3626  data_time: 0.0096  memory: 4054  grad_norm: 4.7684  loss: 0.4711  loss_rpn_cls: 0.0220  loss_rpn_bbox: 0.0175  s0.loss_cls: 0.1356  s0.acc: 98.8281  s0.loss_bbox: 0.0830  s1.loss_cls: 0.0610  s1.acc: 99.7070  s1.loss_bbox: 0.0778  s2.loss_cls: 0.0288  s2.acc: 99.7070  s2.loss_bbox: 0.0456\n",
      "12/09 05:02:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 300/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:18:40  time: 0.3587  data_time: 0.0097  memory: 4054  grad_norm: 4.4895  loss: 0.4743  loss_rpn_cls: 0.0217  loss_rpn_bbox: 0.0202  s0.loss_cls: 0.1348  s0.acc: 95.5078  s0.loss_bbox: 0.0831  s1.loss_cls: 0.0609  s1.acc: 96.2891  s1.loss_bbox: 0.0783  s2.loss_cls: 0.0286  s2.acc: 96.2891  s2.loss_bbox: 0.0468\n",
      "12/09 05:02:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 350/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:18:22  time: 0.3559  data_time: 0.0096  memory: 4053  grad_norm: 4.3343  loss: 0.4890  loss_rpn_cls: 0.0253  loss_rpn_bbox: 0.0212  s0.loss_cls: 0.1400  s0.acc: 99.3652  s0.loss_bbox: 0.0871  s1.loss_cls: 0.0621  s1.acc: 99.6094  s1.loss_bbox: 0.0789  s2.loss_cls: 0.0281  s2.acc: 99.7070  s2.loss_bbox: 0.0463\n",
      "12/09 05:03:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 400/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:18:03  time: 0.3549  data_time: 0.0094  memory: 4054  grad_norm: 4.2114  loss: 0.4282  loss_rpn_cls: 0.0177  loss_rpn_bbox: 0.0172  s0.loss_cls: 0.1225  s0.acc: 88.3301  s0.loss_bbox: 0.0736  s1.loss_cls: 0.0545  s1.acc: 90.5913  s1.loss_bbox: 0.0720  s2.loss_cls: 0.0265  s2.acc: 92.3755  s2.loss_bbox: 0.0443\n",
      "12/09 05:03:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 450/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:17:45  time: 0.3591  data_time: 0.0101  memory: 4054  grad_norm: 4.5799  loss: 0.5309  loss_rpn_cls: 0.0256  loss_rpn_bbox: 0.0212  s0.loss_cls: 0.1520  s0.acc: 94.3359  s0.loss_bbox: 0.0931  s1.loss_cls: 0.0709  s1.acc: 95.1039  s1.loss_bbox: 0.0842  s2.loss_cls: 0.0336  s2.acc: 94.8743  s2.loss_bbox: 0.0503\n",
      "12/09 05:03:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:03:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 500/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:17:27  time: 0.3566  data_time: 0.0096  memory: 4054  grad_norm: 4.7211  loss: 0.4786  loss_rpn_cls: 0.0225  loss_rpn_bbox: 0.0187  s0.loss_cls: 0.1365  s0.acc: 94.7754  s0.loss_bbox: 0.0814  s1.loss_cls: 0.0605  s1.acc: 95.5512  s1.loss_bbox: 0.0811  s2.loss_cls: 0.0297  s2.acc: 95.5556  s2.loss_bbox: 0.0481\n",
      "12/09 05:03:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 550/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:17:09  time: 0.3554  data_time: 0.0093  memory: 4054  grad_norm: 4.8707  loss: 0.5142  loss_rpn_cls: 0.0250  loss_rpn_bbox: 0.0193  s0.loss_cls: 0.1472  s0.acc: 98.2910  s0.loss_bbox: 0.0894  s1.loss_cls: 0.0672  s1.acc: 97.2168  s1.loss_bbox: 0.0841  s2.loss_cls: 0.0316  s2.acc: 96.7285  s2.loss_bbox: 0.0503\n",
      "12/09 05:04:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 600/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:16:51  time: 0.3560  data_time: 0.0094  memory: 4053  grad_norm: 4.9029  loss: 0.5688  loss_rpn_cls: 0.0282  loss_rpn_bbox: 0.0235  s0.loss_cls: 0.1645  s0.acc: 93.1641  s0.loss_bbox: 0.1022  s1.loss_cls: 0.0733  s1.acc: 95.0990  s1.loss_bbox: 0.0906  s2.loss_cls: 0.0346  s2.acc: 96.5808  s2.loss_bbox: 0.0520\n",
      "12/09 05:04:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 650/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:16:33  time: 0.3567  data_time: 0.0097  memory: 4053  grad_norm: 4.5434  loss: 0.5193  loss_rpn_cls: 0.0253  loss_rpn_bbox: 0.0202  s0.loss_cls: 0.1494  s0.acc: 98.4863  s0.loss_bbox: 0.0901  s1.loss_cls: 0.0667  s1.acc: 99.2676  s1.loss_bbox: 0.0855  s2.loss_cls: 0.0307  s2.acc: 99.5605  s2.loss_bbox: 0.0513\n",
      "12/09 05:04:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 700/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:16:15  time: 0.3581  data_time: 0.0099  memory: 4053  grad_norm: 4.4164  loss: 0.4340  loss_rpn_cls: 0.0203  loss_rpn_bbox: 0.0185  s0.loss_cls: 0.1233  s0.acc: 97.4121  s0.loss_bbox: 0.0745  s1.loss_cls: 0.0551  s1.acc: 96.9727  s1.loss_bbox: 0.0723  s2.loss_cls: 0.0263  s2.acc: 96.7285  s2.loss_bbox: 0.0437\n",
      "12/09 05:05:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 750/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:15:56  time: 0.3568  data_time: 0.0095  memory: 4054  grad_norm: 4.3186  loss: 0.5222  loss_rpn_cls: 0.0247  loss_rpn_bbox: 0.0240  s0.loss_cls: 0.1467  s0.acc: 90.4785  s0.loss_bbox: 0.0929  s1.loss_cls: 0.0678  s1.acc: 92.0898  s1.loss_bbox: 0.0849  s2.loss_cls: 0.0324  s2.acc: 93.9941  s2.loss_bbox: 0.0489\n",
      "12/09 05:05:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 800/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:15:38  time: 0.3576  data_time: 0.0093  memory: 4053  grad_norm: 4.4596  loss: 0.4928  loss_rpn_cls: 0.0210  loss_rpn_bbox: 0.0205  s0.loss_cls: 0.1452  s0.acc: 94.6777  s0.loss_bbox: 0.0837  s1.loss_cls: 0.0644  s1.acc: 96.2890  s1.loss_bbox: 0.0817  s2.loss_cls: 0.0303  s2.acc: 96.2339  s2.loss_bbox: 0.0460\n",
      "12/09 05:05:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 850/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:15:20  time: 0.3602  data_time: 0.0097  memory: 4054  grad_norm: 4.4706  loss: 0.4929  loss_rpn_cls: 0.0245  loss_rpn_bbox: 0.0195  s0.loss_cls: 0.1406  s0.acc: 93.2617  s0.loss_bbox: 0.0840  s1.loss_cls: 0.0644  s1.acc: 93.9409  s1.loss_bbox: 0.0806  s2.loss_cls: 0.0311  s2.acc: 93.2053  s2.loss_bbox: 0.0482\n",
      "12/09 05:06:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 900/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:15:02  time: 0.3579  data_time: 0.0101  memory: 4053  grad_norm: 4.4638  loss: 0.4963  loss_rpn_cls: 0.0266  loss_rpn_bbox: 0.0235  s0.loss_cls: 0.1427  s0.acc: 93.1152  s0.loss_bbox: 0.0844  s1.loss_cls: 0.0650  s1.acc: 93.0176  s1.loss_bbox: 0.0785  s2.loss_cls: 0.0310  s2.acc: 95.2148  s2.loss_bbox: 0.0446\n",
      "12/09 05:06:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 950/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:14:44  time: 0.3576  data_time: 0.0097  memory: 4053  grad_norm: 4.6911  loss: 0.5258  loss_rpn_cls: 0.0265  loss_rpn_bbox: 0.0199  s0.loss_cls: 0.1528  s0.acc: 91.7480  s0.loss_bbox: 0.0925  s1.loss_cls: 0.0672  s1.acc: 92.5689  s1.loss_bbox: 0.0852  s2.loss_cls: 0.0311  s2.acc: 92.9204  s2.loss_bbox: 0.0504\n",
      "12/09 05:06:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1000/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:14:26  time: 0.3549  data_time: 0.0096  memory: 4054  grad_norm: 4.5036  loss: 0.4819  loss_rpn_cls: 0.0226  loss_rpn_bbox: 0.0186  s0.loss_cls: 0.1425  s0.acc: 96.3867  s0.loss_bbox: 0.0810  s1.loss_cls: 0.0646  s1.acc: 96.5686  s1.loss_bbox: 0.0771  s2.loss_cls: 0.0312  s2.acc: 96.9118  s2.loss_bbox: 0.0443\n",
      "12/09 05:06:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1050/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:14:08  time: 0.3555  data_time: 0.0092  memory: 4053  grad_norm: 4.4519  loss: 0.4561  loss_rpn_cls: 0.0226  loss_rpn_bbox: 0.0187  s0.loss_cls: 0.1349  s0.acc: 96.4844  s0.loss_bbox: 0.0764  s1.loss_cls: 0.0597  s1.acc: 97.2759  s1.loss_bbox: 0.0710  s2.loss_cls: 0.0288  s2.acc: 97.0471  s2.loss_bbox: 0.0440\n",
      "12/09 05:07:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1100/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:13:50  time: 0.3566  data_time: 0.0101  memory: 4054  grad_norm: 4.1883  loss: 0.4516  loss_rpn_cls: 0.0221  loss_rpn_bbox: 0.0189  s0.loss_cls: 0.1313  s0.acc: 95.0684  s0.loss_bbox: 0.0782  s1.loss_cls: 0.0582  s1.acc: 95.2637  s1.loss_bbox: 0.0720  s2.loss_cls: 0.0276  s2.acc: 96.5820  s2.loss_bbox: 0.0434\n",
      "12/09 05:07:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1150/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:13:32  time: 0.3596  data_time: 0.0098  memory: 4054  grad_norm: 4.4325  loss: 0.4629  loss_rpn_cls: 0.0224  loss_rpn_bbox: 0.0183  s0.loss_cls: 0.1311  s0.acc: 97.9980  s0.loss_bbox: 0.0799  s1.loss_cls: 0.0593  s1.acc: 98.6328  s1.loss_bbox: 0.0763  s2.loss_cls: 0.0288  s2.acc: 97.5098  s2.loss_bbox: 0.0468\n",
      "12/09 05:07:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1200/1221]  base_lr: 3.7688e-05 lr: 3.7688e-05  eta: 1:13:14  time: 0.3585  data_time: 0.0098  memory: 4054  grad_norm: 5.4013  loss: 0.5806  loss_rpn_cls: 0.0248  loss_rpn_bbox: 0.0247  s0.loss_cls: 0.1625  s0.acc: 92.1875  s0.loss_bbox: 0.1006  s1.loss_cls: 0.0747  s1.acc: 93.3400  s1.loss_bbox: 0.0992  s2.loss_cls: 0.0356  s2.acc: 95.6784  s2.loss_bbox: 0.0585\n",
      "12/09 05:07:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:07:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 8 epochs\n",
      "12/09 05:08:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][  50/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:12:48  time: 0.3604  data_time: 0.0135  memory: 4053  grad_norm: 4.7260  loss: 0.5158  loss_rpn_cls: 0.0235  loss_rpn_bbox: 0.0208  s0.loss_cls: 0.1479  s0.acc: 96.6309  s0.loss_bbox: 0.0939  s1.loss_cls: 0.0655  s1.acc: 96.9200  s1.loss_bbox: 0.0847  s2.loss_cls: 0.0300  s2.acc: 97.0500  s2.loss_bbox: 0.0496\n",
      "12/09 05:08:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 100/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:12:30  time: 0.3567  data_time: 0.0099  memory: 4054  grad_norm: 4.5837  loss: 0.4544  loss_rpn_cls: 0.0201  loss_rpn_bbox: 0.0203  s0.loss_cls: 0.1291  s0.acc: 92.9688  s0.loss_bbox: 0.0817  s1.loss_cls: 0.0562  s1.acc: 92.9199  s1.loss_bbox: 0.0751  s2.loss_cls: 0.0266  s2.acc: 94.6777  s2.loss_bbox: 0.0453\n",
      "12/09 05:08:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 150/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:12:12  time: 0.3539  data_time: 0.0096  memory: 4053  grad_norm: 4.3307  loss: 0.4343  loss_rpn_cls: 0.0193  loss_rpn_bbox: 0.0178  s0.loss_cls: 0.1215  s0.acc: 91.4551  s0.loss_bbox: 0.0759  s1.loss_cls: 0.0536  s1.acc: 93.3738  s1.loss_bbox: 0.0731  s2.loss_cls: 0.0262  s2.acc: 92.8571  s2.loss_bbox: 0.0469\n",
      "12/09 05:09:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 200/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:11:54  time: 0.3552  data_time: 0.0094  memory: 4054  grad_norm: 4.1946  loss: 0.4643  loss_rpn_cls: 0.0206  loss_rpn_bbox: 0.0185  s0.loss_cls: 0.1319  s0.acc: 93.2617  s0.loss_bbox: 0.0847  s1.loss_cls: 0.0579  s1.acc: 93.5743  s1.loss_bbox: 0.0785  s2.loss_cls: 0.0268  s2.acc: 95.0176  s2.loss_bbox: 0.0454\n",
      "12/09 05:09:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 250/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:11:35  time: 0.3570  data_time: 0.0099  memory: 4054  grad_norm: 4.2664  loss: 0.4455  loss_rpn_cls: 0.0213  loss_rpn_bbox: 0.0173  s0.loss_cls: 0.1250  s0.acc: 97.7051  s0.loss_bbox: 0.0818  s1.loss_cls: 0.0530  s1.acc: 98.7305  s1.loss_bbox: 0.0770  s2.loss_cls: 0.0250  s2.acc: 98.8281  s2.loss_bbox: 0.0451\n",
      "12/09 05:09:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 300/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:11:17  time: 0.3568  data_time: 0.0097  memory: 4053  grad_norm: 4.2205  loss: 0.4951  loss_rpn_cls: 0.0227  loss_rpn_bbox: 0.0197  s0.loss_cls: 0.1403  s0.acc: 97.1191  s0.loss_bbox: 0.0877  s1.loss_cls: 0.0610  s1.acc: 98.4103  s1.loss_bbox: 0.0849  s2.loss_cls: 0.0286  s2.acc: 98.2932  s2.loss_bbox: 0.0501\n",
      "12/09 05:10:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 350/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:10:59  time: 0.3574  data_time: 0.0097  memory: 4054  grad_norm: 4.2434  loss: 0.4758  loss_rpn_cls: 0.0223  loss_rpn_bbox: 0.0214  s0.loss_cls: 0.1318  s0.acc: 95.8984  s0.loss_bbox: 0.0868  s1.loss_cls: 0.0563  s1.acc: 96.9238  s1.loss_bbox: 0.0810  s2.loss_cls: 0.0271  s2.acc: 98.9650  s2.loss_bbox: 0.0490\n",
      "12/09 05:10:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 400/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:10:41  time: 0.3563  data_time: 0.0095  memory: 4053  grad_norm: 4.2845  loss: 0.4570  loss_rpn_cls: 0.0234  loss_rpn_bbox: 0.0204  s0.loss_cls: 0.1271  s0.acc: 93.4570  s0.loss_bbox: 0.0810  s1.loss_cls: 0.0557  s1.acc: 94.2007  s1.loss_bbox: 0.0763  s2.loss_cls: 0.0260  s2.acc: 93.1624  s2.loss_bbox: 0.0470\n",
      "12/09 05:10:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 450/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:10:23  time: 0.3563  data_time: 0.0099  memory: 4054  grad_norm: 3.9920  loss: 0.3893  loss_rpn_cls: 0.0186  loss_rpn_bbox: 0.0154  s0.loss_cls: 0.1100  s0.acc: 93.6523  s0.loss_bbox: 0.0696  s1.loss_cls: 0.0458  s1.acc: 93.3921  s1.loss_bbox: 0.0666  s2.loss_cls: 0.0220  s2.acc: 95.3125  s2.loss_bbox: 0.0413\n",
      "12/09 05:11:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 500/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:10:05  time: 0.3575  data_time: 0.0092  memory: 4054  grad_norm: 4.4066  loss: 0.5295  loss_rpn_cls: 0.0254  loss_rpn_bbox: 0.0234  s0.loss_cls: 0.1486  s0.acc: 88.5254  s0.loss_bbox: 0.0964  s1.loss_cls: 0.0668  s1.acc: 90.5045  s1.loss_bbox: 0.0884  s2.loss_cls: 0.0307  s2.acc: 92.3001  s2.loss_bbox: 0.0499\n",
      "12/09 05:11:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 550/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:09:47  time: 0.3572  data_time: 0.0096  memory: 4054  grad_norm: 4.0878  loss: 0.4540  loss_rpn_cls: 0.0203  loss_rpn_bbox: 0.0187  s0.loss_cls: 0.1267  s0.acc: 93.1152  s0.loss_bbox: 0.0835  s1.loss_cls: 0.0547  s1.acc: 93.0005  s1.loss_bbox: 0.0786  s2.loss_cls: 0.0256  s2.acc: 91.1448  s2.loss_bbox: 0.0458\n",
      "12/09 05:11:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 600/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:09:29  time: 0.3583  data_time: 0.0095  memory: 4054  grad_norm: 4.1545  loss: 0.4533  loss_rpn_cls: 0.0215  loss_rpn_bbox: 0.0215  s0.loss_cls: 0.1303  s0.acc: 92.8711  s0.loss_bbox: 0.0807  s1.loss_cls: 0.0572  s1.acc: 93.0176  s1.loss_bbox: 0.0732  s2.loss_cls: 0.0269  s2.acc: 92.4316  s2.loss_bbox: 0.0420\n",
      "12/09 05:11:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 650/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:09:11  time: 0.3581  data_time: 0.0093  memory: 4054  grad_norm: 4.4387  loss: 0.4516  loss_rpn_cls: 0.0210  loss_rpn_bbox: 0.0195  s0.loss_cls: 0.1277  s0.acc: 98.2910  s0.loss_bbox: 0.0799  s1.loss_cls: 0.0559  s1.acc: 97.8516  s1.loss_bbox: 0.0757  s2.loss_cls: 0.0269  s2.acc: 98.8770  s2.loss_bbox: 0.0450\n",
      "12/09 05:12:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 700/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:08:53  time: 0.3566  data_time: 0.0096  memory: 4053  grad_norm: 4.1549  loss: 0.4206  loss_rpn_cls: 0.0194  loss_rpn_bbox: 0.0180  s0.loss_cls: 0.1188  s0.acc: 96.9727  s0.loss_bbox: 0.0735  s1.loss_cls: 0.0513  s1.acc: 97.4609  s1.loss_bbox: 0.0718  s2.loss_cls: 0.0242  s2.acc: 98.1934  s2.loss_bbox: 0.0435\n",
      "12/09 05:12:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 750/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:08:35  time: 0.3570  data_time: 0.0092  memory: 4053  grad_norm: 4.3760  loss: 0.4658  loss_rpn_cls: 0.0237  loss_rpn_bbox: 0.0196  s0.loss_cls: 0.1346  s0.acc: 94.6777  s0.loss_bbox: 0.0843  s1.loss_cls: 0.0579  s1.acc: 95.5090  s1.loss_bbox: 0.0752  s2.loss_cls: 0.0270  s2.acc: 95.9184  s2.loss_bbox: 0.0434\n",
      "12/09 05:12:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 800/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:08:17  time: 0.3580  data_time: 0.0098  memory: 4054  grad_norm: 4.3938  loss: 0.4429  loss_rpn_cls: 0.0197  loss_rpn_bbox: 0.0185  s0.loss_cls: 0.1250  s0.acc: 92.1387  s0.loss_bbox: 0.0769  s1.loss_cls: 0.0573  s1.acc: 92.5187  s1.loss_bbox: 0.0737  s2.loss_cls: 0.0273  s2.acc: 93.9227  s2.loss_bbox: 0.0445\n",
      "12/09 05:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 850/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:07:59  time: 0.3570  data_time: 0.0097  memory: 4054  grad_norm: 4.3628  loss: 0.4496  loss_rpn_cls: 0.0226  loss_rpn_bbox: 0.0228  s0.loss_cls: 0.1257  s0.acc: 98.0957  s0.loss_bbox: 0.0779  s1.loss_cls: 0.0542  s1.acc: 98.6816  s1.loss_bbox: 0.0747  s2.loss_cls: 0.0258  s2.acc: 98.3887  s2.loss_bbox: 0.0460\n",
      "12/09 05:13:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 900/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:07:41  time: 0.3590  data_time: 0.0095  memory: 4054  grad_norm: 4.3846  loss: 0.4546  loss_rpn_cls: 0.0211  loss_rpn_bbox: 0.0209  s0.loss_cls: 0.1265  s0.acc: 97.9492  s0.loss_bbox: 0.0798  s1.loss_cls: 0.0578  s1.acc: 97.8027  s1.loss_bbox: 0.0753  s2.loss_cls: 0.0284  s2.acc: 96.8750  s2.loss_bbox: 0.0449\n",
      "12/09 05:13:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 950/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:07:23  time: 0.3574  data_time: 0.0097  memory: 4054  grad_norm: 3.7726  loss: 0.3639  loss_rpn_cls: 0.0152  loss_rpn_bbox: 0.0153  s0.loss_cls: 0.1019  s0.acc: 98.2422  s0.loss_bbox: 0.0656  s1.loss_cls: 0.0442  s1.acc: 97.8516  s1.loss_bbox: 0.0616  s2.loss_cls: 0.0210  s2.acc: 97.5586  s2.loss_bbox: 0.0392\n",
      "12/09 05:13:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1000/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:07:05  time: 0.3564  data_time: 0.0098  memory: 4054  grad_norm: 4.1077  loss: 0.3656  loss_rpn_cls: 0.0152  loss_rpn_bbox: 0.0138  s0.loss_cls: 0.1050  s0.acc: 93.9941  s0.loss_bbox: 0.0619  s1.loss_cls: 0.0452  s1.acc: 95.3023  s1.loss_bbox: 0.0627  s2.loss_cls: 0.0222  s2.acc: 96.0222  s2.loss_bbox: 0.0396\n",
      "12/09 05:14:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1050/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:06:46  time: 0.3566  data_time: 0.0094  memory: 4054  grad_norm: 4.4379  loss: 0.4296  loss_rpn_cls: 0.0184  loss_rpn_bbox: 0.0164  s0.loss_cls: 0.1202  s0.acc: 93.0176  s0.loss_bbox: 0.0745  s1.loss_cls: 0.0530  s1.acc: 94.5464  s1.loss_bbox: 0.0738  s2.loss_cls: 0.0262  s2.acc: 93.2412  s2.loss_bbox: 0.0471\n",
      "12/09 05:14:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1100/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:06:28  time: 0.3581  data_time: 0.0095  memory: 4054  grad_norm: 4.3477  loss: 0.4543  loss_rpn_cls: 0.0206  loss_rpn_bbox: 0.0178  s0.loss_cls: 0.1281  s0.acc: 95.9473  s0.loss_bbox: 0.0818  s1.loss_cls: 0.0562  s1.acc: 96.4216  s1.loss_bbox: 0.0764  s2.loss_cls: 0.0266  s2.acc: 97.3542  s2.loss_bbox: 0.0466\n",
      "12/09 05:14:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1150/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:06:10  time: 0.3572  data_time: 0.0093  memory: 4054  grad_norm: 4.1399  loss: 0.4285  loss_rpn_cls: 0.0206  loss_rpn_bbox: 0.0185  s0.loss_cls: 0.1204  s0.acc: 96.5332  s0.loss_bbox: 0.0753  s1.loss_cls: 0.0547  s1.acc: 96.6287  s1.loss_bbox: 0.0709  s2.loss_cls: 0.0250  s2.acc: 97.9146  s2.loss_bbox: 0.0432\n",
      "12/09 05:15:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1200/1221]  base_lr: 2.5750e-05 lr: 2.5750e-05  eta: 1:05:52  time: 0.3584  data_time: 0.0097  memory: 4054  grad_norm: 4.5667  loss: 0.5210  loss_rpn_cls: 0.0248  loss_rpn_bbox: 0.0199  s0.loss_cls: 0.1449  s0.acc: 98.3887  s0.loss_bbox: 0.0952  s1.loss_cls: 0.0636  s1.acc: 99.1699  s1.loss_bbox: 0.0884  s2.loss_cls: 0.0307  s2.acc: 99.1699  s2.loss_bbox: 0.0536\n",
      "12/09 05:15:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:15:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
      "12/09 05:15:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:15:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][  50/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:05:27  time: 0.3597  data_time: 0.0134  memory: 4054  grad_norm: 4.2829  loss: 0.4671  loss_rpn_cls: 0.0215  loss_rpn_bbox: 0.0206  s0.loss_cls: 0.1284  s0.acc: 97.0703  s0.loss_bbox: 0.0863  s1.loss_cls: 0.0565  s1.acc: 98.1863  s1.loss_bbox: 0.0794  s2.loss_cls: 0.0269  s2.acc: 98.4796  s2.loss_bbox: 0.0475\n",
      "12/09 05:15:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 100/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:05:09  time: 0.3591  data_time: 0.0095  memory: 4053  grad_norm: 3.7336  loss: 0.3740  loss_rpn_cls: 0.0182  loss_rpn_bbox: 0.0154  s0.loss_cls: 0.1053  s0.acc: 94.9707  s0.loss_bbox: 0.0659  s1.loss_cls: 0.0442  s1.acc: 95.7905  s1.loss_bbox: 0.0641  s2.loss_cls: 0.0210  s2.acc: 96.8981  s2.loss_bbox: 0.0399\n",
      "12/09 05:16:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 150/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:04:51  time: 0.3559  data_time: 0.0096  memory: 4054  grad_norm: 3.7985  loss: 0.3870  loss_rpn_cls: 0.0194  loss_rpn_bbox: 0.0171  s0.loss_cls: 0.1070  s0.acc: 96.9238  s0.loss_bbox: 0.0712  s1.loss_cls: 0.0442  s1.acc: 96.9652  s1.loss_bbox: 0.0663  s2.loss_cls: 0.0208  s2.acc: 96.6043  s2.loss_bbox: 0.0410\n",
      "12/09 05:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 200/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:04:33  time: 0.3534  data_time: 0.0093  memory: 4054  grad_norm: 3.9081  loss: 0.3559  loss_rpn_cls: 0.0168  loss_rpn_bbox: 0.0147  s0.loss_cls: 0.0981  s0.acc: 98.3398  s0.loss_bbox: 0.0630  s1.loss_cls: 0.0430  s1.acc: 99.0505  s1.loss_bbox: 0.0610  s2.loss_cls: 0.0211  s2.acc: 99.1936  s2.loss_bbox: 0.0383\n",
      "12/09 05:16:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 250/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:04:15  time: 0.3565  data_time: 0.0096  memory: 4053  grad_norm: 4.0426  loss: 0.4260  loss_rpn_cls: 0.0173  loss_rpn_bbox: 0.0191  s0.loss_cls: 0.1208  s0.acc: 95.1660  s0.loss_bbox: 0.0773  s1.loss_cls: 0.0508  s1.acc: 96.0784  s1.loss_bbox: 0.0718  s2.loss_cls: 0.0241  s2.acc: 97.1139  s2.loss_bbox: 0.0449\n",
      "12/09 05:17:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 300/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:03:56  time: 0.3531  data_time: 0.0093  memory: 4054  grad_norm: 4.2108  loss: 0.4465  loss_rpn_cls: 0.0189  loss_rpn_bbox: 0.0203  s0.loss_cls: 0.1239  s0.acc: 97.1191  s0.loss_bbox: 0.0833  s1.loss_cls: 0.0527  s1.acc: 97.5382  s1.loss_bbox: 0.0767  s2.loss_cls: 0.0250  s2.acc: 98.3127  s2.loss_bbox: 0.0457\n",
      "12/09 05:17:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 350/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:03:38  time: 0.3583  data_time: 0.0099  memory: 4053  grad_norm: 3.8084  loss: 0.4014  loss_rpn_cls: 0.0196  loss_rpn_bbox: 0.0171  s0.loss_cls: 0.1104  s0.acc: 96.1914  s0.loss_bbox: 0.0740  s1.loss_cls: 0.0469  s1.acc: 96.1924  s1.loss_bbox: 0.0692  s2.loss_cls: 0.0222  s2.acc: 96.5795  s2.loss_bbox: 0.0419\n",
      "12/09 05:17:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 400/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:03:20  time: 0.3559  data_time: 0.0098  memory: 4053  grad_norm: 4.2783  loss: 0.4261  loss_rpn_cls: 0.0162  loss_rpn_bbox: 0.0173  s0.loss_cls: 0.1194  s0.acc: 92.4805  s0.loss_bbox: 0.0775  s1.loss_cls: 0.0510  s1.acc: 92.9746  s1.loss_bbox: 0.0751  s2.loss_cls: 0.0239  s2.acc: 94.3669  s2.loss_bbox: 0.0457\n",
      "12/09 05:18:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 450/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:03:02  time: 0.3556  data_time: 0.0096  memory: 4054  grad_norm: 4.1217  loss: 0.4070  loss_rpn_cls: 0.0179  loss_rpn_bbox: 0.0182  s0.loss_cls: 0.1168  s0.acc: 94.0430  s0.loss_bbox: 0.0728  s1.loss_cls: 0.0495  s1.acc: 94.9975  s1.loss_bbox: 0.0672  s2.loss_cls: 0.0240  s2.acc: 94.8693  s2.loss_bbox: 0.0406\n",
      "12/09 05:18:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 500/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:02:44  time: 0.3539  data_time: 0.0093  memory: 4054  grad_norm: 3.9082  loss: 0.3931  loss_rpn_cls: 0.0189  loss_rpn_bbox: 0.0162  s0.loss_cls: 0.1089  s0.acc: 95.1660  s0.loss_bbox: 0.0716  s1.loss_cls: 0.0466  s1.acc: 96.7838  s1.loss_bbox: 0.0676  s2.loss_cls: 0.0215  s2.acc: 95.6457  s2.loss_bbox: 0.0419\n",
      "12/09 05:18:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 550/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:02:26  time: 0.3593  data_time: 0.0100  memory: 4054  grad_norm: 4.2824  loss: 0.4237  loss_rpn_cls: 0.0189  loss_rpn_bbox: 0.0192  s0.loss_cls: 0.1148  s0.acc: 90.4785  s0.loss_bbox: 0.0779  s1.loss_cls: 0.0518  s1.acc: 88.6274  s1.loss_bbox: 0.0721  s2.loss_cls: 0.0246  s2.acc: 88.6986  s2.loss_bbox: 0.0443\n",
      "12/09 05:18:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 600/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:02:08  time: 0.3573  data_time: 0.0099  memory: 4054  grad_norm: 4.1897  loss: 0.4405  loss_rpn_cls: 0.0207  loss_rpn_bbox: 0.0180  s0.loss_cls: 0.1232  s0.acc: 92.8223  s0.loss_bbox: 0.0790  s1.loss_cls: 0.0532  s1.acc: 93.0577  s1.loss_bbox: 0.0749  s2.loss_cls: 0.0258  s2.acc: 92.9376  s2.loss_bbox: 0.0457\n",
      "12/09 05:19:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 650/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:01:50  time: 0.3561  data_time: 0.0095  memory: 4054  grad_norm: 3.9681  loss: 0.4183  loss_rpn_cls: 0.0181  loss_rpn_bbox: 0.0170  s0.loss_cls: 0.1149  s0.acc: 94.6289  s0.loss_bbox: 0.0791  s1.loss_cls: 0.0484  s1.acc: 96.1824  s1.loss_bbox: 0.0739  s2.loss_cls: 0.0230  s2.acc: 96.4729  s2.loss_bbox: 0.0437\n",
      "12/09 05:19:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 700/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:01:32  time: 0.3592  data_time: 0.0097  memory: 4054  grad_norm: 4.1567  loss: 0.4144  loss_rpn_cls: 0.0152  loss_rpn_bbox: 0.0177  s0.loss_cls: 0.1190  s0.acc: 98.6816  s0.loss_bbox: 0.0751  s1.loss_cls: 0.0515  s1.acc: 99.3602  s1.loss_bbox: 0.0694  s2.loss_cls: 0.0245  s2.acc: 99.4056  s2.loss_bbox: 0.0419\n",
      "12/09 05:19:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 750/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:01:14  time: 0.3561  data_time: 0.0103  memory: 4054  grad_norm: 4.1644  loss: 0.4167  loss_rpn_cls: 0.0179  loss_rpn_bbox: 0.0188  s0.loss_cls: 0.1152  s0.acc: 93.8477  s0.loss_bbox: 0.0770  s1.loss_cls: 0.0493  s1.acc: 94.2829  s1.loss_bbox: 0.0715  s2.loss_cls: 0.0242  s2.acc: 93.2579  s2.loss_bbox: 0.0429\n",
      "12/09 05:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 800/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:00:56  time: 0.3551  data_time: 0.0098  memory: 4054  grad_norm: 4.1914  loss: 0.4469  loss_rpn_cls: 0.0190  loss_rpn_bbox: 0.0178  s0.loss_cls: 0.1223  s0.acc: 98.8281  s0.loss_bbox: 0.0829  s1.loss_cls: 0.0531  s1.acc: 99.4629  s1.loss_bbox: 0.0786  s2.loss_cls: 0.0255  s2.acc: 99.3164  s2.loss_bbox: 0.0477\n",
      "12/09 05:20:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 850/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:00:38  time: 0.3580  data_time: 0.0098  memory: 4053  grad_norm: 4.5911  loss: 0.4805  loss_rpn_cls: 0.0202  loss_rpn_bbox: 0.0201  s0.loss_cls: 0.1322  s0.acc: 94.8730  s0.loss_bbox: 0.0887  s1.loss_cls: 0.0568  s1.acc: 96.2526  s1.loss_bbox: 0.0858  s2.loss_cls: 0.0258  s2.acc: 96.1558  s2.loss_bbox: 0.0508\n",
      "12/09 05:20:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 900/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:00:20  time: 0.3553  data_time: 0.0094  memory: 4054  grad_norm: 4.2834  loss: 0.4375  loss_rpn_cls: 0.0200  loss_rpn_bbox: 0.0176  s0.loss_cls: 0.1190  s0.acc: 96.8262  s0.loss_bbox: 0.0806  s1.loss_cls: 0.0512  s1.acc: 96.9832  s1.loss_bbox: 0.0786  s2.loss_cls: 0.0244  s2.acc: 96.3092  s2.loss_bbox: 0.0461\n",
      "12/09 05:21:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 950/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 1:00:02  time: 0.3537  data_time: 0.0093  memory: 4054  grad_norm: 4.1418  loss: 0.3679  loss_rpn_cls: 0.0131  loss_rpn_bbox: 0.0141  s0.loss_cls: 0.0990  s0.acc: 95.6543  s0.loss_bbox: 0.0703  s1.loss_cls: 0.0411  s1.acc: 96.6337  s1.loss_bbox: 0.0680  s2.loss_cls: 0.0201  s2.acc: 95.7921  s2.loss_bbox: 0.0423\n",
      "12/09 05:21:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1000/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 0:59:44  time: 0.3571  data_time: 0.0096  memory: 4054  grad_norm: 4.2507  loss: 0.3639  loss_rpn_cls: 0.0168  loss_rpn_bbox: 0.0146  s0.loss_cls: 0.1056  s0.acc: 94.9707  s0.loss_bbox: 0.0616  s1.loss_cls: 0.0465  s1.acc: 95.5566  s1.loss_bbox: 0.0596  s2.loss_cls: 0.0222  s2.acc: 95.8008  s2.loss_bbox: 0.0370\n",
      "12/09 05:21:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:21:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1050/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 0:59:25  time: 0.3552  data_time: 0.0096  memory: 4054  grad_norm: 4.4053  loss: 0.4243  loss_rpn_cls: 0.0212  loss_rpn_bbox: 0.0200  s0.loss_cls: 0.1139  s0.acc: 96.2891  s0.loss_bbox: 0.0783  s1.loss_cls: 0.0506  s1.acc: 96.9238  s1.loss_bbox: 0.0734  s2.loss_cls: 0.0230  s2.acc: 95.6926  s2.loss_bbox: 0.0439\n",
      "12/09 05:21:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1100/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 0:59:07  time: 0.3537  data_time: 0.0095  memory: 4054  grad_norm: 4.2314  loss: 0.4207  loss_rpn_cls: 0.0175  loss_rpn_bbox: 0.0174  s0.loss_cls: 0.1192  s0.acc: 98.7793  s0.loss_bbox: 0.0751  s1.loss_cls: 0.0525  s1.acc: 98.3887  s1.loss_bbox: 0.0710  s2.loss_cls: 0.0243  s2.acc: 98.1445  s2.loss_bbox: 0.0437\n",
      "12/09 05:22:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1150/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 0:58:49  time: 0.3566  data_time: 0.0097  memory: 4054  grad_norm: 4.2465  loss: 0.4506  loss_rpn_cls: 0.0211  loss_rpn_bbox: 0.0199  s0.loss_cls: 0.1249  s0.acc: 98.0469  s0.loss_bbox: 0.0840  s1.loss_cls: 0.0532  s1.acc: 98.7793  s1.loss_bbox: 0.0776  s2.loss_cls: 0.0252  s2.acc: 99.0723  s2.loss_bbox: 0.0448\n",
      "12/09 05:22:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1200/1221]  base_lr: 1.5498e-05 lr: 1.5498e-05  eta: 0:58:31  time: 0.3549  data_time: 0.0095  memory: 4053  grad_norm: 3.8643  loss: 0.3962  loss_rpn_cls: 0.0180  loss_rpn_bbox: 0.0173  s0.loss_cls: 0.1124  s0.acc: 97.6562  s0.loss_bbox: 0.0742  s1.loss_cls: 0.0468  s1.acc: 98.0703  s1.loss_bbox: 0.0660  s2.loss_cls: 0.0220  s2.acc: 97.4013  s2.loss_bbox: 0.0394\n",
      "12/09 05:22:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:22:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\n",
      "12/09 05:22:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][  50/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:58:06  time: 0.3588  data_time: 0.0130  memory: 4053  grad_norm: 3.8134  loss: 0.3805  loss_rpn_cls: 0.0161  loss_rpn_bbox: 0.0184  s0.loss_cls: 0.1056  s0.acc: 93.5059  s0.loss_bbox: 0.0692  s1.loss_cls: 0.0456  s1.acc: 94.4279  s1.loss_bbox: 0.0645  s2.loss_cls: 0.0220  s2.acc: 95.0075  s2.loss_bbox: 0.0392\n",
      "12/09 05:23:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 100/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:57:48  time: 0.3562  data_time: 0.0098  memory: 4054  grad_norm: 4.3282  loss: 0.4561  loss_rpn_cls: 0.0200  loss_rpn_bbox: 0.0199  s0.loss_cls: 0.1248  s0.acc: 91.4551  s0.loss_bbox: 0.0854  s1.loss_cls: 0.0523  s1.acc: 92.3272  s1.loss_bbox: 0.0800  s2.loss_cls: 0.0252  s2.acc: 93.2590  s2.loss_bbox: 0.0485\n",
      "12/09 05:23:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 150/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:57:30  time: 0.3551  data_time: 0.0098  memory: 4054  grad_norm: 4.1441  loss: 0.4253  loss_rpn_cls: 0.0183  loss_rpn_bbox: 0.0174  s0.loss_cls: 0.1148  s0.acc: 97.4609  s0.loss_bbox: 0.0823  s1.loss_cls: 0.0491  s1.acc: 97.6562  s1.loss_bbox: 0.0759  s2.loss_cls: 0.0229  s2.acc: 96.4844  s2.loss_bbox: 0.0445\n",
      "12/09 05:23:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 200/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:57:11  time: 0.3523  data_time: 0.0093  memory: 4054  grad_norm: 3.7432  loss: 0.3722  loss_rpn_cls: 0.0160  loss_rpn_bbox: 0.0171  s0.loss_cls: 0.1018  s0.acc: 96.0938  s0.loss_bbox: 0.0711  s1.loss_cls: 0.0416  s1.acc: 97.2010  s1.loss_bbox: 0.0653  s2.loss_cls: 0.0197  s2.acc: 97.1795  s2.loss_bbox: 0.0395\n",
      "12/09 05:24:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 250/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:56:53  time: 0.3548  data_time: 0.0097  memory: 4054  grad_norm: 3.7861  loss: 0.3465  loss_rpn_cls: 0.0136  loss_rpn_bbox: 0.0142  s0.loss_cls: 0.0984  s0.acc: 95.2148  s0.loss_bbox: 0.0603  s1.loss_cls: 0.0410  s1.acc: 96.2816  s1.loss_bbox: 0.0605  s2.loss_cls: 0.0197  s2.acc: 96.4108  s2.loss_bbox: 0.0387\n",
      "12/09 05:24:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 300/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:56:35  time: 0.3552  data_time: 0.0098  memory: 4054  grad_norm: 4.0837  loss: 0.4176  loss_rpn_cls: 0.0154  loss_rpn_bbox: 0.0166  s0.loss_cls: 0.1185  s0.acc: 95.6055  s0.loss_bbox: 0.0768  s1.loss_cls: 0.0492  s1.acc: 96.4535  s1.loss_bbox: 0.0719  s2.loss_cls: 0.0233  s2.acc: 97.1944  s2.loss_bbox: 0.0460\n",
      "12/09 05:24:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 350/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:56:17  time: 0.3527  data_time: 0.0093  memory: 4054  grad_norm: 3.8272  loss: 0.3966  loss_rpn_cls: 0.0159  loss_rpn_bbox: 0.0160  s0.loss_cls: 0.1084  s0.acc: 97.3145  s0.loss_bbox: 0.0765  s1.loss_cls: 0.0455  s1.acc: 97.6074  s1.loss_bbox: 0.0712  s2.loss_cls: 0.0212  s2.acc: 99.0234  s2.loss_bbox: 0.0419\n",
      "12/09 05:25:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 400/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:55:59  time: 0.3536  data_time: 0.0096  memory: 4054  grad_norm: 4.0418  loss: 0.4221  loss_rpn_cls: 0.0225  loss_rpn_bbox: 0.0198  s0.loss_cls: 0.1132  s0.acc: 96.1914  s0.loss_bbox: 0.0779  s1.loss_cls: 0.0488  s1.acc: 95.8984  s1.loss_bbox: 0.0725  s2.loss_cls: 0.0235  s2.acc: 95.4456  s2.loss_bbox: 0.0438\n",
      "12/09 05:25:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 450/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:55:41  time: 0.3537  data_time: 0.0092  memory: 4054  grad_norm: 4.6651  loss: 0.4933  loss_rpn_cls: 0.0227  loss_rpn_bbox: 0.0229  s0.loss_cls: 0.1331  s0.acc: 93.5547  s0.loss_bbox: 0.0934  s1.loss_cls: 0.0574  s1.acc: 93.8653  s1.loss_bbox: 0.0855  s2.loss_cls: 0.0273  s2.acc: 94.3753  s2.loss_bbox: 0.0509\n",
      "12/09 05:25:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 500/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:55:23  time: 0.3565  data_time: 0.0097  memory: 4053  grad_norm: 3.9703  loss: 0.4094  loss_rpn_cls: 0.0159  loss_rpn_bbox: 0.0174  s0.loss_cls: 0.1158  s0.acc: 97.9492  s0.loss_bbox: 0.0761  s1.loss_cls: 0.0504  s1.acc: 97.5586  s1.loss_bbox: 0.0687  s2.loss_cls: 0.0238  s2.acc: 97.9980  s2.loss_bbox: 0.0413\n",
      "12/09 05:25:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 550/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:55:05  time: 0.3562  data_time: 0.0095  memory: 4054  grad_norm: 3.6003  loss: 0.3562  loss_rpn_cls: 0.0146  loss_rpn_bbox: 0.0165  s0.loss_cls: 0.0972  s0.acc: 97.8516  s0.loss_bbox: 0.0687  s1.loss_cls: 0.0398  s1.acc: 97.9146  s1.loss_bbox: 0.0637  s2.loss_cls: 0.0185  s2.acc: 98.3508  s2.loss_bbox: 0.0373\n",
      "12/09 05:26:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 600/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:54:47  time: 0.3563  data_time: 0.0092  memory: 4053  grad_norm: 3.9730  loss: 0.4093  loss_rpn_cls: 0.0163  loss_rpn_bbox: 0.0185  s0.loss_cls: 0.1119  s0.acc: 95.9473  s0.loss_bbox: 0.0775  s1.loss_cls: 0.0464  s1.acc: 96.5174  s1.loss_bbox: 0.0733  s2.loss_cls: 0.0221  s2.acc: 97.1130  s2.loss_bbox: 0.0432\n",
      "12/09 05:26:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 650/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:54:29  time: 0.3564  data_time: 0.0100  memory: 4053  grad_norm: 3.7658  loss: 0.3774  loss_rpn_cls: 0.0171  loss_rpn_bbox: 0.0172  s0.loss_cls: 0.1042  s0.acc: 95.2637  s0.loss_bbox: 0.0696  s1.loss_cls: 0.0437  s1.acc: 95.7457  s1.loss_bbox: 0.0659  s2.loss_cls: 0.0203  s2.acc: 96.3814  s2.loss_bbox: 0.0395\n",
      "12/09 05:26:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 700/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:54:11  time: 0.3589  data_time: 0.0097  memory: 4054  grad_norm: 4.2373  loss: 0.4197  loss_rpn_cls: 0.0180  loss_rpn_bbox: 0.0175  s0.loss_cls: 0.1161  s0.acc: 98.0469  s0.loss_bbox: 0.0788  s1.loss_cls: 0.0486  s1.acc: 99.3652  s1.loss_bbox: 0.0735  s2.loss_cls: 0.0229  s2.acc: 99.3164  s2.loss_bbox: 0.0443\n",
      "12/09 05:27:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 750/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:53:53  time: 0.3563  data_time: 0.0098  memory: 4053  grad_norm: 3.9847  loss: 0.3694  loss_rpn_cls: 0.0151  loss_rpn_bbox: 0.0162  s0.loss_cls: 0.1046  s0.acc: 99.0234  s0.loss_bbox: 0.0649  s1.loss_cls: 0.0434  s1.acc: 99.1211  s1.loss_bbox: 0.0635  s2.loss_cls: 0.0202  s2.acc: 99.5117  s2.loss_bbox: 0.0415\n",
      "12/09 05:27:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:27:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 800/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:53:35  time: 0.3560  data_time: 0.0099  memory: 4054  grad_norm: 3.6949  loss: 0.3696  loss_rpn_cls: 0.0162  loss_rpn_bbox: 0.0184  s0.loss_cls: 0.0998  s0.acc: 92.8711  s0.loss_bbox: 0.0686  s1.loss_cls: 0.0430  s1.acc: 93.5323  s1.loss_bbox: 0.0650  s2.loss_cls: 0.0201  s2.acc: 92.7536  s2.loss_bbox: 0.0385\n",
      "12/09 05:27:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 850/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:53:17  time: 0.3547  data_time: 0.0098  memory: 4053  grad_norm: 4.3112  loss: 0.3844  loss_rpn_cls: 0.0170  loss_rpn_bbox: 0.0175  s0.loss_cls: 0.1064  s0.acc: 99.1211  s0.loss_bbox: 0.0705  s1.loss_cls: 0.0455  s1.acc: 99.2188  s1.loss_bbox: 0.0658  s2.loss_cls: 0.0209  s2.acc: 99.5076  s2.loss_bbox: 0.0408\n",
      "12/09 05:28:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 900/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:52:59  time: 0.3544  data_time: 0.0095  memory: 4053  grad_norm: 4.2022  loss: 0.4274  loss_rpn_cls: 0.0188  loss_rpn_bbox: 0.0189  s0.loss_cls: 0.1215  s0.acc: 90.4785  s0.loss_bbox: 0.0776  s1.loss_cls: 0.0520  s1.acc: 93.4318  s1.loss_bbox: 0.0722  s2.loss_cls: 0.0240  s2.acc: 94.0299  s2.loss_bbox: 0.0424\n",
      "12/09 05:28:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 950/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:52:41  time: 0.3557  data_time: 0.0096  memory: 4054  grad_norm: 3.7070  loss: 0.3862  loss_rpn_cls: 0.0151  loss_rpn_bbox: 0.0172  s0.loss_cls: 0.1053  s0.acc: 99.5605  s0.loss_bbox: 0.0736  s1.loss_cls: 0.0445  s1.acc: 99.8047  s1.loss_bbox: 0.0679  s2.loss_cls: 0.0213  s2.acc: 99.9023  s2.loss_bbox: 0.0412\n",
      "12/09 05:28:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1000/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:52:23  time: 0.3561  data_time: 0.0096  memory: 4054  grad_norm: 4.2545  loss: 0.3667  loss_rpn_cls: 0.0147  loss_rpn_bbox: 0.0144  s0.loss_cls: 0.1017  s0.acc: 96.5332  s0.loss_bbox: 0.0660  s1.loss_cls: 0.0425  s1.acc: 97.6004  s1.loss_bbox: 0.0649  s2.loss_cls: 0.0204  s2.acc: 97.4359  s2.loss_bbox: 0.0421\n",
      "12/09 05:28:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1050/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:52:05  time: 0.3563  data_time: 0.0098  memory: 4053  grad_norm: 3.9302  loss: 0.3642  loss_rpn_cls: 0.0151  loss_rpn_bbox: 0.0157  s0.loss_cls: 0.1031  s0.acc: 97.9980  s0.loss_bbox: 0.0680  s1.loss_cls: 0.0429  s1.acc: 98.2910  s1.loss_bbox: 0.0619  s2.loss_cls: 0.0201  s2.acc: 98.4375  s2.loss_bbox: 0.0374\n",
      "12/09 05:29:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1100/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:51:47  time: 0.3571  data_time: 0.0099  memory: 4053  grad_norm: 3.7283  loss: 0.3738  loss_rpn_cls: 0.0149  loss_rpn_bbox: 0.0155  s0.loss_cls: 0.1047  s0.acc: 93.1152  s0.loss_bbox: 0.0699  s1.loss_cls: 0.0425  s1.acc: 94.0918  s1.loss_bbox: 0.0652  s2.loss_cls: 0.0201  s2.acc: 95.8008  s2.loss_bbox: 0.0411\n",
      "12/09 05:29:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1150/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:51:29  time: 0.3610  data_time: 0.0098  memory: 4054  grad_norm: 3.9900  loss: 0.3881  loss_rpn_cls: 0.0169  loss_rpn_bbox: 0.0174  s0.loss_cls: 0.1084  s0.acc: 99.1211  s0.loss_bbox: 0.0694  s1.loss_cls: 0.0452  s1.acc: 98.9746  s1.loss_bbox: 0.0671  s2.loss_cls: 0.0213  s2.acc: 98.6816  s2.loss_bbox: 0.0425\n",
      "12/09 05:29:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1200/1221]  base_lr: 7.6317e-06 lr: 7.6317e-06  eta: 0:51:11  time: 0.3513  data_time: 0.0092  memory: 4053  grad_norm: 3.7262  loss: 0.3328  loss_rpn_cls: 0.0136  loss_rpn_bbox: 0.0141  s0.loss_cls: 0.0909  s0.acc: 96.6309  s0.loss_bbox: 0.0621  s1.loss_cls: 0.0383  s1.acc: 95.8984  s1.loss_bbox: 0.0602  s2.loss_cls: 0.0180  s2.acc: 96.0449  s2.loss_bbox: 0.0357\n",
      "12/09 05:29:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:29:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 11 epochs\n",
      "12/09 05:30:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][  50/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:50:45  time: 0.3634  data_time: 0.0139  memory: 4054  grad_norm: 3.7398  loss: 0.3931  loss_rpn_cls: 0.0160  loss_rpn_bbox: 0.0186  s0.loss_cls: 0.1085  s0.acc: 93.8477  s0.loss_bbox: 0.0735  s1.loss_cls: 0.0448  s1.acc: 93.9941  s1.loss_bbox: 0.0677  s2.loss_cls: 0.0213  s2.acc: 96.0449  s2.loss_bbox: 0.0427\n",
      "12/09 05:30:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:50:27  time: 0.3542  data_time: 0.0096  memory: 4054  grad_norm: 4.0510  loss: 0.4486  loss_rpn_cls: 0.0190  loss_rpn_bbox: 0.0181  s0.loss_cls: 0.1207  s0.acc: 91.4551  s0.loss_bbox: 0.0844  s1.loss_cls: 0.0494  s1.acc: 93.2998  s1.loss_bbox: 0.0817  s2.loss_cls: 0.0231  s2.acc: 94.8589  s2.loss_bbox: 0.0521\n",
      "12/09 05:30:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:50:09  time: 0.3560  data_time: 0.0100  memory: 4053  grad_norm: 3.9402  loss: 0.4044  loss_rpn_cls: 0.0160  loss_rpn_bbox: 0.0184  s0.loss_cls: 0.1099  s0.acc: 96.2891  s0.loss_bbox: 0.0760  s1.loss_cls: 0.0457  s1.acc: 96.5213  s1.loss_bbox: 0.0732  s2.loss_cls: 0.0217  s2.acc: 96.7679  s2.loss_bbox: 0.0435\n",
      "12/09 05:31:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:49:51  time: 0.3572  data_time: 0.0096  memory: 4054  grad_norm: 3.8375  loss: 0.3894  loss_rpn_cls: 0.0168  loss_rpn_bbox: 0.0182  s0.loss_cls: 0.1070  s0.acc: 99.5117  s0.loss_bbox: 0.0724  s1.loss_cls: 0.0443  s1.acc: 99.8047  s1.loss_bbox: 0.0683  s2.loss_cls: 0.0207  s2.acc: 99.1211  s2.loss_bbox: 0.0416\n",
      "12/09 05:31:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 250/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:49:33  time: 0.3544  data_time: 0.0093  memory: 4054  grad_norm: 3.6322  loss: 0.3277  loss_rpn_cls: 0.0118  loss_rpn_bbox: 0.0136  s0.loss_cls: 0.0922  s0.acc: 93.8477  s0.loss_bbox: 0.0605  s1.loss_cls: 0.0379  s1.acc: 95.4545  s1.loss_bbox: 0.0580  s2.loss_cls: 0.0177  s2.acc: 96.1175  s2.loss_bbox: 0.0358\n",
      "12/09 05:31:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 300/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:49:15  time: 0.3564  data_time: 0.0099  memory: 4054  grad_norm: 4.0606  loss: 0.4341  loss_rpn_cls: 0.0190  loss_rpn_bbox: 0.0202  s0.loss_cls: 0.1168  s0.acc: 98.3398  s0.loss_bbox: 0.0812  s1.loss_cls: 0.0510  s1.acc: 98.5840  s1.loss_bbox: 0.0756  s2.loss_cls: 0.0243  s2.acc: 96.6292  s2.loss_bbox: 0.0460\n",
      "12/09 05:32:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 350/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:48:57  time: 0.3538  data_time: 0.0094  memory: 4054  grad_norm: 3.8192  loss: 0.3618  loss_rpn_cls: 0.0151  loss_rpn_bbox: 0.0144  s0.loss_cls: 0.0984  s0.acc: 94.0430  s0.loss_bbox: 0.0653  s1.loss_cls: 0.0419  s1.acc: 95.4322  s1.loss_bbox: 0.0649  s2.loss_cls: 0.0199  s2.acc: 96.4163  s2.loss_bbox: 0.0419\n",
      "12/09 05:32:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 400/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:48:39  time: 0.3555  data_time: 0.0095  memory: 4054  grad_norm: 3.9322  loss: 0.3902  loss_rpn_cls: 0.0155  loss_rpn_bbox: 0.0184  s0.loss_cls: 0.1053  s0.acc: 95.9961  s0.loss_bbox: 0.0733  s1.loss_cls: 0.0445  s1.acc: 96.6060  s1.loss_bbox: 0.0701  s2.loss_cls: 0.0214  s2.acc: 97.1499  s2.loss_bbox: 0.0417\n",
      "12/09 05:32:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 450/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:48:21  time: 0.3538  data_time: 0.0094  memory: 4053  grad_norm: 4.1240  loss: 0.3510  loss_rpn_cls: 0.0141  loss_rpn_bbox: 0.0156  s0.loss_cls: 0.0954  s0.acc: 96.8750  s0.loss_bbox: 0.0647  s1.loss_cls: 0.0394  s1.acc: 98.3163  s1.loss_bbox: 0.0628  s2.loss_cls: 0.0188  s2.acc: 98.2804  s2.loss_bbox: 0.0401\n",
      "12/09 05:32:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 500/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:48:03  time: 0.3562  data_time: 0.0094  memory: 4053  grad_norm: 3.9453  loss: 0.4047  loss_rpn_cls: 0.0173  loss_rpn_bbox: 0.0187  s0.loss_cls: 0.1100  s0.acc: 97.9004  s0.loss_bbox: 0.0766  s1.loss_cls: 0.0460  s1.acc: 99.0723  s1.loss_bbox: 0.0705  s2.loss_cls: 0.0213  s2.acc: 98.5833  s2.loss_bbox: 0.0444\n",
      "12/09 05:33:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 550/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:47:45  time: 0.3556  data_time: 0.0096  memory: 4053  grad_norm: 4.0030  loss: 0.3788  loss_rpn_cls: 0.0155  loss_rpn_bbox: 0.0164  s0.loss_cls: 0.1026  s0.acc: 99.1699  s0.loss_bbox: 0.0718  s1.loss_cls: 0.0406  s1.acc: 99.6582  s1.loss_bbox: 0.0698  s2.loss_cls: 0.0193  s2.acc: 99.8047  s2.loss_bbox: 0.0427\n",
      "12/09 05:33:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:33:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 600/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:47:27  time: 0.3550  data_time: 0.0094  memory: 4054  grad_norm: 4.2439  loss: 0.4125  loss_rpn_cls: 0.0190  loss_rpn_bbox: 0.0188  s0.loss_cls: 0.1133  s0.acc: 97.7051  s0.loss_bbox: 0.0743  s1.loss_cls: 0.0487  s1.acc: 98.1934  s1.loss_bbox: 0.0700  s2.loss_cls: 0.0236  s2.acc: 98.2422  s2.loss_bbox: 0.0448\n",
      "12/09 05:33:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 650/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:47:09  time: 0.3555  data_time: 0.0089  memory: 4054  grad_norm: 3.8145  loss: 0.3124  loss_rpn_cls: 0.0107  loss_rpn_bbox: 0.0119  s0.loss_cls: 0.0872  s0.acc: 97.4121  s0.loss_bbox: 0.0559  s1.loss_cls: 0.0369  s1.acc: 98.1564  s1.loss_bbox: 0.0560  s2.loss_cls: 0.0174  s2.acc: 98.4940  s2.loss_bbox: 0.0364\n",
      "12/09 05:34:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 700/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:46:51  time: 0.3630  data_time: 0.0093  memory: 4054  grad_norm: 3.7227  loss: 0.3543  loss_rpn_cls: 0.0166  loss_rpn_bbox: 0.0137  s0.loss_cls: 0.0990  s0.acc: 93.8965  s0.loss_bbox: 0.0669  s1.loss_cls: 0.0403  s1.acc: 94.7603  s1.loss_bbox: 0.0615  s2.loss_cls: 0.0188  s2.acc: 96.1065  s2.loss_bbox: 0.0376\n",
      "12/09 05:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 750/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:46:33  time: 0.3518  data_time: 0.0098  memory: 4054  grad_norm: 3.6987  loss: 0.3716  loss_rpn_cls: 0.0150  loss_rpn_bbox: 0.0154  s0.loss_cls: 0.1027  s0.acc: 99.1699  s0.loss_bbox: 0.0699  s1.loss_cls: 0.0431  s1.acc: 99.1211  s1.loss_bbox: 0.0660  s2.loss_cls: 0.0193  s2.acc: 99.4629  s2.loss_bbox: 0.0401\n",
      "12/09 05:34:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 800/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:46:15  time: 0.3541  data_time: 0.0096  memory: 4053  grad_norm: 4.1516  loss: 0.3672  loss_rpn_cls: 0.0164  loss_rpn_bbox: 0.0150  s0.loss_cls: 0.0988  s0.acc: 97.8516  s0.loss_bbox: 0.0694  s1.loss_cls: 0.0422  s1.acc: 97.6562  s1.loss_bbox: 0.0650  s2.loss_cls: 0.0199  s2.acc: 98.5840  s2.loss_bbox: 0.0405\n",
      "12/09 05:35:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 850/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:45:57  time: 0.3548  data_time: 0.0092  memory: 4053  grad_norm: 3.9124  loss: 0.3624  loss_rpn_cls: 0.0155  loss_rpn_bbox: 0.0147  s0.loss_cls: 0.0997  s0.acc: 96.3867  s0.loss_bbox: 0.0673  s1.loss_cls: 0.0410  s1.acc: 96.8581  s1.loss_bbox: 0.0639  s2.loss_cls: 0.0197  s2.acc: 97.8410  s2.loss_bbox: 0.0405\n",
      "12/09 05:35:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 900/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:45:39  time: 0.3541  data_time: 0.0094  memory: 4054  grad_norm: 4.1494  loss: 0.3993  loss_rpn_cls: 0.0167  loss_rpn_bbox: 0.0164  s0.loss_cls: 0.1061  s0.acc: 94.7754  s0.loss_bbox: 0.0748  s1.loss_cls: 0.0456  s1.acc: 96.6152  s1.loss_bbox: 0.0737  s2.loss_cls: 0.0219  s2.acc: 96.7229  s2.loss_bbox: 0.0441\n",
      "12/09 05:35:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 950/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:45:21  time: 0.3569  data_time: 0.0099  memory: 4053  grad_norm: 3.7632  loss: 0.3345  loss_rpn_cls: 0.0135  loss_rpn_bbox: 0.0145  s0.loss_cls: 0.0938  s0.acc: 96.6797  s0.loss_bbox: 0.0630  s1.loss_cls: 0.0383  s1.acc: 98.0914  s1.loss_bbox: 0.0582  s2.loss_cls: 0.0180  s2.acc: 96.8639  s2.loss_bbox: 0.0352\n",
      "12/09 05:35:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1000/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:45:03  time: 0.3524  data_time: 0.0094  memory: 4054  grad_norm: 3.9464  loss: 0.4208  loss_rpn_cls: 0.0193  loss_rpn_bbox: 0.0220  s0.loss_cls: 0.1148  s0.acc: 98.0957  s0.loss_bbox: 0.0806  s1.loss_cls: 0.0488  s1.acc: 97.6074  s1.loss_bbox: 0.0706  s2.loss_cls: 0.0233  s2.acc: 98.4863  s2.loss_bbox: 0.0413\n",
      "12/09 05:36:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1050/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:44:45  time: 0.3553  data_time: 0.0098  memory: 4054  grad_norm: 3.9967  loss: 0.4456  loss_rpn_cls: 0.0212  loss_rpn_bbox: 0.0195  s0.loss_cls: 0.1220  s0.acc: 98.6816  s0.loss_bbox: 0.0850  s1.loss_cls: 0.0505  s1.acc: 99.3164  s1.loss_bbox: 0.0766  s2.loss_cls: 0.0244  s2.acc: 98.3887  s2.loss_bbox: 0.0464\n",
      "12/09 05:36:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:44:27  time: 0.3541  data_time: 0.0098  memory: 4054  grad_norm: 3.8630  loss: 0.4040  loss_rpn_cls: 0.0186  loss_rpn_bbox: 0.0219  s0.loss_cls: 0.1130  s0.acc: 93.5547  s0.loss_bbox: 0.0731  s1.loss_cls: 0.0476  s1.acc: 93.7782  s1.loss_bbox: 0.0667  s2.loss_cls: 0.0222  s2.acc: 95.2333  s2.loss_bbox: 0.0408\n",
      "12/09 05:36:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:44:09  time: 0.3543  data_time: 0.0098  memory: 4053  grad_norm: 3.9629  loss: 0.3897  loss_rpn_cls: 0.0156  loss_rpn_bbox: 0.0172  s0.loss_cls: 0.1090  s0.acc: 96.7285  s0.loss_bbox: 0.0731  s1.loss_cls: 0.0460  s1.acc: 97.5598  s1.loss_bbox: 0.0667  s2.loss_cls: 0.0217  s2.acc: 97.8403  s2.loss_bbox: 0.0403\n",
      "12/09 05:37:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:43:51  time: 0.3579  data_time: 0.0100  memory: 4054  grad_norm: 3.8401  loss: 0.4085  loss_rpn_cls: 0.0171  loss_rpn_bbox: 0.0192  s0.loss_cls: 0.1113  s0.acc: 98.6328  s0.loss_bbox: 0.0764  s1.loss_cls: 0.0477  s1.acc: 98.7793  s1.loss_bbox: 0.0708  s2.loss_cls: 0.0224  s2.acc: 98.6816  s2.loss_bbox: 0.0437\n",
      "12/09 05:37:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:37:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12 epochs\n",
      "12/09 05:37:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][  50/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:43:26  time: 0.3621  data_time: 0.0134  memory: 4054  grad_norm: 4.1336  loss: 0.3925  loss_rpn_cls: 0.0142  loss_rpn_bbox: 0.0171  s0.loss_cls: 0.1070  s0.acc: 95.6543  s0.loss_bbox: 0.0742  s1.loss_cls: 0.0467  s1.acc: 96.5620  s1.loss_bbox: 0.0693  s2.loss_cls: 0.0220  s2.acc: 96.5517  s2.loss_bbox: 0.0420\n",
      "12/09 05:37:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:43:08  time: 0.3584  data_time: 0.0098  memory: 4053  grad_norm: 3.7659  loss: 0.3821  loss_rpn_cls: 0.0153  loss_rpn_bbox: 0.0162  s0.loss_cls: 0.1060  s0.acc: 97.6562  s0.loss_bbox: 0.0721  s1.loss_cls: 0.0445  s1.acc: 98.7192  s1.loss_bbox: 0.0667  s2.loss_cls: 0.0209  s2.acc: 98.9609  s2.loss_bbox: 0.0403\n",
      "12/09 05:38:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:42:50  time: 0.3579  data_time: 0.0101  memory: 4054  grad_norm: 4.3069  loss: 0.3697  loss_rpn_cls: 0.0154  loss_rpn_bbox: 0.0166  s0.loss_cls: 0.0993  s0.acc: 95.5566  s0.loss_bbox: 0.0704  s1.loss_cls: 0.0402  s1.acc: 96.9133  s1.loss_bbox: 0.0662  s2.loss_cls: 0.0192  s2.acc: 96.5162  s2.loss_bbox: 0.0425\n",
      "12/09 05:38:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:42:32  time: 0.3603  data_time: 0.0101  memory: 4054  grad_norm: 4.1386  loss: 0.4356  loss_rpn_cls: 0.0168  loss_rpn_bbox: 0.0184  s0.loss_cls: 0.1180  s0.acc: 95.3613  s0.loss_bbox: 0.0831  s1.loss_cls: 0.0514  s1.acc: 95.0860  s1.loss_bbox: 0.0775  s2.loss_cls: 0.0245  s2.acc: 95.0568  s2.loss_bbox: 0.0461\n",
      "12/09 05:38:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 250/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:42:14  time: 0.3570  data_time: 0.0098  memory: 4053  grad_norm: 3.9001  loss: 0.3903  loss_rpn_cls: 0.0185  loss_rpn_bbox: 0.0182  s0.loss_cls: 0.1079  s0.acc: 96.1426  s0.loss_bbox: 0.0742  s1.loss_cls: 0.0436  s1.acc: 96.4004  s1.loss_bbox: 0.0672  s2.loss_cls: 0.0204  s2.acc: 96.2170  s2.loss_bbox: 0.0404\n",
      "12/09 05:39:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 300/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:41:56  time: 0.3587  data_time: 0.0099  memory: 4054  grad_norm: 3.7100  loss: 0.3417  loss_rpn_cls: 0.0139  loss_rpn_bbox: 0.0153  s0.loss_cls: 0.0943  s0.acc: 92.5781  s0.loss_bbox: 0.0639  s1.loss_cls: 0.0380  s1.acc: 94.2414  s1.loss_bbox: 0.0609  s2.loss_cls: 0.0176  s2.acc: 93.8129  s2.loss_bbox: 0.0378\n",
      "12/09 05:39:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:39:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 350/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:41:38  time: 0.3563  data_time: 0.0101  memory: 4053  grad_norm: 4.0993  loss: 0.3876  loss_rpn_cls: 0.0168  loss_rpn_bbox: 0.0176  s0.loss_cls: 0.1061  s0.acc: 94.4824  s0.loss_bbox: 0.0732  s1.loss_cls: 0.0436  s1.acc: 95.0820  s1.loss_bbox: 0.0682  s2.loss_cls: 0.0205  s2.acc: 93.7500  s2.loss_bbox: 0.0416\n",
      "12/09 05:39:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 400/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:41:21  time: 0.3588  data_time: 0.0096  memory: 4054  grad_norm: 4.1115  loss: 0.3657  loss_rpn_cls: 0.0147  loss_rpn_bbox: 0.0155  s0.loss_cls: 0.0989  s0.acc: 97.2168  s0.loss_bbox: 0.0691  s1.loss_cls: 0.0409  s1.acc: 97.6559  s1.loss_bbox: 0.0659  s2.loss_cls: 0.0196  s2.acc: 98.2526  s2.loss_bbox: 0.0411\n",
      "12/09 05:39:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 450/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:41:03  time: 0.3529  data_time: 0.0095  memory: 4054  grad_norm: 3.9595  loss: 0.3049  loss_rpn_cls: 0.0149  loss_rpn_bbox: 0.0131  s0.loss_cls: 0.0832  s0.acc: 98.4863  s0.loss_bbox: 0.0562  s1.loss_cls: 0.0345  s1.acc: 98.3887  s1.loss_bbox: 0.0536  s2.loss_cls: 0.0159  s2.acc: 99.4629  s2.loss_bbox: 0.0336\n",
      "12/09 05:40:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 500/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:40:45  time: 0.3570  data_time: 0.0102  memory: 4053  grad_norm: 3.5348  loss: 0.3191  loss_rpn_cls: 0.0136  loss_rpn_bbox: 0.0148  s0.loss_cls: 0.0866  s0.acc: 97.3633  s0.loss_bbox: 0.0604  s1.loss_cls: 0.0361  s1.acc: 98.6816  s1.loss_bbox: 0.0563  s2.loss_cls: 0.0170  s2.acc: 99.1699  s2.loss_bbox: 0.0344\n",
      "12/09 05:40:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 550/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:40:27  time: 0.3542  data_time: 0.0097  memory: 4054  grad_norm: 4.0136  loss: 0.3825  loss_rpn_cls: 0.0168  loss_rpn_bbox: 0.0180  s0.loss_cls: 0.1063  s0.acc: 97.6074  s0.loss_bbox: 0.0704  s1.loss_cls: 0.0448  s1.acc: 98.5558  s1.loss_bbox: 0.0648  s2.loss_cls: 0.0210  s2.acc: 97.7398  s2.loss_bbox: 0.0405\n",
      "12/09 05:40:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 600/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:40:09  time: 0.3555  data_time: 0.0097  memory: 4054  grad_norm: 4.1324  loss: 0.4295  loss_rpn_cls: 0.0201  loss_rpn_bbox: 0.0182  s0.loss_cls: 0.1185  s0.acc: 93.5059  s0.loss_bbox: 0.0811  s1.loss_cls: 0.0509  s1.acc: 93.3696  s1.loss_bbox: 0.0734  s2.loss_cls: 0.0237  s2.acc: 93.8583  s2.loss_bbox: 0.0437\n",
      "12/09 05:41:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 650/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:39:51  time: 0.3558  data_time: 0.0097  memory: 4054  grad_norm: 3.7198  loss: 0.3782  loss_rpn_cls: 0.0144  loss_rpn_bbox: 0.0167  s0.loss_cls: 0.1024  s0.acc: 94.5801  s0.loss_bbox: 0.0710  s1.loss_cls: 0.0438  s1.acc: 95.0655  s1.loss_bbox: 0.0684  s2.loss_cls: 0.0204  s2.acc: 94.9644  s2.loss_bbox: 0.0411\n",
      "12/09 05:41:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 700/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:39:33  time: 0.3577  data_time: 0.0100  memory: 4054  grad_norm: 4.3498  loss: 0.4077  loss_rpn_cls: 0.0171  loss_rpn_bbox: 0.0174  s0.loss_cls: 0.1058  s0.acc: 98.2422  s0.loss_bbox: 0.0801  s1.loss_cls: 0.0448  s1.acc: 98.7618  s1.loss_bbox: 0.0750  s2.loss_cls: 0.0211  s2.acc: 99.1504  s2.loss_bbox: 0.0465\n",
      "12/09 05:41:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 750/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:39:15  time: 0.3544  data_time: 0.0096  memory: 4054  grad_norm: 3.7420  loss: 0.3742  loss_rpn_cls: 0.0167  loss_rpn_bbox: 0.0156  s0.loss_cls: 0.1023  s0.acc: 94.1406  s0.loss_bbox: 0.0722  s1.loss_cls: 0.0416  s1.acc: 95.2334  s1.loss_bbox: 0.0664  s2.loss_cls: 0.0194  s2.acc: 95.0932  s2.loss_bbox: 0.0400\n",
      "12/09 05:42:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 800/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:38:57  time: 0.3528  data_time: 0.0096  memory: 4053  grad_norm: 3.4262  loss: 0.3327  loss_rpn_cls: 0.0128  loss_rpn_bbox: 0.0147  s0.loss_cls: 0.0900  s0.acc: 94.5801  s0.loss_bbox: 0.0637  s1.loss_cls: 0.0363  s1.acc: 94.1089  s1.loss_bbox: 0.0603  s2.loss_cls: 0.0173  s2.acc: 94.4804  s2.loss_bbox: 0.0376\n",
      "12/09 05:42:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 850/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:38:39  time: 0.3550  data_time: 0.0096  memory: 4053  grad_norm: 3.8468  loss: 0.3866  loss_rpn_cls: 0.0182  loss_rpn_bbox: 0.0164  s0.loss_cls: 0.1040  s0.acc: 93.3594  s0.loss_bbox: 0.0733  s1.loss_cls: 0.0422  s1.acc: 94.9778  s1.loss_bbox: 0.0686  s2.loss_cls: 0.0204  s2.acc: 95.6244  s2.loss_bbox: 0.0436\n",
      "12/09 05:42:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 900/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:38:21  time: 0.3579  data_time: 0.0102  memory: 4053  grad_norm: 4.2864  loss: 0.4688  loss_rpn_cls: 0.0194  loss_rpn_bbox: 0.0212  s0.loss_cls: 0.1274  s0.acc: 90.4785  s0.loss_bbox: 0.0907  s1.loss_cls: 0.0532  s1.acc: 89.3320  s1.loss_bbox: 0.0822  s2.loss_cls: 0.0251  s2.acc: 91.3043  s2.loss_bbox: 0.0496\n",
      "12/09 05:42:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 950/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:38:03  time: 0.3543  data_time: 0.0100  memory: 4054  grad_norm: 3.7846  loss: 0.3952  loss_rpn_cls: 0.0188  loss_rpn_bbox: 0.0193  s0.loss_cls: 0.1088  s0.acc: 97.0215  s0.loss_bbox: 0.0714  s1.loss_cls: 0.0468  s1.acc: 97.8543  s1.loss_bbox: 0.0678  s2.loss_cls: 0.0220  s2.acc: 97.7432  s2.loss_bbox: 0.0403\n",
      "12/09 05:43:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1000/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:37:45  time: 0.3571  data_time: 0.0095  memory: 4054  grad_norm: 4.3126  loss: 0.4074  loss_rpn_cls: 0.0174  loss_rpn_bbox: 0.0203  s0.loss_cls: 0.1112  s0.acc: 95.8496  s0.loss_bbox: 0.0745  s1.loss_cls: 0.0480  s1.acc: 96.2594  s1.loss_bbox: 0.0704  s2.loss_cls: 0.0231  s2.acc: 96.1078  s2.loss_bbox: 0.0424\n",
      "12/09 05:43:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1050/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:37:27  time: 0.3576  data_time: 0.0100  memory: 4054  grad_norm: 3.7427  loss: 0.3516  loss_rpn_cls: 0.0143  loss_rpn_bbox: 0.0151  s0.loss_cls: 0.0968  s0.acc: 97.6074  s0.loss_bbox: 0.0668  s1.loss_cls: 0.0397  s1.acc: 98.3533  s1.loss_bbox: 0.0611  s2.loss_cls: 0.0187  s2.acc: 98.2341  s2.loss_bbox: 0.0392\n",
      "12/09 05:43:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:37:09  time: 0.3563  data_time: 0.0095  memory: 4054  grad_norm: 3.8682  loss: 0.3851  loss_rpn_cls: 0.0147  loss_rpn_bbox: 0.0164  s0.loss_cls: 0.1031  s0.acc: 91.5527  s0.loss_bbox: 0.0735  s1.loss_cls: 0.0433  s1.acc: 92.6647  s1.loss_bbox: 0.0696  s2.loss_cls: 0.0200  s2.acc: 91.8946  s2.loss_bbox: 0.0444\n",
      "12/09 05:44:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:36:51  time: 0.3544  data_time: 0.0097  memory: 4054  grad_norm: 3.7482  loss: 0.4073  loss_rpn_cls: 0.0178  loss_rpn_bbox: 0.0195  s0.loss_cls: 0.1083  s0.acc: 98.2910  s0.loss_bbox: 0.0780  s1.loss_cls: 0.0456  s1.acc: 98.6719  s1.loss_bbox: 0.0734  s2.loss_cls: 0.0217  s2.acc: 97.8272  s2.loss_bbox: 0.0430\n",
      "12/09 05:44:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:36:33  time: 0.3544  data_time: 0.0098  memory: 4053  grad_norm: 3.9742  loss: 0.3353  loss_rpn_cls: 0.0150  loss_rpn_bbox: 0.0138  s0.loss_cls: 0.0943  s0.acc: 98.6816  s0.loss_bbox: 0.0598  s1.loss_cls: 0.0401  s1.acc: 99.4629  s1.loss_bbox: 0.0575  s2.loss_cls: 0.0192  s2.acc: 99.7070  s2.loss_bbox: 0.0356\n",
      "12/09 05:44:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:44:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 13 epochs\n",
      "12/09 05:44:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][  50/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:36:08  time: 0.3591  data_time: 0.0134  memory: 4054  grad_norm: 3.7500  loss: 0.3477  loss_rpn_cls: 0.0149  loss_rpn_bbox: 0.0156  s0.loss_cls: 0.0935  s0.acc: 94.7266  s0.loss_bbox: 0.0649  s1.loss_cls: 0.0389  s1.acc: 96.5146  s1.loss_bbox: 0.0624  s2.loss_cls: 0.0186  s2.acc: 95.5499  s2.loss_bbox: 0.0388\n",
      "12/09 05:45:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:35:50  time: 0.3587  data_time: 0.0097  memory: 4053  grad_norm: 3.5653  loss: 0.2951  loss_rpn_cls: 0.0113  loss_rpn_bbox: 0.0138  s0.loss_cls: 0.0765  s0.acc: 98.4375  s0.loss_bbox: 0.0552  s1.loss_cls: 0.0314  s1.acc: 99.2489  s1.loss_bbox: 0.0556  s2.loss_cls: 0.0151  s2.acc: 99.1866  s2.loss_bbox: 0.0362\n",
      "12/09 05:45:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:45:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:35:32  time: 0.3596  data_time: 0.0095  memory: 4054  grad_norm: 4.0968  loss: 0.4034  loss_rpn_cls: 0.0178  loss_rpn_bbox: 0.0182  s0.loss_cls: 0.1123  s0.acc: 94.8730  s0.loss_bbox: 0.0760  s1.loss_cls: 0.0458  s1.acc: 95.1476  s1.loss_bbox: 0.0693  s2.loss_cls: 0.0213  s2.acc: 95.7661  s2.loss_bbox: 0.0428\n",
      "12/09 05:45:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:35:14  time: 0.3563  data_time: 0.0098  memory: 4054  grad_norm: 3.8533  loss: 0.3568  loss_rpn_cls: 0.0134  loss_rpn_bbox: 0.0163  s0.loss_cls: 0.0991  s0.acc: 89.9414  s0.loss_bbox: 0.0644  s1.loss_cls: 0.0422  s1.acc: 92.2998  s1.loss_bbox: 0.0621  s2.loss_cls: 0.0200  s2.acc: 93.2221  s2.loss_bbox: 0.0393\n",
      "12/09 05:46:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 250/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:34:56  time: 0.3546  data_time: 0.0100  memory: 4053  grad_norm: 3.9215  loss: 0.3632  loss_rpn_cls: 0.0129  loss_rpn_bbox: 0.0144  s0.loss_cls: 0.1000  s0.acc: 95.5566  s0.loss_bbox: 0.0696  s1.loss_cls: 0.0409  s1.acc: 96.8285  s1.loss_bbox: 0.0654  s2.loss_cls: 0.0192  s2.acc: 97.5260  s2.loss_bbox: 0.0409\n",
      "12/09 05:46:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 300/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:34:38  time: 0.3570  data_time: 0.0094  memory: 4054  grad_norm: 3.9938  loss: 0.3929  loss_rpn_cls: 0.0169  loss_rpn_bbox: 0.0154  s0.loss_cls: 0.1092  s0.acc: 95.6543  s0.loss_bbox: 0.0750  s1.loss_cls: 0.0469  s1.acc: 96.1084  s1.loss_bbox: 0.0667  s2.loss_cls: 0.0218  s2.acc: 97.0936  s2.loss_bbox: 0.0409\n",
      "12/09 05:46:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 350/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:34:20  time: 0.3582  data_time: 0.0099  memory: 4054  grad_norm: 4.1185  loss: 0.4245  loss_rpn_cls: 0.0212  loss_rpn_bbox: 0.0223  s0.loss_cls: 0.1154  s0.acc: 99.1699  s0.loss_bbox: 0.0793  s1.loss_cls: 0.0492  s1.acc: 99.3157  s1.loss_bbox: 0.0717  s2.loss_cls: 0.0229  s2.acc: 99.6550  s2.loss_bbox: 0.0424\n",
      "12/09 05:46:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 400/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:34:02  time: 0.3553  data_time: 0.0098  memory: 4054  grad_norm: 4.2418  loss: 0.3613  loss_rpn_cls: 0.0144  loss_rpn_bbox: 0.0159  s0.loss_cls: 0.0999  s0.acc: 96.3867  s0.loss_bbox: 0.0649  s1.loss_cls: 0.0425  s1.acc: 96.1462  s1.loss_bbox: 0.0636  s2.loss_cls: 0.0202  s2.acc: 96.6051  s2.loss_bbox: 0.0398\n",
      "12/09 05:47:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 450/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:33:44  time: 0.3545  data_time: 0.0099  memory: 4053  grad_norm: 3.7376  loss: 0.4117  loss_rpn_cls: 0.0193  loss_rpn_bbox: 0.0182  s0.loss_cls: 0.1088  s0.acc: 96.3379  s0.loss_bbox: 0.0801  s1.loss_cls: 0.0454  s1.acc: 96.1481  s1.loss_bbox: 0.0741  s2.loss_cls: 0.0212  s2.acc: 96.6416  s2.loss_bbox: 0.0446\n",
      "12/09 05:47:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 500/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:33:26  time: 0.3540  data_time: 0.0096  memory: 4054  grad_norm: 3.8853  loss: 0.3601  loss_rpn_cls: 0.0151  loss_rpn_bbox: 0.0163  s0.loss_cls: 0.1007  s0.acc: 94.1406  s0.loss_bbox: 0.0671  s1.loss_cls: 0.0407  s1.acc: 94.5810  s1.loss_bbox: 0.0629  s2.loss_cls: 0.0189  s2.acc: 94.8092  s2.loss_bbox: 0.0384\n",
      "12/09 05:47:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 550/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:33:08  time: 0.3555  data_time: 0.0093  memory: 4053  grad_norm: 3.8648  loss: 0.4182  loss_rpn_cls: 0.0183  loss_rpn_bbox: 0.0197  s0.loss_cls: 0.1116  s0.acc: 95.5078  s0.loss_bbox: 0.0812  s1.loss_cls: 0.0476  s1.acc: 95.9941  s1.loss_bbox: 0.0745  s2.loss_cls: 0.0223  s2.acc: 95.9586  s2.loss_bbox: 0.0430\n",
      "12/09 05:48:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 600/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:32:50  time: 0.3541  data_time: 0.0096  memory: 4054  grad_norm: 4.2162  loss: 0.3531  loss_rpn_cls: 0.0168  loss_rpn_bbox: 0.0158  s0.loss_cls: 0.0966  s0.acc: 95.1660  s0.loss_bbox: 0.0636  s1.loss_cls: 0.0418  s1.acc: 95.4232  s1.loss_bbox: 0.0607  s2.loss_cls: 0.0196  s2.acc: 96.3163  s2.loss_bbox: 0.0383\n",
      "12/09 05:48:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 650/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:32:32  time: 0.3556  data_time: 0.0097  memory: 4054  grad_norm: 4.2114  loss: 0.3902  loss_rpn_cls: 0.0175  loss_rpn_bbox: 0.0181  s0.loss_cls: 0.1057  s0.acc: 96.3379  s0.loss_bbox: 0.0731  s1.loss_cls: 0.0442  s1.acc: 96.8719  s1.loss_bbox: 0.0678  s2.loss_cls: 0.0211  s2.acc: 96.5638  s2.loss_bbox: 0.0427\n",
      "12/09 05:48:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 700/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:32:14  time: 0.3551  data_time: 0.0097  memory: 4053  grad_norm: 4.1004  loss: 0.3620  loss_rpn_cls: 0.0143  loss_rpn_bbox: 0.0164  s0.loss_cls: 0.0985  s0.acc: 95.9473  s0.loss_bbox: 0.0700  s1.loss_cls: 0.0399  s1.acc: 95.7669  s1.loss_bbox: 0.0632  s2.loss_cls: 0.0184  s2.acc: 96.2038  s2.loss_bbox: 0.0412\n",
      "12/09 05:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 750/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:31:57  time: 0.3548  data_time: 0.0101  memory: 4053  grad_norm: 4.2235  loss: 0.3997  loss_rpn_cls: 0.0187  loss_rpn_bbox: 0.0196  s0.loss_cls: 0.1099  s0.acc: 95.9473  s0.loss_bbox: 0.0741  s1.loss_cls: 0.0457  s1.acc: 97.2168  s1.loss_bbox: 0.0679  s2.loss_cls: 0.0216  s2.acc: 97.5098  s2.loss_bbox: 0.0422\n",
      "12/09 05:49:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 800/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:31:39  time: 0.3543  data_time: 0.0096  memory: 4054  grad_norm: 3.7850  loss: 0.3425  loss_rpn_cls: 0.0129  loss_rpn_bbox: 0.0150  s0.loss_cls: 0.0945  s0.acc: 97.1680  s0.loss_bbox: 0.0640  s1.loss_cls: 0.0394  s1.acc: 98.4375  s1.loss_bbox: 0.0613  s2.loss_cls: 0.0185  s2.acc: 98.9258  s2.loss_bbox: 0.0370\n",
      "12/09 05:49:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 850/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:31:21  time: 0.3527  data_time: 0.0090  memory: 4053  grad_norm: 3.6415  loss: 0.3686  loss_rpn_cls: 0.0157  loss_rpn_bbox: 0.0165  s0.loss_cls: 0.0988  s0.acc: 92.7734  s0.loss_bbox: 0.0693  s1.loss_cls: 0.0418  s1.acc: 94.0822  s1.loss_bbox: 0.0651  s2.loss_cls: 0.0205  s2.acc: 94.7106  s2.loss_bbox: 0.0410\n",
      "12/09 05:49:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 900/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:31:03  time: 0.3538  data_time: 0.0092  memory: 4054  grad_norm: 3.8194  loss: 0.3697  loss_rpn_cls: 0.0177  loss_rpn_bbox: 0.0176  s0.loss_cls: 0.1028  s0.acc: 98.2422  s0.loss_bbox: 0.0680  s1.loss_cls: 0.0421  s1.acc: 98.9746  s1.loss_bbox: 0.0627  s2.loss_cls: 0.0200  s2.acc: 98.8770  s2.loss_bbox: 0.0387\n",
      "12/09 05:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 950/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:30:45  time: 0.3546  data_time: 0.0095  memory: 4054  grad_norm: 4.4152  loss: 0.3890  loss_rpn_cls: 0.0163  loss_rpn_bbox: 0.0166  s0.loss_cls: 0.1066  s0.acc: 96.8262  s0.loss_bbox: 0.0740  s1.loss_cls: 0.0447  s1.acc: 97.8000  s1.loss_bbox: 0.0690  s2.loss_cls: 0.0208  s2.acc: 97.6523  s2.loss_bbox: 0.0411\n",
      "12/09 05:50:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1000/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:30:27  time: 0.3550  data_time: 0.0098  memory: 4054  grad_norm: 4.0942  loss: 0.3677  loss_rpn_cls: 0.0146  loss_rpn_bbox: 0.0144  s0.loss_cls: 0.1011  s0.acc: 94.6777  s0.loss_bbox: 0.0686  s1.loss_cls: 0.0419  s1.acc: 96.1331  s1.loss_bbox: 0.0651  s2.loss_cls: 0.0199  s2.acc: 96.3867  s2.loss_bbox: 0.0420\n",
      "12/09 05:50:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1050/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:30:09  time: 0.3530  data_time: 0.0094  memory: 4054  grad_norm: 3.9357  loss: 0.3845  loss_rpn_cls: 0.0162  loss_rpn_bbox: 0.0154  s0.loss_cls: 0.1071  s0.acc: 96.9238  s0.loss_bbox: 0.0746  s1.loss_cls: 0.0424  s1.acc: 97.6995  s1.loss_bbox: 0.0675  s2.loss_cls: 0.0204  s2.acc: 97.4296  s2.loss_bbox: 0.0408\n",
      "12/09 05:51:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:29:51  time: 0.3569  data_time: 0.0098  memory: 4054  grad_norm: 3.9433  loss: 0.3684  loss_rpn_cls: 0.0149  loss_rpn_bbox: 0.0160  s0.loss_cls: 0.0991  s0.acc: 98.6816  s0.loss_bbox: 0.0710  s1.loss_cls: 0.0413  s1.acc: 98.7305  s1.loss_bbox: 0.0668  s2.loss_cls: 0.0189  s2.acc: 98.9258  s2.loss_bbox: 0.0403\n",
      "12/09 05:51:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:51:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:29:33  time: 0.3571  data_time: 0.0097  memory: 4054  grad_norm: 4.0268  loss: 0.4007  loss_rpn_cls: 0.0161  loss_rpn_bbox: 0.0195  s0.loss_cls: 0.1092  s0.acc: 99.5117  s0.loss_bbox: 0.0759  s1.loss_cls: 0.0454  s1.acc: 99.6094  s1.loss_bbox: 0.0701  s2.loss_cls: 0.0217  s2.acc: 99.5117  s2.loss_bbox: 0.0427\n",
      "12/09 05:51:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:29:15  time: 0.3560  data_time: 0.0095  memory: 4053  grad_norm: 3.9365  loss: 0.4007  loss_rpn_cls: 0.0158  loss_rpn_bbox: 0.0176  s0.loss_cls: 0.1078  s0.acc: 98.2422  s0.loss_bbox: 0.0778  s1.loss_cls: 0.0437  s1.acc: 98.0469  s1.loss_bbox: 0.0720  s2.loss_cls: 0.0208  s2.acc: 98.7793  s2.loss_bbox: 0.0453\n",
      "12/09 05:51:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:51:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 14 epochs\n",
      "12/09 05:52:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][  50/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:28:50  time: 0.3577  data_time: 0.0131  memory: 4054  grad_norm: 3.8911  loss: 0.3659  loss_rpn_cls: 0.0148  loss_rpn_bbox: 0.0186  s0.loss_cls: 0.1018  s0.acc: 90.9668  s0.loss_bbox: 0.0667  s1.loss_cls: 0.0419  s1.acc: 91.8418  s1.loss_bbox: 0.0627  s2.loss_cls: 0.0200  s2.acc: 92.3000  s2.loss_bbox: 0.0393\n",
      "12/09 05:52:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:28:32  time: 0.3543  data_time: 0.0095  memory: 4054  grad_norm: 3.4388  loss: 0.3382  loss_rpn_cls: 0.0123  loss_rpn_bbox: 0.0163  s0.loss_cls: 0.0896  s0.acc: 96.2402  s0.loss_bbox: 0.0657  s1.loss_cls: 0.0360  s1.acc: 97.7103  s1.loss_bbox: 0.0619  s2.loss_cls: 0.0171  s2.acc: 98.2957  s2.loss_bbox: 0.0394\n",
      "12/09 05:52:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:28:14  time: 0.3574  data_time: 0.0096  memory: 4053  grad_norm: 3.7498  loss: 0.3261  loss_rpn_cls: 0.0127  loss_rpn_bbox: 0.0140  s0.loss_cls: 0.0889  s0.acc: 99.9023  s0.loss_bbox: 0.0616  s1.loss_cls: 0.0345  s1.acc: 99.8535  s1.loss_bbox: 0.0592  s2.loss_cls: 0.0162  s2.acc: 99.7559  s2.loss_bbox: 0.0390\n",
      "12/09 05:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:27:56  time: 0.3580  data_time: 0.0096  memory: 4053  grad_norm: 3.8727  loss: 0.3321  loss_rpn_cls: 0.0142  loss_rpn_bbox: 0.0142  s0.loss_cls: 0.0929  s0.acc: 98.1445  s0.loss_bbox: 0.0615  s1.loss_cls: 0.0392  s1.acc: 98.6567  s1.loss_bbox: 0.0557  s2.loss_cls: 0.0188  s2.acc: 98.8024  s2.loss_bbox: 0.0356\n",
      "12/09 05:53:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 250/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:27:38  time: 0.3545  data_time: 0.0095  memory: 4054  grad_norm: 3.9555  loss: 0.3952  loss_rpn_cls: 0.0193  loss_rpn_bbox: 0.0176  s0.loss_cls: 0.1095  s0.acc: 93.6523  s0.loss_bbox: 0.0715  s1.loss_cls: 0.0469  s1.acc: 94.5072  s1.loss_bbox: 0.0679  s2.loss_cls: 0.0216  s2.acc: 95.7747  s2.loss_bbox: 0.0409\n",
      "12/09 05:53:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 300/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:27:20  time: 0.3545  data_time: 0.0093  memory: 4054  grad_norm: 4.1129  loss: 0.3727  loss_rpn_cls: 0.0135  loss_rpn_bbox: 0.0159  s0.loss_cls: 0.0984  s0.acc: 96.8262  s0.loss_bbox: 0.0714  s1.loss_cls: 0.0411  s1.acc: 97.0180  s1.loss_bbox: 0.0696  s2.loss_cls: 0.0199  s2.acc: 96.5481  s2.loss_bbox: 0.0431\n",
      "12/09 05:53:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 350/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:27:02  time: 0.3544  data_time: 0.0094  memory: 4053  grad_norm: 3.7407  loss: 0.3710  loss_rpn_cls: 0.0152  loss_rpn_bbox: 0.0166  s0.loss_cls: 0.0979  s0.acc: 97.0703  s0.loss_bbox: 0.0709  s1.loss_cls: 0.0412  s1.acc: 97.3145  s1.loss_bbox: 0.0671  s2.loss_cls: 0.0200  s2.acc: 97.9004  s2.loss_bbox: 0.0420\n",
      "12/09 05:54:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 400/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:26:44  time: 0.3554  data_time: 0.0094  memory: 4054  grad_norm: 3.8331  loss: 0.3858  loss_rpn_cls: 0.0160  loss_rpn_bbox: 0.0163  s0.loss_cls: 0.1080  s0.acc: 95.7520  s0.loss_bbox: 0.0722  s1.loss_cls: 0.0448  s1.acc: 96.3636  s1.loss_bbox: 0.0673  s2.loss_cls: 0.0209  s2.acc: 95.9214  s2.loss_bbox: 0.0403\n",
      "12/09 05:54:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 450/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:26:26  time: 0.3541  data_time: 0.0098  memory: 4053  grad_norm: 4.1537  loss: 0.4298  loss_rpn_cls: 0.0168  loss_rpn_bbox: 0.0182  s0.loss_cls: 0.1213  s0.acc: 91.3574  s0.loss_bbox: 0.0800  s1.loss_cls: 0.0510  s1.acc: 93.4493  s1.loss_bbox: 0.0735  s2.loss_cls: 0.0238  s2.acc: 92.5811  s2.loss_bbox: 0.0453\n",
      "12/09 05:54:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 500/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:26:08  time: 0.3552  data_time: 0.0097  memory: 4054  grad_norm: 3.8316  loss: 0.4101  loss_rpn_cls: 0.0174  loss_rpn_bbox: 0.0187  s0.loss_cls: 0.1100  s0.acc: 98.8281  s0.loss_bbox: 0.0786  s1.loss_cls: 0.0463  s1.acc: 98.9258  s1.loss_bbox: 0.0732  s2.loss_cls: 0.0215  s2.acc: 98.9746  s2.loss_bbox: 0.0445\n",
      "12/09 05:55:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 550/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:25:50  time: 0.3539  data_time: 0.0098  memory: 4054  grad_norm: 4.1411  loss: 0.3989  loss_rpn_cls: 0.0196  loss_rpn_bbox: 0.0182  s0.loss_cls: 0.1109  s0.acc: 94.0430  s0.loss_bbox: 0.0732  s1.loss_cls: 0.0457  s1.acc: 94.5491  s1.loss_bbox: 0.0684  s2.loss_cls: 0.0213  s2.acc: 95.1861  s2.loss_bbox: 0.0415\n",
      "12/09 05:55:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 600/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:25:32  time: 0.3527  data_time: 0.0094  memory: 4054  grad_norm: 3.9811  loss: 0.3712  loss_rpn_cls: 0.0162  loss_rpn_bbox: 0.0163  s0.loss_cls: 0.1022  s0.acc: 95.3613  s0.loss_bbox: 0.0676  s1.loss_cls: 0.0437  s1.acc: 94.9010  s1.loss_bbox: 0.0651  s2.loss_cls: 0.0208  s2.acc: 95.2028  s2.loss_bbox: 0.0394\n",
      "12/09 05:55:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 650/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:25:14  time: 0.3529  data_time: 0.0095  memory: 4054  grad_norm: 3.4948  loss: 0.3150  loss_rpn_cls: 0.0150  loss_rpn_bbox: 0.0144  s0.loss_cls: 0.0837  s0.acc: 98.8770  s0.loss_bbox: 0.0597  s1.loss_cls: 0.0357  s1.acc: 99.4141  s1.loss_bbox: 0.0555  s2.loss_cls: 0.0167  s2.acc: 99.6094  s2.loss_bbox: 0.0342\n",
      "12/09 05:55:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 700/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:24:57  time: 0.3548  data_time: 0.0100  memory: 4053  grad_norm: 4.0908  loss: 0.4094  loss_rpn_cls: 0.0171  loss_rpn_bbox: 0.0199  s0.loss_cls: 0.1133  s0.acc: 99.5605  s0.loss_bbox: 0.0757  s1.loss_cls: 0.0469  s1.acc: 99.0234  s1.loss_bbox: 0.0705  s2.loss_cls: 0.0223  s2.acc: 99.1699  s2.loss_bbox: 0.0439\n",
      "12/09 05:56:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 750/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:24:39  time: 0.3567  data_time: 0.0100  memory: 4053  grad_norm: 4.1718  loss: 0.4295  loss_rpn_cls: 0.0203  loss_rpn_bbox: 0.0184  s0.loss_cls: 0.1155  s0.acc: 97.3145  s0.loss_bbox: 0.0817  s1.loss_cls: 0.0492  s1.acc: 98.4198  s1.loss_bbox: 0.0759  s2.loss_cls: 0.0232  s2.acc: 98.2665  s2.loss_bbox: 0.0454\n",
      "12/09 05:56:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 800/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:24:21  time: 0.3559  data_time: 0.0096  memory: 4054  grad_norm: 3.9297  loss: 0.4019  loss_rpn_cls: 0.0156  loss_rpn_bbox: 0.0179  s0.loss_cls: 0.1091  s0.acc: 95.8984  s0.loss_bbox: 0.0766  s1.loss_cls: 0.0452  s1.acc: 96.2162  s1.loss_bbox: 0.0726  s2.loss_cls: 0.0211  s2.acc: 96.7568  s2.loss_bbox: 0.0439\n",
      "12/09 05:56:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 850/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:24:03  time: 0.3558  data_time: 0.0097  memory: 4053  grad_norm: 4.0866  loss: 0.4405  loss_rpn_cls: 0.0178  loss_rpn_bbox: 0.0245  s0.loss_cls: 0.1165  s0.acc: 95.3125  s0.loss_bbox: 0.0829  s1.loss_cls: 0.0494  s1.acc: 96.4677  s1.loss_bbox: 0.0789  s2.loss_cls: 0.0232  s2.acc: 96.4747  s2.loss_bbox: 0.0472\n",
      "12/09 05:57:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 900/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:23:45  time: 0.3558  data_time: 0.0097  memory: 4053  grad_norm: 3.5017  loss: 0.3049  loss_rpn_cls: 0.0139  loss_rpn_bbox: 0.0122  s0.loss_cls: 0.0865  s0.acc: 98.2422  s0.loss_bbox: 0.0554  s1.loss_cls: 0.0364  s1.acc: 98.1934  s1.loss_bbox: 0.0509  s2.loss_cls: 0.0165  s2.acc: 98.7305  s2.loss_bbox: 0.0332\n",
      "12/09 05:57:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:57:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 950/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:23:27  time: 0.3562  data_time: 0.0102  memory: 4053  grad_norm: 3.9913  loss: 0.3625  loss_rpn_cls: 0.0143  loss_rpn_bbox: 0.0131  s0.loss_cls: 0.0969  s0.acc: 99.3652  s0.loss_bbox: 0.0694  s1.loss_cls: 0.0398  s1.acc: 99.5117  s1.loss_bbox: 0.0671  s2.loss_cls: 0.0192  s2.acc: 99.6582  s2.loss_bbox: 0.0428\n",
      "12/09 05:57:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1000/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:23:09  time: 0.3567  data_time: 0.0095  memory: 4053  grad_norm: 4.2162  loss: 0.4356  loss_rpn_cls: 0.0182  loss_rpn_bbox: 0.0192  s0.loss_cls: 0.1165  s0.acc: 98.1445  s0.loss_bbox: 0.0841  s1.loss_cls: 0.0486  s1.acc: 97.6074  s1.loss_bbox: 0.0784  s2.loss_cls: 0.0233  s2.acc: 98.2910  s2.loss_bbox: 0.0473\n",
      "12/09 05:58:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1050/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:22:51  time: 0.3549  data_time: 0.0096  memory: 4054  grad_norm: 3.7269  loss: 0.3275  loss_rpn_cls: 0.0127  loss_rpn_bbox: 0.0138  s0.loss_cls: 0.0895  s0.acc: 94.3359  s0.loss_bbox: 0.0613  s1.loss_cls: 0.0364  s1.acc: 93.7747  s1.loss_bbox: 0.0589  s2.loss_cls: 0.0177  s2.acc: 93.6672  s2.loss_bbox: 0.0372\n",
      "12/09 05:58:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:22:33  time: 0.3554  data_time: 0.0097  memory: 4054  grad_norm: 3.8384  loss: 0.3738  loss_rpn_cls: 0.0167  loss_rpn_bbox: 0.0182  s0.loss_cls: 0.0976  s0.acc: 98.7793  s0.loss_bbox: 0.0724  s1.loss_cls: 0.0404  s1.acc: 98.3887  s1.loss_bbox: 0.0671  s2.loss_cls: 0.0198  s2.acc: 99.2676  s2.loss_bbox: 0.0416\n",
      "12/09 05:58:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:22:15  time: 0.3527  data_time: 0.0095  memory: 4054  grad_norm: 3.7027  loss: 0.3715  loss_rpn_cls: 0.0147  loss_rpn_bbox: 0.0172  s0.loss_cls: 0.0994  s0.acc: 95.5078  s0.loss_bbox: 0.0730  s1.loss_cls: 0.0422  s1.acc: 95.5556  s1.loss_bbox: 0.0663  s2.loss_cls: 0.0198  s2.acc: 96.9488  s2.loss_bbox: 0.0389\n",
      "12/09 05:58:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:21:57  time: 0.3572  data_time: 0.0100  memory: 4053  grad_norm: 3.8648  loss: 0.3378  loss_rpn_cls: 0.0138  loss_rpn_bbox: 0.0142  s0.loss_cls: 0.0897  s0.acc: 97.5586  s0.loss_bbox: 0.0641  s1.loss_cls: 0.0365  s1.acc: 98.1647  s1.loss_bbox: 0.0622  s2.loss_cls: 0.0173  s2.acc: 98.7970  s2.loss_bbox: 0.0401\n",
      "12/09 05:59:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 05:59:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 15 epochs\n",
      "12/09 05:59:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][  50/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:21:32  time: 0.3591  data_time: 0.0131  memory: 4054  grad_norm: 4.0763  loss: 0.3796  loss_rpn_cls: 0.0151  loss_rpn_bbox: 0.0159  s0.loss_cls: 0.1045  s0.acc: 96.5820  s0.loss_bbox: 0.0746  s1.loss_cls: 0.0419  s1.acc: 98.0510  s1.loss_bbox: 0.0663  s2.loss_cls: 0.0201  s2.acc: 97.3856  s2.loss_bbox: 0.0412\n",
      "12/09 05:59:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:21:14  time: 0.3542  data_time: 0.0098  memory: 4054  grad_norm: 4.1208  loss: 0.3728  loss_rpn_cls: 0.0161  loss_rpn_bbox: 0.0158  s0.loss_cls: 0.1022  s0.acc: 96.5820  s0.loss_bbox: 0.0708  s1.loss_cls: 0.0415  s1.acc: 97.9803  s1.loss_bbox: 0.0660  s2.loss_cls: 0.0195  s2.acc: 97.7832  s2.loss_bbox: 0.0410\n",
      "12/09 06:00:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:20:56  time: 0.3578  data_time: 0.0096  memory: 4053  grad_norm: 3.9353  loss: 0.3475  loss_rpn_cls: 0.0124  loss_rpn_bbox: 0.0156  s0.loss_cls: 0.0964  s0.acc: 98.5352  s0.loss_bbox: 0.0664  s1.loss_cls: 0.0394  s1.acc: 98.9746  s1.loss_bbox: 0.0611  s2.loss_cls: 0.0182  s2.acc: 99.3652  s2.loss_bbox: 0.0381\n",
      "12/09 06:00:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:20:38  time: 0.3537  data_time: 0.0095  memory: 4054  grad_norm: 3.3417  loss: 0.2668  loss_rpn_cls: 0.0094  loss_rpn_bbox: 0.0122  s0.loss_cls: 0.0724  s0.acc: 98.5840  s0.loss_bbox: 0.0501  s1.loss_cls: 0.0291  s1.acc: 99.3513  s1.loss_bbox: 0.0480  s2.loss_cls: 0.0135  s2.acc: 99.2961  s2.loss_bbox: 0.0321\n",
      "12/09 06:00:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 250/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:20:20  time: 0.3554  data_time: 0.0100  memory: 4054  grad_norm: 3.5271  loss: 0.3100  loss_rpn_cls: 0.0139  loss_rpn_bbox: 0.0146  s0.loss_cls: 0.0845  s0.acc: 95.7031  s0.loss_bbox: 0.0594  s1.loss_cls: 0.0339  s1.acc: 96.2000  s1.loss_bbox: 0.0545  s2.loss_cls: 0.0160  s2.acc: 96.5105  s2.loss_bbox: 0.0331\n",
      "12/09 06:00:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 300/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:20:02  time: 0.3561  data_time: 0.0097  memory: 4054  grad_norm: 3.6919  loss: 0.3379  loss_rpn_cls: 0.0146  loss_rpn_bbox: 0.0138  s0.loss_cls: 0.0902  s0.acc: 99.2188  s0.loss_bbox: 0.0652  s1.loss_cls: 0.0359  s1.acc: 99.6094  s1.loss_bbox: 0.0611  s2.loss_cls: 0.0169  s2.acc: 99.5117  s2.loss_bbox: 0.0401\n",
      "12/09 06:01:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 350/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:19:45  time: 0.3569  data_time: 0.0096  memory: 4054  grad_norm: 3.7758  loss: 0.3617  loss_rpn_cls: 0.0137  loss_rpn_bbox: 0.0154  s0.loss_cls: 0.0996  s0.acc: 97.2656  s0.loss_bbox: 0.0685  s1.loss_cls: 0.0418  s1.acc: 98.1925  s1.loss_bbox: 0.0644  s2.loss_cls: 0.0192  s2.acc: 98.0305  s2.loss_bbox: 0.0391\n",
      "12/09 06:01:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 400/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:19:27  time: 0.3569  data_time: 0.0102  memory: 4053  grad_norm: 4.0284  loss: 0.3812  loss_rpn_cls: 0.0180  loss_rpn_bbox: 0.0166  s0.loss_cls: 0.1016  s0.acc: 98.3887  s0.loss_bbox: 0.0726  s1.loss_cls: 0.0423  s1.acc: 99.3652  s1.loss_bbox: 0.0682  s2.loss_cls: 0.0204  s2.acc: 99.3164  s2.loss_bbox: 0.0415\n",
      "12/09 06:01:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 450/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:19:09  time: 0.3605  data_time: 0.0097  memory: 4054  grad_norm: 4.4342  loss: 0.4477  loss_rpn_cls: 0.0182  loss_rpn_bbox: 0.0207  s0.loss_cls: 0.1228  s0.acc: 96.6309  s0.loss_bbox: 0.0841  s1.loss_cls: 0.0516  s1.acc: 96.8285  s1.loss_bbox: 0.0782  s2.loss_cls: 0.0247  s2.acc: 97.6143  s2.loss_bbox: 0.0475\n",
      "12/09 06:02:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 500/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:18:51  time: 0.3527  data_time: 0.0093  memory: 4053  grad_norm: 3.6154  loss: 0.3669  loss_rpn_cls: 0.0139  loss_rpn_bbox: 0.0154  s0.loss_cls: 0.0998  s0.acc: 98.3398  s0.loss_bbox: 0.0717  s1.loss_cls: 0.0417  s1.acc: 99.0723  s1.loss_bbox: 0.0661  s2.loss_cls: 0.0195  s2.acc: 99.1699  s2.loss_bbox: 0.0387\n",
      "12/09 06:02:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 550/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:18:33  time: 0.3562  data_time: 0.0099  memory: 4053  grad_norm: 4.0559  loss: 0.4188  loss_rpn_cls: 0.0174  loss_rpn_bbox: 0.0197  s0.loss_cls: 0.1100  s0.acc: 96.9727  s0.loss_bbox: 0.0819  s1.loss_cls: 0.0438  s1.acc: 97.9872  s1.loss_bbox: 0.0776  s2.loss_cls: 0.0208  s2.acc: 98.0325  s2.loss_bbox: 0.0477\n",
      "12/09 06:02:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 600/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:18:15  time: 0.3561  data_time: 0.0097  memory: 4053  grad_norm: 4.1035  loss: 0.3878  loss_rpn_cls: 0.0166  loss_rpn_bbox: 0.0197  s0.loss_cls: 0.1037  s0.acc: 97.6562  s0.loss_bbox: 0.0715  s1.loss_cls: 0.0427  s1.acc: 98.3847  s1.loss_bbox: 0.0695  s2.loss_cls: 0.0200  s2.acc: 97.8952  s2.loss_bbox: 0.0442\n",
      "12/09 06:02:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 650/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:17:57  time: 0.3569  data_time: 0.0095  memory: 4054  grad_norm: 3.9235  loss: 0.4062  loss_rpn_cls: 0.0191  loss_rpn_bbox: 0.0175  s0.loss_cls: 0.1107  s0.acc: 95.5078  s0.loss_bbox: 0.0776  s1.loss_cls: 0.0442  s1.acc: 95.8604  s1.loss_bbox: 0.0720  s2.loss_cls: 0.0206  s2.acc: 95.8707  s2.loss_bbox: 0.0444\n",
      "12/09 06:03:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 06:03:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 700/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:17:39  time: 0.3548  data_time: 0.0096  memory: 4054  grad_norm: 4.1117  loss: 0.3792  loss_rpn_cls: 0.0160  loss_rpn_bbox: 0.0156  s0.loss_cls: 0.1036  s0.acc: 98.5840  s0.loss_bbox: 0.0726  s1.loss_cls: 0.0434  s1.acc: 99.1699  s1.loss_bbox: 0.0668  s2.loss_cls: 0.0199  s2.acc: 99.6094  s2.loss_bbox: 0.0413\n",
      "12/09 06:03:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 750/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:17:21  time: 0.3553  data_time: 0.0098  memory: 4054  grad_norm: 3.6365  loss: 0.3146  loss_rpn_cls: 0.0120  loss_rpn_bbox: 0.0136  s0.loss_cls: 0.0840  s0.acc: 93.8965  s0.loss_bbox: 0.0601  s1.loss_cls: 0.0351  s1.acc: 94.6052  s1.loss_bbox: 0.0578  s2.loss_cls: 0.0161  s2.acc: 94.9658  s2.loss_bbox: 0.0358\n",
      "12/09 06:03:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 800/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:17:03  time: 0.3529  data_time: 0.0098  memory: 4053  grad_norm: 4.1236  loss: 0.4147  loss_rpn_cls: 0.0190  loss_rpn_bbox: 0.0183  s0.loss_cls: 0.1170  s0.acc: 97.6074  s0.loss_bbox: 0.0746  s1.loss_cls: 0.0492  s1.acc: 99.0025  s1.loss_bbox: 0.0711  s2.loss_cls: 0.0229  s2.acc: 98.7928  s2.loss_bbox: 0.0427\n",
      "12/09 06:04:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 850/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:16:46  time: 0.3527  data_time: 0.0097  memory: 4054  grad_norm: 3.6746  loss: 0.3475  loss_rpn_cls: 0.0128  loss_rpn_bbox: 0.0141  s0.loss_cls: 0.0965  s0.acc: 97.1680  s0.loss_bbox: 0.0631  s1.loss_cls: 0.0406  s1.acc: 97.3145  s1.loss_bbox: 0.0614  s2.loss_cls: 0.0200  s2.acc: 97.2168  s2.loss_bbox: 0.0389\n",
      "12/09 06:04:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 900/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:16:28  time: 0.3554  data_time: 0.0099  memory: 4054  grad_norm: 3.9551  loss: 0.4295  loss_rpn_cls: 0.0189  loss_rpn_bbox: 0.0207  s0.loss_cls: 0.1159  s0.acc: 97.8027  s0.loss_bbox: 0.0828  s1.loss_cls: 0.0498  s1.acc: 97.9980  s1.loss_bbox: 0.0741  s2.loss_cls: 0.0239  s2.acc: 98.8770  s2.loss_bbox: 0.0434\n",
      "12/09 06:04:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 950/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:16:10  time: 0.3541  data_time: 0.0098  memory: 4053  grad_norm: 4.1375  loss: 0.3688  loss_rpn_cls: 0.0167  loss_rpn_bbox: 0.0163  s0.loss_cls: 0.1014  s0.acc: 94.6289  s0.loss_bbox: 0.0708  s1.loss_cls: 0.0424  s1.acc: 95.4635  s1.loss_bbox: 0.0639  s2.loss_cls: 0.0195  s2.acc: 95.1772  s2.loss_bbox: 0.0379\n",
      "12/09 06:05:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1000/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:15:52  time: 0.3544  data_time: 0.0100  memory: 4054  grad_norm: 3.7028  loss: 0.3385  loss_rpn_cls: 0.0138  loss_rpn_bbox: 0.0160  s0.loss_cls: 0.0916  s0.acc: 96.4355  s0.loss_bbox: 0.0623  s1.loss_cls: 0.0376  s1.acc: 95.9961  s1.loss_bbox: 0.0610  s2.loss_cls: 0.0181  s2.acc: 96.2690  s2.loss_bbox: 0.0381\n",
      "12/09 06:05:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1050/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:15:34  time: 0.3546  data_time: 0.0099  memory: 4054  grad_norm: 4.1765  loss: 0.3838  loss_rpn_cls: 0.0165  loss_rpn_bbox: 0.0193  s0.loss_cls: 0.1036  s0.acc: 97.7051  s0.loss_bbox: 0.0744  s1.loss_cls: 0.0432  s1.acc: 98.7793  s1.loss_bbox: 0.0651  s2.loss_cls: 0.0205  s2.acc: 99.6094  s2.loss_bbox: 0.0412\n",
      "12/09 06:05:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:15:16  time: 0.3535  data_time: 0.0095  memory: 4054  grad_norm: 3.8273  loss: 0.3374  loss_rpn_cls: 0.0137  loss_rpn_bbox: 0.0158  s0.loss_cls: 0.0916  s0.acc: 98.9258  s0.loss_bbox: 0.0628  s1.loss_cls: 0.0382  s1.acc: 98.8281  s1.loss_bbox: 0.0608  s2.loss_cls: 0.0179  s2.acc: 98.3398  s2.loss_bbox: 0.0366\n",
      "12/09 06:05:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:14:58  time: 0.3550  data_time: 0.0097  memory: 4054  grad_norm: 4.3639  loss: 0.4735  loss_rpn_cls: 0.0220  loss_rpn_bbox: 0.0237  s0.loss_cls: 0.1281  s0.acc: 95.3613  s0.loss_bbox: 0.0874  s1.loss_cls: 0.0559  s1.acc: 95.8457  s1.loss_bbox: 0.0818  s2.loss_cls: 0.0260  s2.acc: 96.3636  s2.loss_bbox: 0.0484\n",
      "12/09 06:06:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:14:40  time: 0.3596  data_time: 0.0100  memory: 4054  grad_norm: 4.1199  loss: 0.3522  loss_rpn_cls: 0.0152  loss_rpn_bbox: 0.0146  s0.loss_cls: 0.0957  s0.acc: 98.5352  s0.loss_bbox: 0.0659  s1.loss_cls: 0.0404  s1.acc: 98.6816  s1.loss_bbox: 0.0633  s2.loss_cls: 0.0193  s2.acc: 98.3398  s2.loss_bbox: 0.0377\n",
      "12/09 06:06:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 06:06:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 16 epochs\n",
      "12/09 06:06:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][  50/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:14:15  time: 0.3577  data_time: 0.0130  memory: 4054  grad_norm: 4.0053  loss: 0.3838  loss_rpn_cls: 0.0202  loss_rpn_bbox: 0.0189  s0.loss_cls: 0.1037  s0.acc: 98.7793  s0.loss_bbox: 0.0706  s1.loss_cls: 0.0441  s1.acc: 98.0469  s1.loss_bbox: 0.0657  s2.loss_cls: 0.0209  s2.acc: 97.6562  s2.loss_bbox: 0.0396\n",
      "12/09 06:07:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:13:57  time: 0.3576  data_time: 0.0098  memory: 4053  grad_norm: 4.0083  loss: 0.4046  loss_rpn_cls: 0.0169  loss_rpn_bbox: 0.0188  s0.loss_cls: 0.1107  s0.acc: 98.5352  s0.loss_bbox: 0.0780  s1.loss_cls: 0.0451  s1.acc: 99.0723  s1.loss_bbox: 0.0698  s2.loss_cls: 0.0217  s2.acc: 98.5352  s2.loss_bbox: 0.0436\n",
      "12/09 06:07:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:13:39  time: 0.3552  data_time: 0.0096  memory: 4053  grad_norm: 3.8756  loss: 0.4224  loss_rpn_cls: 0.0178  loss_rpn_bbox: 0.0200  s0.loss_cls: 0.1159  s0.acc: 95.8496  s0.loss_bbox: 0.0798  s1.loss_cls: 0.0492  s1.acc: 96.3779  s1.loss_bbox: 0.0733  s2.loss_cls: 0.0229  s2.acc: 97.3568  s2.loss_bbox: 0.0435\n",
      "12/09 06:07:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:13:21  time: 0.3591  data_time: 0.0100  memory: 4053  grad_norm: 4.0162  loss: 0.3867  loss_rpn_cls: 0.0152  loss_rpn_bbox: 0.0168  s0.loss_cls: 0.1046  s0.acc: 90.0879  s0.loss_bbox: 0.0736  s1.loss_cls: 0.0432  s1.acc: 92.5641  s1.loss_bbox: 0.0696  s2.loss_cls: 0.0201  s2.acc: 92.9897  s2.loss_bbox: 0.0435\n",
      "12/09 06:07:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 250/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:13:03  time: 0.3542  data_time: 0.0094  memory: 4053  grad_norm: 4.3170  loss: 0.3715  loss_rpn_cls: 0.0138  loss_rpn_bbox: 0.0150  s0.loss_cls: 0.0992  s0.acc: 97.8516  s0.loss_bbox: 0.0737  s1.loss_cls: 0.0404  s1.acc: 99.2600  s1.loss_bbox: 0.0692  s2.loss_cls: 0.0189  s2.acc: 98.6653  s2.loss_bbox: 0.0413\n",
      "12/09 06:08:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 300/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:12:45  time: 0.3566  data_time: 0.0100  memory: 4054  grad_norm: 3.7811  loss: 0.3771  loss_rpn_cls: 0.0159  loss_rpn_bbox: 0.0156  s0.loss_cls: 0.1031  s0.acc: 96.8262  s0.loss_bbox: 0.0713  s1.loss_cls: 0.0430  s1.acc: 97.0893  s1.loss_bbox: 0.0665  s2.loss_cls: 0.0203  s2.acc: 97.1414  s2.loss_bbox: 0.0413\n",
      "12/09 06:08:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 350/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:12:28  time: 0.3562  data_time: 0.0095  memory: 4053  grad_norm: 3.7003  loss: 0.3586  loss_rpn_cls: 0.0153  loss_rpn_bbox: 0.0152  s0.loss_cls: 0.0984  s0.acc: 95.1172  s0.loss_bbox: 0.0656  s1.loss_cls: 0.0405  s1.acc: 95.8250  s1.loss_bbox: 0.0637  s2.loss_cls: 0.0193  s2.acc: 95.9841  s2.loss_bbox: 0.0407\n",
      "12/09 06:08:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 400/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:12:10  time: 0.3583  data_time: 0.0099  memory: 4054  grad_norm: 3.7746  loss: 0.3981  loss_rpn_cls: 0.0208  loss_rpn_bbox: 0.0196  s0.loss_cls: 0.1085  s0.acc: 97.9004  s0.loss_bbox: 0.0768  s1.loss_cls: 0.0448  s1.acc: 98.5665  s1.loss_bbox: 0.0677  s2.loss_cls: 0.0206  s2.acc: 98.7568  s2.loss_bbox: 0.0393\n",
      "12/09 06:09:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 450/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:11:52  time: 0.3546  data_time: 0.0097  memory: 4054  grad_norm: 3.9512  loss: 0.3833  loss_rpn_cls: 0.0160  loss_rpn_bbox: 0.0179  s0.loss_cls: 0.1024  s0.acc: 93.1641  s0.loss_bbox: 0.0723  s1.loss_cls: 0.0428  s1.acc: 92.6624  s1.loss_bbox: 0.0687  s2.loss_cls: 0.0204  s2.acc: 93.4321  s2.loss_bbox: 0.0427\n",
      "12/09 06:09:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 06:09:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 500/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:11:34  time: 0.3556  data_time: 0.0100  memory: 4054  grad_norm: 4.2123  loss: 0.4141  loss_rpn_cls: 0.0170  loss_rpn_bbox: 0.0179  s0.loss_cls: 0.1096  s0.acc: 99.3164  s0.loss_bbox: 0.0803  s1.loss_cls: 0.0459  s1.acc: 99.3164  s1.loss_bbox: 0.0750  s2.loss_cls: 0.0223  s2.acc: 99.6582  s2.loss_bbox: 0.0461\n",
      "12/09 06:09:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 550/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:11:16  time: 0.3558  data_time: 0.0096  memory: 4053  grad_norm: 3.9097  loss: 0.3586  loss_rpn_cls: 0.0143  loss_rpn_bbox: 0.0148  s0.loss_cls: 0.0975  s0.acc: 97.5586  s0.loss_bbox: 0.0673  s1.loss_cls: 0.0406  s1.acc: 98.7305  s1.loss_bbox: 0.0636  s2.loss_cls: 0.0195  s2.acc: 99.1211  s2.loss_bbox: 0.0409\n",
      "12/09 06:09:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 600/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:10:58  time: 0.3578  data_time: 0.0101  memory: 4054  grad_norm: 3.7812  loss: 0.3907  loss_rpn_cls: 0.0158  loss_rpn_bbox: 0.0176  s0.loss_cls: 0.1029  s0.acc: 95.3613  s0.loss_bbox: 0.0758  s1.loss_cls: 0.0447  s1.acc: 96.7044  s1.loss_bbox: 0.0699  s2.loss_cls: 0.0212  s2.acc: 97.1949  s2.loss_bbox: 0.0428\n",
      "12/09 06:10:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 650/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:10:40  time: 0.3579  data_time: 0.0097  memory: 4054  grad_norm: 4.2195  loss: 0.4024  loss_rpn_cls: 0.0174  loss_rpn_bbox: 0.0163  s0.loss_cls: 0.1133  s0.acc: 93.7012  s0.loss_bbox: 0.0747  s1.loss_cls: 0.0482  s1.acc: 94.1855  s1.loss_bbox: 0.0686  s2.loss_cls: 0.0226  s2.acc: 95.1637  s2.loss_bbox: 0.0412\n",
      "12/09 06:10:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 700/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:10:22  time: 0.3565  data_time: 0.0100  memory: 4054  grad_norm: 3.7432  loss: 0.3123  loss_rpn_cls: 0.0118  loss_rpn_bbox: 0.0132  s0.loss_cls: 0.0858  s0.acc: 96.8750  s0.loss_bbox: 0.0590  s1.loss_cls: 0.0351  s1.acc: 98.2910  s1.loss_bbox: 0.0551  s2.loss_cls: 0.0163  s2.acc: 97.6562  s2.loss_bbox: 0.0361\n",
      "12/09 06:10:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 750/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:10:04  time: 0.3556  data_time: 0.0098  memory: 4054  grad_norm: 3.8194  loss: 0.3709  loss_rpn_cls: 0.0151  loss_rpn_bbox: 0.0163  s0.loss_cls: 0.1017  s0.acc: 99.3164  s0.loss_bbox: 0.0705  s1.loss_cls: 0.0413  s1.acc: 99.2188  s1.loss_bbox: 0.0657  s2.loss_cls: 0.0198  s2.acc: 99.4141  s2.loss_bbox: 0.0406\n",
      "12/09 06:11:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 800/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:09:47  time: 0.3528  data_time: 0.0095  memory: 4054  grad_norm: 4.0157  loss: 0.3353  loss_rpn_cls: 0.0137  loss_rpn_bbox: 0.0168  s0.loss_cls: 0.0915  s0.acc: 99.3164  s0.loss_bbox: 0.0616  s1.loss_cls: 0.0379  s1.acc: 99.6094  s1.loss_bbox: 0.0585  s2.loss_cls: 0.0184  s2.acc: 99.8535  s2.loss_bbox: 0.0370\n",
      "12/09 06:11:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 850/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:09:29  time: 0.3589  data_time: 0.0098  memory: 4053  grad_norm: 4.0422  loss: 0.2974  loss_rpn_cls: 0.0116  loss_rpn_bbox: 0.0133  s0.loss_cls: 0.0795  s0.acc: 96.5820  s0.loss_bbox: 0.0559  s1.loss_cls: 0.0335  s1.acc: 97.1244  s1.loss_bbox: 0.0551  s2.loss_cls: 0.0154  s2.acc: 97.5112  s2.loss_bbox: 0.0332\n",
      "12/09 06:11:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 900/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:09:11  time: 0.3529  data_time: 0.0098  memory: 4054  grad_norm: 3.6486  loss: 0.3261  loss_rpn_cls: 0.0130  loss_rpn_bbox: 0.0151  s0.loss_cls: 0.0880  s0.acc: 97.9980  s0.loss_bbox: 0.0606  s1.loss_cls: 0.0375  s1.acc: 98.5243  s1.loss_bbox: 0.0575  s2.loss_cls: 0.0177  s2.acc: 97.4926  s2.loss_bbox: 0.0366\n",
      "12/09 06:12:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 950/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:08:53  time: 0.3581  data_time: 0.0098  memory: 4053  grad_norm: 3.9266  loss: 0.3888  loss_rpn_cls: 0.0173  loss_rpn_bbox: 0.0161  s0.loss_cls: 0.1057  s0.acc: 95.8984  s0.loss_bbox: 0.0741  s1.loss_cls: 0.0444  s1.acc: 96.1900  s1.loss_bbox: 0.0691  s2.loss_cls: 0.0201  s2.acc: 96.8812  s2.loss_bbox: 0.0421\n",
      "12/09 06:12:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1000/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:08:35  time: 0.3563  data_time: 0.0099  memory: 4054  grad_norm: 3.8965  loss: 0.4150  loss_rpn_cls: 0.0194  loss_rpn_bbox: 0.0207  s0.loss_cls: 0.1099  s0.acc: 96.6309  s0.loss_bbox: 0.0792  s1.loss_cls: 0.0454  s1.acc: 98.1791  s1.loss_bbox: 0.0737  s2.loss_cls: 0.0226  s2.acc: 97.2987  s2.loss_bbox: 0.0441\n",
      "12/09 06:12:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1050/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:08:17  time: 0.3592  data_time: 0.0097  memory: 4054  grad_norm: 3.6397  loss: 0.3221  loss_rpn_cls: 0.0129  loss_rpn_bbox: 0.0169  s0.loss_cls: 0.0862  s0.acc: 96.6797  s0.loss_bbox: 0.0615  s1.loss_cls: 0.0348  s1.acc: 97.1471  s1.loss_bbox: 0.0575  s2.loss_cls: 0.0165  s2.acc: 97.1110  s2.loss_bbox: 0.0358\n",
      "12/09 06:12:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:07:59  time: 0.3549  data_time: 0.0098  memory: 4054  grad_norm: 3.9074  loss: 0.3343  loss_rpn_cls: 0.0118  loss_rpn_bbox: 0.0157  s0.loss_cls: 0.0925  s0.acc: 98.3398  s0.loss_bbox: 0.0627  s1.loss_cls: 0.0367  s1.acc: 99.1699  s1.loss_bbox: 0.0600  s2.loss_cls: 0.0172  s2.acc: 99.5117  s2.loss_bbox: 0.0376\n",
      "12/09 06:13:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:07:41  time: 0.3573  data_time: 0.0098  memory: 4054  grad_norm: 3.9194  loss: 0.3921  loss_rpn_cls: 0.0194  loss_rpn_bbox: 0.0178  s0.loss_cls: 0.1050  s0.acc: 98.4375  s0.loss_bbox: 0.0749  s1.loss_cls: 0.0439  s1.acc: 98.4375  s1.loss_bbox: 0.0688  s2.loss_cls: 0.0207  s2.acc: 98.5840  s2.loss_bbox: 0.0417\n",
      "12/09 06:13:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:07:24  time: 0.3572  data_time: 0.0098  memory: 4053  grad_norm: 3.7937  loss: 0.3442  loss_rpn_cls: 0.0137  loss_rpn_bbox: 0.0157  s0.loss_cls: 0.0940  s0.acc: 96.4844  s0.loss_bbox: 0.0657  s1.loss_cls: 0.0383  s1.acc: 96.8765  s1.loss_bbox: 0.0613  s2.loss_cls: 0.0184  s2.acc: 97.5585  s2.loss_bbox: 0.0373\n",
      "12/09 06:13:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 06:13:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 17 epochs\n",
      "12/09 06:14:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][  50/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:06:58  time: 0.3625  data_time: 0.0134  memory: 4054  grad_norm: 3.7305  loss: 0.3526  loss_rpn_cls: 0.0154  loss_rpn_bbox: 0.0166  s0.loss_cls: 0.0982  s0.acc: 95.4102  s0.loss_bbox: 0.0654  s1.loss_cls: 0.0399  s1.acc: 95.0344  s1.loss_bbox: 0.0607  s2.loss_cls: 0.0189  s2.acc: 95.6778  s2.loss_bbox: 0.0375\n",
      "12/09 06:14:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:06:40  time: 0.3534  data_time: 0.0096  memory: 4054  grad_norm: 3.7530  loss: 0.3402  loss_rpn_cls: 0.0134  loss_rpn_bbox: 0.0145  s0.loss_cls: 0.0959  s0.acc: 96.6309  s0.loss_bbox: 0.0637  s1.loss_cls: 0.0393  s1.acc: 98.3781  s1.loss_bbox: 0.0589  s2.loss_cls: 0.0180  s2.acc: 97.8384  s2.loss_bbox: 0.0365\n",
      "12/09 06:14:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:06:22  time: 0.3548  data_time: 0.0097  memory: 4053  grad_norm: 4.0028  loss: 0.3788  loss_rpn_cls: 0.0158  loss_rpn_bbox: 0.0157  s0.loss_cls: 0.1030  s0.acc: 91.3086  s0.loss_bbox: 0.0709  s1.loss_cls: 0.0436  s1.acc: 92.7681  s1.loss_bbox: 0.0672  s2.loss_cls: 0.0206  s2.acc: 94.2414  s2.loss_bbox: 0.0420\n",
      "12/09 06:14:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:06:05  time: 0.3571  data_time: 0.0098  memory: 4054  grad_norm: 3.7237  loss: 0.3374  loss_rpn_cls: 0.0154  loss_rpn_bbox: 0.0133  s0.loss_cls: 0.0900  s0.acc: 97.3145  s0.loss_bbox: 0.0643  s1.loss_cls: 0.0378  s1.acc: 97.7362  s1.loss_bbox: 0.0617  s2.loss_cls: 0.0176  s2.acc: 97.1963  s2.loss_bbox: 0.0372\n",
      "12/09 06:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 06:15:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 250/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:05:47  time: 0.3576  data_time: 0.0100  memory: 4053  grad_norm: 3.5797  loss: 0.3478  loss_rpn_cls: 0.0142  loss_rpn_bbox: 0.0145  s0.loss_cls: 0.0946  s0.acc: 93.5547  s0.loss_bbox: 0.0677  s1.loss_cls: 0.0377  s1.acc: 95.5023  s1.loss_bbox: 0.0625  s2.loss_cls: 0.0179  s2.acc: 95.7457  s2.loss_bbox: 0.0386\n",
      "12/09 06:15:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 300/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:05:29  time: 0.3555  data_time: 0.0098  memory: 4054  grad_norm: 3.9202  loss: 0.3791  loss_rpn_cls: 0.0178  loss_rpn_bbox: 0.0184  s0.loss_cls: 0.1016  s0.acc: 94.2871  s0.loss_bbox: 0.0739  s1.loss_cls: 0.0411  s1.acc: 95.9294  s1.loss_bbox: 0.0661  s2.loss_cls: 0.0192  s2.acc: 95.8824  s2.loss_bbox: 0.0411\n",
      "12/09 06:15:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 350/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:05:11  time: 0.3549  data_time: 0.0097  memory: 4054  grad_norm: 3.5534  loss: 0.3230  loss_rpn_cls: 0.0144  loss_rpn_bbox: 0.0155  s0.loss_cls: 0.0887  s0.acc: 98.5840  s0.loss_bbox: 0.0628  s1.loss_cls: 0.0354  s1.acc: 99.2676  s1.loss_bbox: 0.0557  s2.loss_cls: 0.0169  s2.acc: 99.7070  s2.loss_bbox: 0.0335\n",
      "12/09 06:16:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 400/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:04:53  time: 0.3579  data_time: 0.0101  memory: 4054  grad_norm: 3.9132  loss: 0.4019  loss_rpn_cls: 0.0160  loss_rpn_bbox: 0.0201  s0.loss_cls: 0.1064  s0.acc: 97.7539  s0.loss_bbox: 0.0766  s1.loss_cls: 0.0454  s1.acc: 98.1546  s1.loss_bbox: 0.0724  s2.loss_cls: 0.0217  s2.acc: 97.7398  s2.loss_bbox: 0.0433\n",
      "12/09 06:16:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 450/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:04:35  time: 0.3544  data_time: 0.0099  memory: 4054  grad_norm: 3.9186  loss: 0.3998  loss_rpn_cls: 0.0154  loss_rpn_bbox: 0.0178  s0.loss_cls: 0.1114  s0.acc: 93.4570  s0.loss_bbox: 0.0774  s1.loss_cls: 0.0462  s1.acc: 93.9901  s1.loss_bbox: 0.0702  s2.loss_cls: 0.0218  s2.acc: 95.2849  s2.loss_bbox: 0.0397\n",
      "12/09 06:16:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 500/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:04:17  time: 0.3574  data_time: 0.0096  memory: 4054  grad_norm: 3.5127  loss: 0.3199  loss_rpn_cls: 0.0135  loss_rpn_bbox: 0.0171  s0.loss_cls: 0.0871  s0.acc: 97.9980  s0.loss_bbox: 0.0601  s1.loss_cls: 0.0365  s1.acc: 97.5098  s1.loss_bbox: 0.0559  s2.loss_cls: 0.0166  s2.acc: 97.1191  s2.loss_bbox: 0.0331\n",
      "12/09 06:16:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 550/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:03:59  time: 0.3530  data_time: 0.0092  memory: 4054  grad_norm: 4.0350  loss: 0.3461  loss_rpn_cls: 0.0148  loss_rpn_bbox: 0.0154  s0.loss_cls: 0.0899  s0.acc: 97.6074  s0.loss_bbox: 0.0673  s1.loss_cls: 0.0361  s1.acc: 98.2647  s1.loss_bbox: 0.0639  s2.loss_cls: 0.0178  s2.acc: 98.2447  s2.loss_bbox: 0.0409\n",
      "12/09 06:17:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 600/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:03:41  time: 0.3544  data_time: 0.0096  memory: 4054  grad_norm: 3.8747  loss: 0.4109  loss_rpn_cls: 0.0157  loss_rpn_bbox: 0.0158  s0.loss_cls: 0.1100  s0.acc: 98.6328  s0.loss_bbox: 0.0803  s1.loss_cls: 0.0453  s1.acc: 98.7793  s1.loss_bbox: 0.0754  s2.loss_cls: 0.0218  s2.acc: 99.3164  s2.loss_bbox: 0.0466\n",
      "12/09 06:17:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 650/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:03:24  time: 0.3534  data_time: 0.0094  memory: 4054  grad_norm: 3.8757  loss: 0.3458  loss_rpn_cls: 0.0128  loss_rpn_bbox: 0.0148  s0.loss_cls: 0.0913  s0.acc: 93.8965  s0.loss_bbox: 0.0658  s1.loss_cls: 0.0379  s1.acc: 95.2994  s1.loss_bbox: 0.0639  s2.loss_cls: 0.0183  s2.acc: 95.5611  s2.loss_bbox: 0.0409\n",
      "12/09 06:17:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 700/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:03:06  time: 0.3548  data_time: 0.0095  memory: 4054  grad_norm: 4.1041  loss: 0.3641  loss_rpn_cls: 0.0145  loss_rpn_bbox: 0.0155  s0.loss_cls: 0.0981  s0.acc: 91.2109  s0.loss_bbox: 0.0685  s1.loss_cls: 0.0408  s1.acc: 91.3172  s1.loss_bbox: 0.0665  s2.loss_cls: 0.0192  s2.acc: 92.6035  s2.loss_bbox: 0.0411\n",
      "12/09 06:18:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 750/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:02:48  time: 0.3561  data_time: 0.0098  memory: 4054  grad_norm: 3.7372  loss: 0.3767  loss_rpn_cls: 0.0190  loss_rpn_bbox: 0.0191  s0.loss_cls: 0.1020  s0.acc: 97.1680  s0.loss_bbox: 0.0709  s1.loss_cls: 0.0423  s1.acc: 98.3342  s1.loss_bbox: 0.0646  s2.loss_cls: 0.0194  s2.acc: 98.2809  s2.loss_bbox: 0.0395\n",
      "12/09 06:18:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 800/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:02:30  time: 0.3534  data_time: 0.0100  memory: 4053  grad_norm: 4.0169  loss: 0.3099  loss_rpn_cls: 0.0118  loss_rpn_bbox: 0.0125  s0.loss_cls: 0.0850  s0.acc: 95.9473  s0.loss_bbox: 0.0583  s1.loss_cls: 0.0351  s1.acc: 96.5347  s1.loss_bbox: 0.0549  s2.loss_cls: 0.0166  s2.acc: 97.2318  s2.loss_bbox: 0.0356\n",
      "12/09 06:18:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 850/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:02:12  time: 0.3540  data_time: 0.0100  memory: 4054  grad_norm: 4.0292  loss: 0.3521  loss_rpn_cls: 0.0141  loss_rpn_bbox: 0.0164  s0.loss_cls: 0.0899  s0.acc: 99.6094  s0.loss_bbox: 0.0695  s1.loss_cls: 0.0379  s1.acc: 99.6094  s1.loss_bbox: 0.0655  s2.loss_cls: 0.0183  s2.acc: 99.5117  s2.loss_bbox: 0.0405\n",
      "12/09 06:19:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 900/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:01:54  time: 0.3573  data_time: 0.0097  memory: 4053  grad_norm: 4.3091  loss: 0.3860  loss_rpn_cls: 0.0155  loss_rpn_bbox: 0.0169  s0.loss_cls: 0.1059  s0.acc: 98.1445  s0.loss_bbox: 0.0734  s1.loss_cls: 0.0438  s1.acc: 98.6816  s1.loss_bbox: 0.0675  s2.loss_cls: 0.0211  s2.acc: 99.2172  s2.loss_bbox: 0.0418\n",
      "12/09 06:19:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 950/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:01:36  time: 0.3573  data_time: 0.0100  memory: 4054  grad_norm: 4.0600  loss: 0.4251  loss_rpn_cls: 0.0202  loss_rpn_bbox: 0.0216  s0.loss_cls: 0.1148  s0.acc: 95.9473  s0.loss_bbox: 0.0806  s1.loss_cls: 0.0478  s1.acc: 95.4749  s1.loss_bbox: 0.0724  s2.loss_cls: 0.0225  s2.acc: 95.7690  s2.loss_bbox: 0.0451\n",
      "12/09 06:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1000/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:01:18  time: 0.3558  data_time: 0.0097  memory: 4054  grad_norm: 3.9303  loss: 0.3919  loss_rpn_cls: 0.0157  loss_rpn_bbox: 0.0181  s0.loss_cls: 0.1088  s0.acc: 94.1406  s0.loss_bbox: 0.0762  s1.loss_cls: 0.0449  s1.acc: 94.8148  s1.loss_bbox: 0.0671  s2.loss_cls: 0.0214  s2.acc: 94.9111  s2.loss_bbox: 0.0397\n",
      "12/09 06:19:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1050/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:01:01  time: 0.3538  data_time: 0.0095  memory: 4053  grad_norm: 3.8154  loss: 0.3773  loss_rpn_cls: 0.0166  loss_rpn_bbox: 0.0178  s0.loss_cls: 0.1017  s0.acc: 92.7246  s0.loss_bbox: 0.0714  s1.loss_cls: 0.0425  s1.acc: 93.5484  s1.loss_bbox: 0.0664  s2.loss_cls: 0.0205  s2.acc: 95.0635  s2.loss_bbox: 0.0405\n",
      "12/09 06:20:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1100/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:00:43  time: 0.3533  data_time: 0.0093  memory: 4054  grad_norm: 4.1890  loss: 0.3996  loss_rpn_cls: 0.0166  loss_rpn_bbox: 0.0183  s0.loss_cls: 0.1081  s0.acc: 97.0703  s0.loss_bbox: 0.0741  s1.loss_cls: 0.0451  s1.acc: 96.7965  s1.loss_bbox: 0.0714  s2.loss_cls: 0.0217  s2.acc: 96.1595  s2.loss_bbox: 0.0444\n",
      "12/09 06:20:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1150/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:00:25  time: 0.3548  data_time: 0.0093  memory: 4054  grad_norm: 3.8563  loss: 0.3476  loss_rpn_cls: 0.0138  loss_rpn_bbox: 0.0134  s0.loss_cls: 0.0965  s0.acc: 96.8750  s0.loss_bbox: 0.0637  s1.loss_cls: 0.0403  s1.acc: 97.6562  s1.loss_bbox: 0.0617  s2.loss_cls: 0.0191  s2.acc: 98.1445  s2.loss_bbox: 0.0391\n",
      "12/09 06:20:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1200/1221]  base_lr: 2.6867e-06 lr: 2.6867e-06  eta: 0:00:07  time: 0.3582  data_time: 0.0098  memory: 4054  grad_norm: 3.9936  loss: 0.3361  loss_rpn_cls: 0.0135  loss_rpn_bbox: 0.0146  s0.loss_cls: 0.0914  s0.acc: 96.0938  s0.loss_bbox: 0.0626  s1.loss_cls: 0.0386  s1.acc: 96.6483  s1.loss_bbox: 0.0603  s2.loss_cls: 0.0180  s2.acc: 97.0544  s2.loss_bbox: 0.0372\n",
      "12/09 06:20:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade_rcnn_swin_tiny_20251209_040843\n",
      "12/09 06:20:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 18 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>base_lr</td><td>▄█▇▇▇▆▅▅▅▅▄▄▄▄▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>data_time</td><td>▃▄▃▂▁▁▂▃▁▂▁▂▂█▂▂▂▂▂▂▁▂▂▂▁▂▂▃▁▂▂▂▂▂▃▂▂▃▂▃</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>grad_norm</td><td>▁▂▇▇▆▅▅▅▇▆▅▄▅▅▅█▄▁▅▂▁▁▂▁▁▄▂▂▃▃▂▃▁▂▃▂▂▂▂▂</td></tr><tr><td>iter</td><td>▁▁▁▂▂▂▂▂▂▂▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>loss</td><td>███▇▆▆▆▅█▅▆▅▆▅▄▄▃▅▃▄▃▃▄▃▄▂▂▂▂▂▁▁▁▂▁▂▁▂▂▂</td></tr><tr><td>loss_rpn_bbox</td><td>▇█▆▆▅▄▅▄▄▄▂▃▃▂▃▃▃▂▁▂▂▁▂▂▃▁▂▂▂▁▂▄▁▁▁▂▁▂▁▁</td></tr><tr><td>loss_rpn_cls</td><td>██▅▄▄▃▄▃▄▃▂▃▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▄███████▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>memory</td><td>▁▁█▁█▁█▁█▁██▁█▁█▁▁█▁███▁██▁███▁███▁█████</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>base_lr</td><td>0.0</td></tr><tr><td>data_time</td><td>0.00985</td></tr><tr><td>epoch</td><td>18</td></tr><tr><td>grad_norm</td><td>3.99358</td></tr><tr><td>iter</td><td>21957</td></tr><tr><td>loss</td><td>0.33611</td></tr><tr><td>loss_rpn_bbox</td><td>0.0146</td></tr><tr><td>loss_rpn_cls</td><td>0.01351</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>memory</td><td>4054</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cascade_rcnn_swin_test</strong> at: <a href='https://wandb.ai/cv_11/cv_11_OD/runs/gwdr7pww' target=\"_blank\">https://wandb.ai/cv_11/cv_11_OD/runs/gwdr7pww</a><br> View project at: <a href='https://wandb.ai/cv_11/cv_11_OD' target=\"_blank\">https://wandb.ai/cv_11/cv_11_OD</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./work_dirs/cascade_rcnn_swin_trash/20251209_040843/vis_data/wandb/run-20251209_040856-gwdr7pww/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CascadeRCNN(\n",
       "  (data_preprocessor): DetDataPreprocessor()\n",
       "  (backbone): SwinTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (adap_padding): AdaptivePadding()\n",
       "      (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (drop_after_pos): Dropout(p=0.0, inplace=False)\n",
       "    (stages): ModuleList(\n",
       "      (0): SwinBlockSequence(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x SwinBlock(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=384, out_features=96, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (adap_padding): AdaptivePadding()\n",
       "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
       "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinBlockSequence(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x SwinBlock(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (adap_padding): AdaptivePadding()\n",
       "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): SwinBlockSequence(\n",
       "        (blocks): ModuleList(\n",
       "          (0-5): 6 x SwinBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (adap_padding): AdaptivePadding()\n",
       "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
       "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (3): SwinBlockSequence(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x SwinBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (1): GELU(approximate='none')\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth'}\n",
       "  (neck): FPN(\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0-3): 4 x ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
       "  (rpn_head): RPNHead(\n",
       "    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (loss_bbox): SmoothL1Loss()\n",
       "    (rpn_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (rpn_cls): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (rpn_reg): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
       "  (roi_head): CascadeRoIHead(\n",
       "    (bbox_roi_extractor): ModuleList(\n",
       "      (0-2): 3 x SingleRoIExtractor(\n",
       "        (roi_layers): ModuleList(\n",
       "          (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "          (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "          (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "          (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bbox_head): ModuleList(\n",
       "      (0-2): 3 x Shared2FCBBoxHead(\n",
       "        (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
       "        (loss_bbox): SmoothL1Loss()\n",
       "        (fc_cls): Linear(in_features=1024, out_features=11, bias=True)\n",
       "        (fc_reg): Linear(in_features=1024, out_features=4, bias=True)\n",
       "        (shared_convs): ModuleList()\n",
       "        (shared_fcs): ModuleList(\n",
       "          (0): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "          (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cls_convs): ModuleList()\n",
       "        (cls_fcs): ModuleList()\n",
       "        (reg_convs): ModuleList()\n",
       "        (reg_fcs): ModuleList()\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "runner = Runner.from_cfg(cfg)\n",
    "runner.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
