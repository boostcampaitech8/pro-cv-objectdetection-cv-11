{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: kkhs4988\n",
      "Teams: ['kkhs4988', 'cv_11']\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "me = api.viewer\n",
    "\n",
    "print(\"Username:\", me.username)\n",
    "print(\"Teams:\", me.teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 import\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmdet.registry import DATASETS\n",
    "from mmdet.utils import register_all_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom 설정\n",
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\",\n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "root = \"../../dataset/\"\n",
    "train_ann = \"train.json\"\n",
    "test_ann  = \"test.json\"\n",
    "\n",
    "# config file 들고오기\n",
    "cfg = Config.fromfile(\"configs/cascade_rcnn/cascade-rcnn_r50_fpn_1x_coco.py\")\n",
    "register_all_modules(init_default_scope=True)\n",
    "cfg.default_scope = \"mmdet\"\n",
    "\n",
    "# dataset config 수정\n",
    "for ds_key in [\"train_dataloader\", \"test_dataloader\"]:\n",
    "    if ds_key not in cfg:\n",
    "        continue\n",
    "    ds = cfg[ds_key][\"dataset\"] if \"dataset\" in cfg[ds_key] else cfg[ds_key]\n",
    "    ds.metainfo = dict(classes=classes)\n",
    "    ds.data_root = root\n",
    "    ds.ann_file = train_ann if ds_key == \"train_dataloader\" else test_ann\n",
    "    ds.data_prefix = dict(img=\"\")\n",
    "\n",
    "cfg.train_dataloader.batch_size = 4\n",
    "cfg.train_dataloader.num_workers = max(2, cfg.train_dataloader.get(\"num_workers\", 2))\n",
    "\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(\n",
    "        type='PhotoMetricDistortion',\n",
    "        brightness_delta=20,\n",
    "        contrast_range=(0.8, 1.2),\n",
    "        saturation_range=(0.8, 1.2),\n",
    "        hue_delta=10\n",
    "    ),\n",
    "    dict(type='Resize', scale=(512, 512), keep_ratio=False),\n",
    "    dict(type='PackDetInputs')\n",
    "]\n",
    "\n",
    "cfg.train_dataloader.dataset.pipeline = train_pipeline\n",
    "\n",
    "\n",
    "cfg.test_dataloader.batch_size = 1\n",
    "cfg.test_dataloader.num_workers = max(2, cfg.test_dataloader.get(\"num_workers\", 2))\n",
    "cfg.test_dataloader.dataset.pipeline[1][\"scale\"] = (512, 512)\n",
    "\n",
    "# validate 비활성화\n",
    "for k in (\"val_dataloader\", \"val_evaluator\", \"val_cfg\", \"val_loop\"):\n",
    "    cfg.pop(k, None)\n",
    "cfg.train_cfg = cfg.get(\"train_cfg\", {})\n",
    "cfg.train_cfg[\"val_interval\"] = 0\n",
    "\n",
    "# 학습 config 수정\n",
    "cfg.device = \"cuda\"\n",
    "cfg.gpu_ids = [0]\n",
    "cfg.randomness = dict(seed=2025, deterministic=False)\n",
    "cfg.work_dir = \"./work_dirs/cascade_rcnn_r50_fpn_1x_trash\"\n",
    "\n",
    "for i in range(3):\n",
    "    cfg.model.roi_head.bbox_head[i].num_classes = len(classes)\n",
    "cfg.optim_wrapper = {**cfg.get(\"optim_wrapper\", {}), \"clip_grad\": dict(max_norm=35, norm_type=2)}\n",
    "\n",
    "cfg.train_cfg.max_epochs = 18\n",
    "cfg.default_hooks[\"checkpoint\"][\"max_keep_ckpts\"] = 3\n",
    "cfg.default_hooks[\"checkpoint\"][\"interval\"] = 1\n",
    "\n",
    "\n",
    "vis_backends = [\n",
    "    dict(type='LocalVisBackend'),\n",
    "        dict(\n",
    "        type='WandbVisBackend',\n",
    "        init_kwargs=dict(\n",
    "            project='cv_11_OD',     # 너가 보고 싶은 프로젝트\n",
    "            entity='cv_11',      # 팀 이름\n",
    "            name='cascade_rcnn_test'\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "cfg.visualizer = dict(\n",
    "    type='DetLocalVisualizer',\n",
    "    vis_backends=vis_backends,\n",
    "    name='visualizer'\n",
    ")\n",
    "\n",
    "cfg.log_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      " [Info] CocoDataset Train dataset with number of images 4883, and instance counts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 [General trash]</td>\n",
       "      <td>3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 [Paper]</td>\n",
       "      <td>6352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 [Paper pack]</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 [Metal]</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 [Glass]</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5 [Plastic]</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6 [Styrofoam]</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7 [Plastic bag]</td>\n",
       "      <td>5178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8 [Battery]</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9 [Clothing]</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            category  count\n",
       "0  0 [General trash]   3965\n",
       "1          1 [Paper]   6352\n",
       "2     2 [Paper pack]    897\n",
       "3          3 [Metal]    936\n",
       "4          4 [Glass]    982\n",
       "5        5 [Plastic]   2943\n",
       "6      6 [Styrofoam]   1263\n",
       "7    7 [Plastic bag]   5178\n",
       "8        8 [Battery]    159\n",
       "9       9 [Clothing]    468"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset summarization 확인\n",
    "train_ds_cfg = cfg.train_dataloader.dataset\n",
    "train_ds = DATASETS.build(train_ds_cfg)\n",
    "\n",
    "def summarize_dataset(ds):\n",
    "    ds.full_init()\n",
    "    num_images = len(ds)\n",
    "    classes = list(ds.metainfo.get(\"classes\", []))\n",
    "\n",
    "    counts = Counter()\n",
    "    for i in range(num_images):\n",
    "        info = ds.get_data_info(i)\n",
    "        for inst in info.get(\"instances\", []):\n",
    "            lbl = inst.get(\"bbox_label\", None)\n",
    "            if lbl is not None:\n",
    "                counts[lbl] += 1\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"category\": [f\"{i} [{c}]\" for i, c in enumerate(classes)],\n",
    "        \"count\": [counts.get(i, 0) for i in range(len(classes))]\n",
    "    })\n",
    "\n",
    "    print(f\"\\n [Info] CocoDataset Train dataset with number of images {num_images}, and instance counts:\")\n",
    "    display(df)\n",
    "\n",
    "summarize_dataset(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/08 02:45:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 2025\n",
      "    GPU 0: Tesla V100-SXM2-32GB\n",
      "    CUDA_HOME: None\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 2.1.0+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.0+cu118\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 2025\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "12/08 02:45:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/coco/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=3, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "device = 'cuda'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "gpu_ids = [\n",
      "    0,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=50,\n",
      "        frozen_stages=1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                        0.2,\n",
      "                        0.2,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=10,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.05,\n",
      "                        0.05,\n",
      "                        0.1,\n",
      "                        0.1,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=10,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "            dict(\n",
      "                bbox_coder=dict(\n",
      "                    target_means=[\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                        0.0,\n",
      "                    ],\n",
      "                    target_stds=[\n",
      "                        0.033,\n",
      "                        0.033,\n",
      "                        0.067,\n",
      "                        0.067,\n",
      "                    ],\n",
      "                    type='DeltaXYWHBBoxCoder'),\n",
      "                fc_out_channels=1024,\n",
      "                in_channels=256,\n",
      "                loss_bbox=dict(beta=1.0, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "                loss_cls=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                num_classes=10,\n",
      "                reg_class_agnostic=True,\n",
      "                roi_feat_size=7,\n",
      "                type='Shared2FCBBoxHead'),\n",
      "        ],\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[\n",
      "            1,\n",
      "            0.5,\n",
      "            0.25,\n",
      "        ],\n",
      "        type='CascadeRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(\n",
      "            beta=0.1111111111111111, loss_weight=1.0, type='SmoothL1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.05),\n",
      "        rpn=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=1000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    pos_iou_thr=0.5,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    pos_iou_thr=0.6,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    ignore_iof_thr=-1,\n",
      "                    match_low_quality=False,\n",
      "                    min_pos_iou=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    pos_iou_thr=0.7,\n",
      "                    type='MaxIoUAssigner'),\n",
      "                debug=False,\n",
      "                pos_weight=-1,\n",
      "                sampler=dict(\n",
      "                    add_gt_as_proposals=True,\n",
      "                    neg_pos_ub=-1,\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    type='RandomSampler')),\n",
      "        ],\n",
      "        rpn=dict(\n",
      "            allowed_border=0,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=2000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='CascadeRCNN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=35, norm_type=2),\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=12,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            8,\n",
      "            11,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "randomness = dict(deterministic=False, seed=2025)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='test.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='../../dataset/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=18, type='EpochBasedTrainLoop', val_interval=0)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file='train.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='../../dataset/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                brightness_delta=20,\n",
      "                contrast_range=(\n",
      "                    0.8,\n",
      "                    1.2,\n",
      "                ),\n",
      "                hue_delta=10,\n",
      "                saturation_range=(\n",
      "                    0.8,\n",
      "                    1.2,\n",
      "                ),\n",
      "                type='PhotoMetricDistortion'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(\n",
      "            init_kwargs=dict(\n",
      "                entity='cv_11', name='cascade_rcnn_test', project='cv_11_OD'),\n",
      "            type='WandbVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/cascade_rcnn_r50_fpn_1x_trash'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/kkhs/mmdetection/work_dirs/cascade_rcnn_r50_fpn_1x_trash/20251208_024525/vis_data/wandb/run-20251208_024538-9fl39hxj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cv_11/cv_11_OD/runs/9fl39hxj' target=\"_blank\">cascade_rcnn_test</a></strong> to <a href='https://wandb.ai/cv_11/cv_11_OD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cv_11/cv_11_OD' target=\"_blank\">https://wandb.ai/cv_11/cv_11_OD</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cv_11/cv_11_OD/runs/9fl39hxj' target=\"_blank\">https://wandb.ai/cv_11/cv_11_OD/runs/9fl39hxj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/08 02:45:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "12/08 02:45:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "12/08 02:45:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: torchvision://resnet50\n",
      "12/08 02:45:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by torchvision backend from path: torchvision://resnet50\n",
      "12/08 02:45:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "12/08 02:45:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "12/08 02:45:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "12/08 02:45:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /data/ephemeral/home/kkhs/mmdetection/work_dirs/cascade_rcnn_r50_fpn_1x_trash.\n",
      "12/08 02:46:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  50/1221]  lr: 1.9820e-03  eta: 1:52:34  time: 0.3080  data_time: 0.0150  memory: 2343  grad_norm: 9.1816  loss: 1.7143  loss_rpn_cls: 0.4166  loss_rpn_bbox: 0.0516  s0.loss_cls: 0.6568  s0.acc: 92.7246  s0.loss_bbox: 0.1079  s1.loss_cls: 0.2998  s1.acc: 96.3867  s1.loss_bbox: 0.0299  s2.loss_cls: 0.1476  s2.acc: 98.1445  s2.loss_bbox: 0.0042\n",
      "12/08 02:46:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 100/1221]  lr: 3.9840e-03  eta: 1:47:41  time: 0.2826  data_time: 0.0083  memory: 2343  grad_norm: 2.8830  loss: 0.8496  loss_rpn_cls: 0.1474  loss_rpn_bbox: 0.0415  s0.loss_cls: 0.3268  s0.acc: 92.8711  s0.loss_bbox: 0.1650  s1.loss_cls: 0.0891  s1.acc: 97.1680  s1.loss_bbox: 0.0470  s2.loss_cls: 0.0265  s2.acc: 98.7305  s2.loss_bbox: 0.0065\n",
      "12/08 02:46:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 150/1221]  lr: 5.9860e-03  eta: 1:45:43  time: 0.2812  data_time: 0.0082  memory: 2343  grad_norm: 3.4538  loss: 0.8436  loss_rpn_cls: 0.1336  loss_rpn_bbox: 0.0367  s0.loss_cls: 0.3377  s0.acc: 91.6504  s0.loss_bbox: 0.1577  s1.loss_cls: 0.0931  s1.acc: 96.6797  s1.loss_bbox: 0.0515  s2.loss_cls: 0.0263  s2.acc: 98.5352  s2.loss_bbox: 0.0070\n",
      "12/08 02:46:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 200/1221]  lr: 7.9880e-03  eta: 1:45:01  time: 0.2855  data_time: 0.0085  memory: 2343  grad_norm: 3.0712  loss: 0.9535  loss_rpn_cls: 0.1352  loss_rpn_bbox: 0.0444  s0.loss_cls: 0.3692  s0.acc: 95.7031  s0.loss_bbox: 0.1831  s1.loss_cls: 0.1093  s1.acc: 97.1191  s1.loss_bbox: 0.0717  s2.loss_cls: 0.0298  s2.acc: 98.7793  s2.loss_bbox: 0.0108\n",
      "12/08 02:47:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 250/1221]  lr: 9.9900e-03  eta: 1:45:26  time: 0.2984  data_time: 0.0094  memory: 2343  grad_norm: 3.1052  loss: 0.8853  loss_rpn_cls: 0.1140  loss_rpn_bbox: 0.0399  s0.loss_cls: 0.3388  s0.acc: 94.4336  s0.loss_bbox: 0.1494  s1.loss_cls: 0.1150  s1.acc: 96.2402  s1.loss_bbox: 0.0785  s2.loss_cls: 0.0341  s2.acc: 97.9492  s2.loss_bbox: 0.0156\n",
      "12/08 02:47:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 300/1221]  lr: 1.1992e-02  eta: 1:44:29  time: 0.2795  data_time: 0.0084  memory: 2342  grad_norm: 2.7962  loss: 0.8664  loss_rpn_cls: 0.0976  loss_rpn_bbox: 0.0404  s0.loss_cls: 0.3172  s0.acc: 90.6738  s0.loss_bbox: 0.1379  s1.loss_cls: 0.1232  s1.acc: 93.7012  s1.loss_bbox: 0.0886  s2.loss_cls: 0.0392  s2.acc: 96.6797  s2.loss_bbox: 0.0223\n",
      "12/08 02:47:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 350/1221]  lr: 1.3994e-02  eta: 1:43:47  time: 0.2804  data_time: 0.0093  memory: 2342  grad_norm: 2.8335  loss: 0.9525  loss_rpn_cls: 0.0949  loss_rpn_bbox: 0.0374  s0.loss_cls: 0.3505  s0.acc: 95.5566  s0.loss_bbox: 0.1523  s1.loss_cls: 0.1385  s1.acc: 95.9473  s1.loss_bbox: 0.1005  s2.loss_cls: 0.0476  s2.acc: 97.4609  s2.loss_bbox: 0.0309\n",
      "12/08 02:47:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 400/1221]  lr: 1.5996e-02  eta: 1:43:12  time: 0.2802  data_time: 0.0084  memory: 2343  grad_norm: 3.3642  loss: 1.0000  loss_rpn_cls: 0.1184  loss_rpn_bbox: 0.0416  s0.loss_cls: 0.3641  s0.acc: 86.2793  s0.loss_bbox: 0.1525  s1.loss_cls: 0.1430  s1.acc: 90.7715  s1.loss_bbox: 0.0969  s2.loss_cls: 0.0509  s2.acc: 95.1172  s2.loss_bbox: 0.0326\n",
      "12/08 02:47:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 450/1221]  lr: 1.7998e-02  eta: 1:42:53  time: 0.2848  data_time: 0.0088  memory: 2343  grad_norm: 3.1386  loss: 0.8885  loss_rpn_cls: 0.1243  loss_rpn_bbox: 0.0506  s0.loss_cls: 0.3095  s0.acc: 91.2598  s0.loss_bbox: 0.1272  s1.loss_cls: 0.1195  s1.acc: 92.9199  s1.loss_bbox: 0.0830  s2.loss_cls: 0.0442  s2.acc: 94.7266  s2.loss_bbox: 0.0302\n",
      "12/08 02:48:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 500/1221]  lr: 2.0000e-02  eta: 1:42:25  time: 0.2804  data_time: 0.0086  memory: 2343  grad_norm: 3.0105  loss: 1.0601  loss_rpn_cls: 0.1376  loss_rpn_bbox: 0.0468  s0.loss_cls: 0.3902  s0.acc: 95.8008  s0.loss_bbox: 0.1597  s1.loss_cls: 0.1486  s1.acc: 96.6797  s1.loss_bbox: 0.0954  s2.loss_cls: 0.0517  s2.acc: 97.8027  s2.loss_bbox: 0.0300\n",
      "12/08 02:48:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 550/1221]  lr: 2.0000e-02  eta: 1:41:58  time: 0.2795  data_time: 0.0084  memory: 2342  grad_norm: 2.2473  loss: 0.9045  loss_rpn_cls: 0.0901  loss_rpn_bbox: 0.0332  s0.loss_cls: 0.3212  s0.acc: 88.8672  s0.loss_bbox: 0.1361  s1.loss_cls: 0.1349  s1.acc: 90.5762  s1.loss_bbox: 0.0980  s2.loss_cls: 0.0517  s2.acc: 91.2109  s2.loss_bbox: 0.0393\n",
      "12/08 02:48:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 600/1221]  lr: 2.0000e-02  eta: 1:41:28  time: 0.2768  data_time: 0.0085  memory: 2342  grad_norm: 2.4982  loss: 1.0544  loss_rpn_cls: 0.1153  loss_rpn_bbox: 0.0426  s0.loss_cls: 0.3776  s0.acc: 89.4531  s0.loss_bbox: 0.1560  s1.loss_cls: 0.1526  s1.acc: 89.9902  s1.loss_bbox: 0.1082  s2.loss_cls: 0.0582  s2.acc: 89.6484  s2.loss_bbox: 0.0439\n",
      "12/08 02:48:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 650/1221]  lr: 2.0000e-02  eta: 1:41:05  time: 0.2799  data_time: 0.0085  memory: 2343  grad_norm: 2.8254  loss: 1.0919  loss_rpn_cls: 0.1153  loss_rpn_bbox: 0.0448  s0.loss_cls: 0.3747  s0.acc: 87.5977  s0.loss_bbox: 0.1661  s1.loss_cls: 0.1602  s1.acc: 92.0410  s1.loss_bbox: 0.1200  s2.loss_cls: 0.0628  s2.acc: 94.9707  s2.loss_bbox: 0.0481\n",
      "12/08 02:49:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 700/1221]  lr: 2.0000e-02  eta: 1:40:49  time: 0.2833  data_time: 0.0088  memory: 2342  grad_norm: 2.1594  loss: 0.9696  loss_rpn_cls: 0.1009  loss_rpn_bbox: 0.0385  s0.loss_cls: 0.3529  s0.acc: 95.4102  s0.loss_bbox: 0.1376  s1.loss_cls: 0.1462  s1.acc: 96.6797  s1.loss_bbox: 0.0961  s2.loss_cls: 0.0571  s2.acc: 97.4121  s2.loss_bbox: 0.0404\n",
      "12/08 02:49:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 750/1221]  lr: 2.0000e-02  eta: 1:40:25  time: 0.2768  data_time: 0.0084  memory: 2342  grad_norm: 2.1045  loss: 0.8729  loss_rpn_cls: 0.0982  loss_rpn_bbox: 0.0356  s0.loss_cls: 0.3093  s0.acc: 90.7715  s0.loss_bbox: 0.1208  s1.loss_cls: 0.1306  s1.acc: 94.0918  s1.loss_bbox: 0.0861  s2.loss_cls: 0.0533  s2.acc: 96.1426  s2.loss_bbox: 0.0390\n",
      "12/08 02:49:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 800/1221]  lr: 2.0000e-02  eta: 1:40:06  time: 0.2807  data_time: 0.0087  memory: 2343  grad_norm: 2.2155  loss: 0.9245  loss_rpn_cls: 0.0927  loss_rpn_bbox: 0.0339  s0.loss_cls: 0.3209  s0.acc: 87.8418  s0.loss_bbox: 0.1299  s1.loss_cls: 0.1410  s1.acc: 90.0879  s1.loss_bbox: 0.1002  s2.loss_cls: 0.0586  s2.acc: 91.7969  s2.loss_bbox: 0.0474\n",
      "12/08 02:49:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 850/1221]  lr: 2.0000e-02  eta: 1:39:50  time: 0.2820  data_time: 0.0088  memory: 2343  grad_norm: 2.4255  loss: 1.0909  loss_rpn_cls: 0.1099  loss_rpn_bbox: 0.0426  s0.loss_cls: 0.3804  s0.acc: 88.3789  s0.loss_bbox: 0.1527  s1.loss_cls: 0.1698  s1.acc: 90.3320  s1.loss_bbox: 0.1158  s2.loss_cls: 0.0694  s2.acc: 93.7012  s2.loss_bbox: 0.0504\n",
      "12/08 02:50:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 900/1221]  lr: 2.0000e-02  eta: 1:39:32  time: 0.2799  data_time: 0.0087  memory: 2342  grad_norm: 2.2259  loss: 0.9922  loss_rpn_cls: 0.0907  loss_rpn_bbox: 0.0362  s0.loss_cls: 0.3358  s0.acc: 93.6523  s0.loss_bbox: 0.1418  s1.loss_cls: 0.1544  s1.acc: 95.3613  s1.loss_bbox: 0.1158  s2.loss_cls: 0.0656  s2.acc: 95.8984  s2.loss_bbox: 0.0520\n",
      "12/08 02:50:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 950/1221]  lr: 2.0000e-02  eta: 1:39:11  time: 0.2774  data_time: 0.0086  memory: 2342  grad_norm: 2.4825  loss: 1.0778  loss_rpn_cls: 0.1219  loss_rpn_bbox: 0.0473  s0.loss_cls: 0.3784  s0.acc: 97.2168  s0.loss_bbox: 0.1440  s1.loss_cls: 0.1629  s1.acc: 97.6074  s1.loss_bbox: 0.1079  s2.loss_cls: 0.0664  s2.acc: 97.8516  s2.loss_bbox: 0.0490\n",
      "12/08 02:50:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 02:50:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1000/1221]  lr: 2.0000e-02  eta: 1:38:51  time: 0.2780  data_time: 0.0080  memory: 2342  grad_norm: 2.1336  loss: 0.9561  loss_rpn_cls: 0.0802  loss_rpn_bbox: 0.0341  s0.loss_cls: 0.3351  s0.acc: 92.6270  s0.loss_bbox: 0.1304  s1.loss_cls: 0.1548  s1.acc: 93.7988  s1.loss_bbox: 0.1074  s2.loss_cls: 0.0642  s2.acc: 95.2148  s2.loss_bbox: 0.0498\n",
      "12/08 02:50:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1050/1221]  lr: 2.0000e-02  eta: 1:38:35  time: 0.2802  data_time: 0.0086  memory: 2342  grad_norm: 2.1151  loss: 0.8765  loss_rpn_cls: 0.0752  loss_rpn_bbox: 0.0309  s0.loss_cls: 0.3125  s0.acc: 87.5977  s0.loss_bbox: 0.1164  s1.loss_cls: 0.1436  s1.acc: 88.1836  s1.loss_bbox: 0.0922  s2.loss_cls: 0.0617  s2.acc: 89.5508  s2.loss_bbox: 0.0441\n",
      "12/08 02:51:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1100/1221]  lr: 2.0000e-02  eta: 1:38:22  time: 0.2845  data_time: 0.0084  memory: 2343  grad_norm: 2.3286  loss: 0.9826  loss_rpn_cls: 0.0918  loss_rpn_bbox: 0.0338  s0.loss_cls: 0.3478  s0.acc: 92.3340  s0.loss_bbox: 0.1338  s1.loss_cls: 0.1567  s1.acc: 91.6992  s1.loss_bbox: 0.1054  s2.loss_cls: 0.0659  s2.acc: 91.3574  s2.loss_bbox: 0.0475\n",
      "12/08 02:51:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1150/1221]  lr: 2.0000e-02  eta: 1:38:07  time: 0.2815  data_time: 0.0084  memory: 2343  grad_norm: 2.1578  loss: 0.9979  loss_rpn_cls: 0.0893  loss_rpn_bbox: 0.0421  s0.loss_cls: 0.3515  s0.acc: 87.0117  s0.loss_bbox: 0.1423  s1.loss_cls: 0.1551  s1.acc: 87.6953  s1.loss_bbox: 0.1045  s2.loss_cls: 0.0656  s2.acc: 89.8438  s2.loss_bbox: 0.0474\n",
      "12/08 02:51:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1200/1221]  lr: 2.0000e-02  eta: 1:37:51  time: 0.2800  data_time: 0.0085  memory: 2342  grad_norm: 2.1669  loss: 1.0469  loss_rpn_cls: 0.0851  loss_rpn_bbox: 0.0353  s0.loss_cls: 0.3650  s0.acc: 95.9961  s0.loss_bbox: 0.1463  s1.loss_cls: 0.1689  s1.acc: 95.0195  s1.loss_bbox: 0.1180  s2.loss_cls: 0.0729  s2.acc: 96.0449  s2.loss_bbox: 0.0553\n",
      "12/08 02:51:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 02:51:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "12/08 02:51:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][  50/1221]  lr: 2.0000e-02  eta: 1:37:30  time: 0.2841  data_time: 0.0113  memory: 2342  grad_norm: 2.2046  loss: 0.9363  loss_rpn_cls: 0.0663  loss_rpn_bbox: 0.0279  s0.loss_cls: 0.3348  s0.acc: 84.3750  s0.loss_bbox: 0.1275  s1.loss_cls: 0.1532  s1.acc: 85.4004  s1.loss_bbox: 0.1062  s2.loss_cls: 0.0668  s2.acc: 88.0859  s2.loss_bbox: 0.0536\n",
      "12/08 02:52:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 100/1221]  lr: 2.0000e-02  eta: 1:37:12  time: 0.2775  data_time: 0.0084  memory: 2342  grad_norm: 2.1314  loss: 0.9110  loss_rpn_cls: 0.0743  loss_rpn_bbox: 0.0301  s0.loss_cls: 0.3204  s0.acc: 93.4082  s0.loss_bbox: 0.1233  s1.loss_cls: 0.1470  s1.acc: 93.1641  s1.loss_bbox: 0.1005  s2.loss_cls: 0.0645  s2.acc: 93.2617  s2.loss_bbox: 0.0510\n",
      "12/08 02:52:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 150/1221]  lr: 2.0000e-02  eta: 1:36:58  time: 0.2828  data_time: 0.0087  memory: 2342  grad_norm: 2.2029  loss: 0.9596  loss_rpn_cls: 0.0977  loss_rpn_bbox: 0.0347  s0.loss_cls: 0.3257  s0.acc: 88.6230  s0.loss_bbox: 0.1243  s1.loss_cls: 0.1544  s1.acc: 89.2578  s1.loss_bbox: 0.1025  s2.loss_cls: 0.0687  s2.acc: 90.9180  s2.loss_bbox: 0.0515\n",
      "12/08 02:52:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 200/1221]  lr: 2.0000e-02  eta: 1:36:41  time: 0.2782  data_time: 0.0086  memory: 2342  grad_norm: 2.0905  loss: 0.8419  loss_rpn_cls: 0.0699  loss_rpn_bbox: 0.0294  s0.loss_cls: 0.2901  s0.acc: 90.5762  s0.loss_bbox: 0.1109  s1.loss_cls: 0.1382  s1.acc: 90.3762  s1.loss_bbox: 0.0932  s2.loss_cls: 0.0619  s2.acc: 91.2555  s2.loss_bbox: 0.0483\n",
      "12/08 02:52:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 250/1221]  lr: 2.0000e-02  eta: 1:36:24  time: 0.2787  data_time: 0.0088  memory: 2342  grad_norm: 1.9596  loss: 0.8722  loss_rpn_cls: 0.0638  loss_rpn_bbox: 0.0321  s0.loss_cls: 0.3006  s0.acc: 90.8691  s0.loss_bbox: 0.1134  s1.loss_cls: 0.1477  s1.acc: 90.0879  s1.loss_bbox: 0.0989  s2.loss_cls: 0.0665  s2.acc: 91.9434  s2.loss_bbox: 0.0492\n",
      "12/08 02:53:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 300/1221]  lr: 2.0000e-02  eta: 1:36:07  time: 0.2776  data_time: 0.0085  memory: 2342  grad_norm: 2.1303  loss: 0.9274  loss_rpn_cls: 0.0690  loss_rpn_bbox: 0.0327  s0.loss_cls: 0.3182  s0.acc: 91.1133  s0.loss_bbox: 0.1282  s1.loss_cls: 0.1518  s1.acc: 91.0156  s1.loss_bbox: 0.1082  s2.loss_cls: 0.0664  s2.acc: 91.5527  s2.loss_bbox: 0.0529\n",
      "12/08 02:53:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 350/1221]  lr: 2.0000e-02  eta: 1:35:50  time: 0.2780  data_time: 0.0083  memory: 2342  grad_norm: 2.2597  loss: 0.9331  loss_rpn_cls: 0.0804  loss_rpn_bbox: 0.0314  s0.loss_cls: 0.3231  s0.acc: 92.3340  s0.loss_bbox: 0.1261  s1.loss_cls: 0.1523  s1.acc: 91.9922  s1.loss_bbox: 0.1011  s2.loss_cls: 0.0666  s2.acc: 93.3105  s2.loss_bbox: 0.0519\n",
      "12/08 02:53:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 400/1221]  lr: 2.0000e-02  eta: 1:35:35  time: 0.2788  data_time: 0.0085  memory: 2342  grad_norm: 2.1797  loss: 0.9959  loss_rpn_cls: 0.0703  loss_rpn_bbox: 0.0296  s0.loss_cls: 0.3539  s0.acc: 94.0918  s0.loss_bbox: 0.1323  s1.loss_cls: 0.1679  s1.acc: 93.7500  s1.loss_bbox: 0.1117  s2.loss_cls: 0.0746  s2.acc: 93.2129  s2.loss_bbox: 0.0558\n",
      "12/08 02:53:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 450/1221]  lr: 2.0000e-02  eta: 1:35:21  time: 0.2831  data_time: 0.0084  memory: 2342  grad_norm: 2.3210  loss: 1.0137  loss_rpn_cls: 0.0802  loss_rpn_bbox: 0.0375  s0.loss_cls: 0.3417  s0.acc: 89.2578  s0.loss_bbox: 0.1407  s1.loss_cls: 0.1633  s1.acc: 88.9648  s1.loss_bbox: 0.1179  s2.loss_cls: 0.0727  s2.acc: 91.6992  s2.loss_bbox: 0.0597\n",
      "12/08 02:53:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 500/1221]  lr: 2.0000e-02  eta: 1:35:06  time: 0.2790  data_time: 0.0086  memory: 2342  grad_norm: 2.2973  loss: 0.9884  loss_rpn_cls: 0.0807  loss_rpn_bbox: 0.0380  s0.loss_cls: 0.3303  s0.acc: 89.6484  s0.loss_bbox: 0.1411  s1.loss_cls: 0.1555  s1.acc: 91.2358  s1.loss_bbox: 0.1161  s2.loss_cls: 0.0696  s2.acc: 91.4412  s2.loss_bbox: 0.0571\n",
      "12/08 02:54:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 550/1221]  lr: 2.0000e-02  eta: 1:34:49  time: 0.2781  data_time: 0.0084  memory: 2342  grad_norm: 2.1718  loss: 0.8484  loss_rpn_cls: 0.0653  loss_rpn_bbox: 0.0337  s0.loss_cls: 0.2863  s0.acc: 90.9668  s0.loss_bbox: 0.1099  s1.loss_cls: 0.1401  s1.acc: 91.7969  s1.loss_bbox: 0.0967  s2.loss_cls: 0.0644  s2.acc: 92.5293  s2.loss_bbox: 0.0520\n",
      "12/08 02:54:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 600/1221]  lr: 2.0000e-02  eta: 1:34:33  time: 0.2782  data_time: 0.0084  memory: 2342  grad_norm: 2.2998  loss: 0.8856  loss_rpn_cls: 0.0845  loss_rpn_bbox: 0.0344  s0.loss_cls: 0.3007  s0.acc: 96.1914  s0.loss_bbox: 0.1135  s1.loss_cls: 0.1463  s1.acc: 95.8008  s1.loss_bbox: 0.0926  s2.loss_cls: 0.0663  s2.acc: 96.5332  s2.loss_bbox: 0.0473\n",
      "12/08 02:54:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 650/1221]  lr: 2.0000e-02  eta: 1:34:19  time: 0.2802  data_time: 0.0086  memory: 2342  grad_norm: 1.9553  loss: 0.8508  loss_rpn_cls: 0.0648  loss_rpn_bbox: 0.0292  s0.loss_cls: 0.2931  s0.acc: 96.3867  s0.loss_bbox: 0.1143  s1.loss_cls: 0.1407  s1.acc: 96.7773  s1.loss_bbox: 0.0978  s2.loss_cls: 0.0633  s2.acc: 95.7520  s2.loss_bbox: 0.0475\n",
      "12/08 02:54:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 700/1221]  lr: 2.0000e-02  eta: 1:34:03  time: 0.2789  data_time: 0.0086  memory: 2343  grad_norm: 2.2772  loss: 0.9841  loss_rpn_cls: 0.0829  loss_rpn_bbox: 0.0401  s0.loss_cls: 0.3364  s0.acc: 88.5254  s0.loss_bbox: 0.1315  s1.loss_cls: 0.1619  s1.acc: 89.6484  s1.loss_bbox: 0.1064  s2.loss_cls: 0.0727  s2.acc: 91.2598  s2.loss_bbox: 0.0522\n",
      "12/08 02:55:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 750/1221]  lr: 2.0000e-02  eta: 1:33:49  time: 0.2813  data_time: 0.0088  memory: 2342  grad_norm: 2.2320  loss: 0.9418  loss_rpn_cls: 0.0853  loss_rpn_bbox: 0.0335  s0.loss_cls: 0.3205  s0.acc: 95.9473  s0.loss_bbox: 0.1245  s1.loss_cls: 0.1550  s1.acc: 95.3125  s1.loss_bbox: 0.1029  s2.loss_cls: 0.0695  s2.acc: 95.8496  s2.loss_bbox: 0.0504\n",
      "12/08 02:55:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 02:55:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 800/1221]  lr: 2.0000e-02  eta: 1:33:37  time: 0.2844  data_time: 0.0087  memory: 2342  grad_norm: 2.3496  loss: 1.0244  loss_rpn_cls: 0.0869  loss_rpn_bbox: 0.0354  s0.loss_cls: 0.3518  s0.acc: 89.8926  s0.loss_bbox: 0.1375  s1.loss_cls: 0.1680  s1.acc: 90.0879  s1.loss_bbox: 0.1156  s2.loss_cls: 0.0736  s2.acc: 91.6016  s2.loss_bbox: 0.0555\n",
      "12/08 02:55:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 850/1221]  lr: 2.0000e-02  eta: 1:33:21  time: 0.2788  data_time: 0.0086  memory: 2343  grad_norm: 2.2284  loss: 0.9665  loss_rpn_cls: 0.0660  loss_rpn_bbox: 0.0335  s0.loss_cls: 0.3404  s0.acc: 87.3535  s0.loss_bbox: 0.1266  s1.loss_cls: 0.1653  s1.acc: 88.9160  s1.loss_bbox: 0.1085  s2.loss_cls: 0.0735  s2.acc: 92.3828  s2.loss_bbox: 0.0527\n",
      "12/08 02:55:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 900/1221]  lr: 2.0000e-02  eta: 1:33:08  time: 0.2822  data_time: 0.0085  memory: 2342  grad_norm: 2.2046  loss: 0.9116  loss_rpn_cls: 0.0799  loss_rpn_bbox: 0.0329  s0.loss_cls: 0.3058  s0.acc: 92.1387  s0.loss_bbox: 0.1209  s1.loss_cls: 0.1488  s1.acc: 92.3305  s1.loss_bbox: 0.1034  s2.loss_cls: 0.0677  s2.acc: 92.9208  s2.loss_bbox: 0.0521\n",
      "12/08 02:56:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 950/1221]  lr: 2.0000e-02  eta: 1:32:54  time: 0.2819  data_time: 0.0088  memory: 2342  grad_norm: 2.0566  loss: 0.7914  loss_rpn_cls: 0.0643  loss_rpn_bbox: 0.0273  s0.loss_cls: 0.2664  s0.acc: 87.1094  s0.loss_bbox: 0.1009  s1.loss_cls: 0.1327  s1.acc: 87.3343  s1.loss_bbox: 0.0912  s2.loss_cls: 0.0618  s2.acc: 88.7255  s2.loss_bbox: 0.0469\n",
      "12/08 02:56:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1000/1221]  lr: 2.0000e-02  eta: 1:32:40  time: 0.2825  data_time: 0.0089  memory: 2343  grad_norm: 2.1743  loss: 0.9522  loss_rpn_cls: 0.0820  loss_rpn_bbox: 0.0302  s0.loss_cls: 0.3266  s0.acc: 90.6738  s0.loss_bbox: 0.1205  s1.loss_cls: 0.1607  s1.acc: 89.8926  s1.loss_bbox: 0.1041  s2.loss_cls: 0.0733  s2.acc: 92.3340  s2.loss_bbox: 0.0549\n",
      "12/08 02:56:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1050/1221]  lr: 2.0000e-02  eta: 1:32:26  time: 0.2812  data_time: 0.0085  memory: 2342  grad_norm: 2.2452  loss: 0.8691  loss_rpn_cls: 0.0739  loss_rpn_bbox: 0.0284  s0.loss_cls: 0.2967  s0.acc: 91.5527  s0.loss_bbox: 0.1055  s1.loss_cls: 0.1484  s1.acc: 91.6992  s1.loss_bbox: 0.0978  s2.loss_cls: 0.0677  s2.acc: 92.8711  s2.loss_bbox: 0.0507\n",
      "12/08 02:56:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1100/1221]  lr: 2.0000e-02  eta: 1:32:11  time: 0.2797  data_time: 0.0084  memory: 2342  grad_norm: 2.2002  loss: 0.8724  loss_rpn_cls: 0.0675  loss_rpn_bbox: 0.0271  s0.loss_cls: 0.3083  s0.acc: 91.1133  s0.loss_bbox: 0.1124  s1.loss_cls: 0.1494  s1.acc: 90.2832  s1.loss_bbox: 0.0928  s2.loss_cls: 0.0673  s2.acc: 92.4316  s2.loss_bbox: 0.0474\n",
      "12/08 02:56:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1150/1221]  lr: 2.0000e-02  eta: 1:31:55  time: 0.2773  data_time: 0.0085  memory: 2342  grad_norm: 1.9309  loss: 0.7970  loss_rpn_cls: 0.0586  loss_rpn_bbox: 0.0238  s0.loss_cls: 0.2809  s0.acc: 89.2578  s0.loss_bbox: 0.1013  s1.loss_cls: 0.1357  s1.acc: 89.9902  s1.loss_bbox: 0.0895  s2.loss_cls: 0.0620  s2.acc: 91.0645  s2.loss_bbox: 0.0452\n",
      "12/08 02:57:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1200/1221]  lr: 2.0000e-02  eta: 1:31:40  time: 0.2790  data_time: 0.0085  memory: 2342  grad_norm: 2.2849  loss: 1.0299  loss_rpn_cls: 0.0810  loss_rpn_bbox: 0.0451  s0.loss_cls: 0.3397  s0.acc: 87.0605  s0.loss_bbox: 0.1473  s1.loss_cls: 0.1637  s1.acc: 87.9395  s1.loss_bbox: 0.1202  s2.loss_cls: 0.0737  s2.acc: 89.7949  s2.loss_bbox: 0.0590\n",
      "12/08 02:57:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 02:57:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "12/08 02:57:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][  50/1221]  lr: 2.0000e-02  eta: 1:31:21  time: 0.2853  data_time: 0.0125  memory: 2342  grad_norm: 2.2961  loss: 0.9192  loss_rpn_cls: 0.0626  loss_rpn_bbox: 0.0326  s0.loss_cls: 0.3217  s0.acc: 86.6211  s0.loss_bbox: 0.1189  s1.loss_cls: 0.1577  s1.acc: 87.1820  s1.loss_bbox: 0.1011  s2.loss_cls: 0.0723  s2.acc: 89.1007  s2.loss_bbox: 0.0524\n",
      "12/08 02:57:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 100/1221]  lr: 2.0000e-02  eta: 1:31:05  time: 0.2773  data_time: 0.0089  memory: 2343  grad_norm: 2.2910  loss: 0.9412  loss_rpn_cls: 0.0737  loss_rpn_bbox: 0.0362  s0.loss_cls: 0.3209  s0.acc: 89.4043  s0.loss_bbox: 0.1248  s1.loss_cls: 0.1566  s1.acc: 90.3320  s1.loss_bbox: 0.1048  s2.loss_cls: 0.0711  s2.acc: 92.0410  s2.loss_bbox: 0.0530\n",
      "12/08 02:58:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 150/1221]  lr: 2.0000e-02  eta: 1:30:50  time: 0.2779  data_time: 0.0086  memory: 2342  grad_norm: 2.0920  loss: 0.8258  loss_rpn_cls: 0.0583  loss_rpn_bbox: 0.0276  s0.loss_cls: 0.2884  s0.acc: 96.4844  s0.loss_bbox: 0.1117  s1.loss_cls: 0.1387  s1.acc: 96.0938  s1.loss_bbox: 0.0919  s2.loss_cls: 0.0630  s2.acc: 94.6777  s2.loss_bbox: 0.0463\n",
      "12/08 02:58:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 200/1221]  lr: 2.0000e-02  eta: 1:30:35  time: 0.2783  data_time: 0.0087  memory: 2342  grad_norm: 2.1022  loss: 0.8409  loss_rpn_cls: 0.0619  loss_rpn_bbox: 0.0306  s0.loss_cls: 0.2881  s0.acc: 87.9395  s0.loss_bbox: 0.1077  s1.loss_cls: 0.1411  s1.acc: 87.0117  s1.loss_bbox: 0.0962  s2.loss_cls: 0.0652  s2.acc: 87.5000  s2.loss_bbox: 0.0500\n",
      "12/08 02:58:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 250/1221]  lr: 2.0000e-02  eta: 1:30:22  time: 0.2839  data_time: 0.0089  memory: 2342  grad_norm: 2.1287  loss: 0.8394  loss_rpn_cls: 0.0633  loss_rpn_bbox: 0.0324  s0.loss_cls: 0.2835  s0.acc: 94.4824  s0.loss_bbox: 0.1105  s1.loss_cls: 0.1400  s1.acc: 94.6289  s1.loss_bbox: 0.0956  s2.loss_cls: 0.0645  s2.acc: 94.4336  s2.loss_bbox: 0.0495\n",
      "12/08 02:58:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 300/1221]  lr: 2.0000e-02  eta: 1:30:06  time: 0.2760  data_time: 0.0083  memory: 2342  grad_norm: 2.2162  loss: 0.8989  loss_rpn_cls: 0.0655  loss_rpn_bbox: 0.0304  s0.loss_cls: 0.3151  s0.acc: 96.6309  s0.loss_bbox: 0.1150  s1.loss_cls: 0.1529  s1.acc: 96.6309  s1.loss_bbox: 0.0986  s2.loss_cls: 0.0697  s2.acc: 97.2168  s2.loss_bbox: 0.0517\n",
      "12/08 02:58:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 350/1221]  lr: 2.0000e-02  eta: 1:29:51  time: 0.2786  data_time: 0.0087  memory: 2342  grad_norm: 2.3423  loss: 0.8715  loss_rpn_cls: 0.0638  loss_rpn_bbox: 0.0291  s0.loss_cls: 0.3058  s0.acc: 89.9414  s0.loss_bbox: 0.1126  s1.loss_cls: 0.1479  s1.acc: 89.8438  s1.loss_bbox: 0.0959  s2.loss_cls: 0.0668  s2.acc: 89.6973  s2.loss_bbox: 0.0497\n",
      "12/08 02:59:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 400/1221]  lr: 2.0000e-02  eta: 1:29:36  time: 0.2777  data_time: 0.0087  memory: 2342  grad_norm: 2.0577  loss: 0.8531  loss_rpn_cls: 0.0782  loss_rpn_bbox: 0.0302  s0.loss_cls: 0.2907  s0.acc: 93.6035  s0.loss_bbox: 0.1064  s1.loss_cls: 0.1415  s1.acc: 93.5547  s1.loss_bbox: 0.0945  s2.loss_cls: 0.0635  s2.acc: 94.6289  s2.loss_bbox: 0.0481\n",
      "12/08 02:59:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 450/1221]  lr: 2.0000e-02  eta: 1:29:22  time: 0.2809  data_time: 0.0086  memory: 2342  grad_norm: 2.2519  loss: 0.8872  loss_rpn_cls: 0.0699  loss_rpn_bbox: 0.0316  s0.loss_cls: 0.3033  s0.acc: 90.1367  s0.loss_bbox: 0.1165  s1.loss_cls: 0.1483  s1.acc: 89.7949  s1.loss_bbox: 0.1000  s2.loss_cls: 0.0679  s2.acc: 89.3555  s2.loss_bbox: 0.0497\n",
      "12/08 02:59:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 500/1221]  lr: 2.0000e-02  eta: 1:29:08  time: 0.2801  data_time: 0.0084  memory: 2342  grad_norm: 2.0883  loss: 0.8331  loss_rpn_cls: 0.0617  loss_rpn_bbox: 0.0270  s0.loss_cls: 0.2859  s0.acc: 83.4961  s0.loss_bbox: 0.1099  s1.loss_cls: 0.1379  s1.acc: 83.5393  s1.loss_bbox: 0.0979  s2.loss_cls: 0.0622  s2.acc: 87.3024  s2.loss_bbox: 0.0506\n",
      "12/08 02:59:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 550/1221]  lr: 2.0000e-02  eta: 1:28:53  time: 0.2782  data_time: 0.0085  memory: 2342  grad_norm: 2.0468  loss: 0.7689  loss_rpn_cls: 0.0639  loss_rpn_bbox: 0.0278  s0.loss_cls: 0.2613  s0.acc: 88.3301  s0.loss_bbox: 0.0944  s1.loss_cls: 0.1332  s1.acc: 88.6230  s1.loss_bbox: 0.0821  s2.loss_cls: 0.0624  s2.acc: 89.6973  s2.loss_bbox: 0.0438\n",
      "12/08 02:59:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:00:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 600/1221]  lr: 2.0000e-02  eta: 1:28:39  time: 0.2810  data_time: 0.0084  memory: 2342  grad_norm: 2.2142  loss: 0.8963  loss_rpn_cls: 0.0685  loss_rpn_bbox: 0.0265  s0.loss_cls: 0.3082  s0.acc: 90.9180  s0.loss_bbox: 0.1179  s1.loss_cls: 0.1509  s1.acc: 89.1602  s1.loss_bbox: 0.1003  s2.loss_cls: 0.0700  s2.acc: 90.2344  s2.loss_bbox: 0.0540\n",
      "12/08 03:00:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 650/1221]  lr: 2.0000e-02  eta: 1:28:24  time: 0.2788  data_time: 0.0085  memory: 2342  grad_norm: 2.2781  loss: 0.9299  loss_rpn_cls: 0.0631  loss_rpn_bbox: 0.0311  s0.loss_cls: 0.3187  s0.acc: 96.8750  s0.loss_bbox: 0.1255  s1.loss_cls: 0.1536  s1.acc: 96.1426  s1.loss_bbox: 0.1095  s2.loss_cls: 0.0703  s2.acc: 95.8984  s2.loss_bbox: 0.0580\n",
      "12/08 03:00:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 700/1221]  lr: 2.0000e-02  eta: 1:28:10  time: 0.2807  data_time: 0.0090  memory: 2342  grad_norm: 2.4074  loss: 0.9129  loss_rpn_cls: 0.0668  loss_rpn_bbox: 0.0320  s0.loss_cls: 0.3138  s0.acc: 93.5059  s0.loss_bbox: 0.1187  s1.loss_cls: 0.1539  s1.acc: 93.5547  s1.loss_bbox: 0.1024  s2.loss_cls: 0.0706  s2.acc: 93.8965  s2.loss_bbox: 0.0547\n",
      "12/08 03:00:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 750/1221]  lr: 2.0000e-02  eta: 1:27:55  time: 0.2770  data_time: 0.0083  memory: 2342  grad_norm: 2.2540  loss: 0.8255  loss_rpn_cls: 0.0566  loss_rpn_bbox: 0.0235  s0.loss_cls: 0.2925  s0.acc: 93.2617  s0.loss_bbox: 0.1045  s1.loss_cls: 0.1422  s1.acc: 92.5636  s1.loss_bbox: 0.0896  s2.loss_cls: 0.0664  s2.acc: 93.3464  s2.loss_bbox: 0.0502\n",
      "12/08 03:01:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 800/1221]  lr: 2.0000e-02  eta: 1:27:40  time: 0.2792  data_time: 0.0086  memory: 2343  grad_norm: 2.2089  loss: 0.9059  loss_rpn_cls: 0.0632  loss_rpn_bbox: 0.0301  s0.loss_cls: 0.3149  s0.acc: 95.3125  s0.loss_bbox: 0.1185  s1.loss_cls: 0.1534  s1.acc: 94.3359  s1.loss_bbox: 0.1019  s2.loss_cls: 0.0701  s2.acc: 92.8223  s2.loss_bbox: 0.0537\n",
      "12/08 03:01:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 850/1221]  lr: 2.0000e-02  eta: 1:27:26  time: 0.2791  data_time: 0.0085  memory: 2342  grad_norm: 2.0609  loss: 0.8159  loss_rpn_cls: 0.0614  loss_rpn_bbox: 0.0347  s0.loss_cls: 0.2733  s0.acc: 94.5801  s0.loss_bbox: 0.1075  s1.loss_cls: 0.1364  s1.acc: 94.9707  s1.loss_bbox: 0.0923  s2.loss_cls: 0.0628  s2.acc: 93.6035  s2.loss_bbox: 0.0474\n",
      "12/08 03:01:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 900/1221]  lr: 2.0000e-02  eta: 1:27:11  time: 0.2793  data_time: 0.0086  memory: 2342  grad_norm: 2.2961  loss: 0.8738  loss_rpn_cls: 0.0588  loss_rpn_bbox: 0.0263  s0.loss_cls: 0.2982  s0.acc: 89.9902  s0.loss_bbox: 0.1154  s1.loss_cls: 0.1478  s1.acc: 90.0879  s1.loss_bbox: 0.1039  s2.loss_cls: 0.0692  s2.acc: 90.9668  s2.loss_bbox: 0.0542\n",
      "12/08 03:01:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 950/1221]  lr: 2.0000e-02  eta: 1:26:56  time: 0.2777  data_time: 0.0085  memory: 2343  grad_norm: 2.3115  loss: 0.9090  loss_rpn_cls: 0.0636  loss_rpn_bbox: 0.0342  s0.loss_cls: 0.3106  s0.acc: 81.8359  s0.loss_bbox: 0.1192  s1.loss_cls: 0.1523  s1.acc: 82.2754  s1.loss_bbox: 0.1047  s2.loss_cls: 0.0699  s2.acc: 83.0078  s2.loss_bbox: 0.0547\n",
      "12/08 03:02:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1000/1221]  lr: 2.0000e-02  eta: 1:26:41  time: 0.2763  data_time: 0.0087  memory: 2342  grad_norm: 2.1267  loss: 0.8285  loss_rpn_cls: 0.0660  loss_rpn_bbox: 0.0285  s0.loss_cls: 0.2754  s0.acc: 92.8711  s0.loss_bbox: 0.1096  s1.loss_cls: 0.1370  s1.acc: 93.4082  s1.loss_bbox: 0.0958  s2.loss_cls: 0.0648  s2.acc: 93.7500  s2.loss_bbox: 0.0514\n",
      "12/08 03:02:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1050/1221]  lr: 2.0000e-02  eta: 1:26:27  time: 0.2794  data_time: 0.0087  memory: 2342  grad_norm: 2.2594  loss: 0.8429  loss_rpn_cls: 0.0683  loss_rpn_bbox: 0.0265  s0.loss_cls: 0.2823  s0.acc: 88.7207  s0.loss_bbox: 0.1098  s1.loss_cls: 0.1394  s1.acc: 90.8203  s1.loss_bbox: 0.0972  s2.loss_cls: 0.0653  s2.acc: 91.8945  s2.loss_bbox: 0.0540\n",
      "12/08 03:02:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1100/1221]  lr: 2.0000e-02  eta: 1:26:12  time: 0.2798  data_time: 0.0092  memory: 2342  grad_norm: 2.2254  loss: 0.8990  loss_rpn_cls: 0.0775  loss_rpn_bbox: 0.0308  s0.loss_cls: 0.3073  s0.acc: 90.7227  s0.loss_bbox: 0.1129  s1.loss_cls: 0.1516  s1.acc: 91.0645  s1.loss_bbox: 0.0982  s2.loss_cls: 0.0700  s2.acc: 94.7266  s2.loss_bbox: 0.0508\n",
      "12/08 03:02:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1150/1221]  lr: 2.0000e-02  eta: 1:25:59  time: 0.2810  data_time: 0.0081  memory: 2343  grad_norm: 2.3305  loss: 0.8233  loss_rpn_cls: 0.0749  loss_rpn_bbox: 0.0300  s0.loss_cls: 0.2702  s0.acc: 91.7969  s0.loss_bbox: 0.1048  s1.loss_cls: 0.1372  s1.acc: 91.9276  s1.loss_bbox: 0.0932  s2.loss_cls: 0.0646  s2.acc: 92.5147  s2.loss_bbox: 0.0485\n",
      "12/08 03:02:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1200/1221]  lr: 2.0000e-02  eta: 1:25:43  time: 0.2762  data_time: 0.0083  memory: 2342  grad_norm: 2.1190  loss: 0.8685  loss_rpn_cls: 0.0720  loss_rpn_bbox: 0.0286  s0.loss_cls: 0.3030  s0.acc: 92.4805  s0.loss_bbox: 0.1123  s1.loss_cls: 0.1458  s1.acc: 91.7969  s1.loss_bbox: 0.0924  s2.loss_cls: 0.0668  s2.acc: 92.6758  s2.loss_bbox: 0.0475\n",
      "12/08 03:03:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:03:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "12/08 03:03:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][  50/1221]  lr: 2.0000e-02  eta: 1:25:23  time: 0.2811  data_time: 0.0122  memory: 2342  grad_norm: 2.3709  loss: 0.8270  loss_rpn_cls: 0.0707  loss_rpn_bbox: 0.0357  s0.loss_cls: 0.2861  s0.acc: 95.4102  s0.loss_bbox: 0.1028  s1.loss_cls: 0.1374  s1.acc: 93.8477  s1.loss_bbox: 0.0873  s2.loss_cls: 0.0616  s2.acc: 93.9941  s2.loss_bbox: 0.0454\n",
      "12/08 03:03:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 100/1221]  lr: 2.0000e-02  eta: 1:25:09  time: 0.2795  data_time: 0.0085  memory: 2342  grad_norm: 2.1425  loss: 0.7837  loss_rpn_cls: 0.0548  loss_rpn_bbox: 0.0289  s0.loss_cls: 0.2629  s0.acc: 96.4355  s0.loss_bbox: 0.1032  s1.loss_cls: 0.1307  s1.acc: 96.7773  s1.loss_bbox: 0.0904  s2.loss_cls: 0.0633  s2.acc: 97.2656  s2.loss_bbox: 0.0494\n",
      "12/08 03:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 150/1221]  lr: 2.0000e-02  eta: 1:24:54  time: 0.2779  data_time: 0.0081  memory: 2342  grad_norm: 2.2605  loss: 0.8272  loss_rpn_cls: 0.0606  loss_rpn_bbox: 0.0288  s0.loss_cls: 0.2732  s0.acc: 92.4805  s0.loss_bbox: 0.1073  s1.loss_cls: 0.1350  s1.acc: 92.4316  s1.loss_bbox: 0.1036  s2.loss_cls: 0.0628  s2.acc: 92.7734  s2.loss_bbox: 0.0559\n",
      "12/08 03:03:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 200/1221]  lr: 2.0000e-02  eta: 1:24:39  time: 0.2754  data_time: 0.0080  memory: 2342  grad_norm: 2.0814  loss: 0.6892  loss_rpn_cls: 0.0438  loss_rpn_bbox: 0.0204  s0.loss_cls: 0.2390  s0.acc: 94.5801  s0.loss_bbox: 0.0837  s1.loss_cls: 0.1236  s1.acc: 95.1172  s1.loss_bbox: 0.0767  s2.loss_cls: 0.0594  s2.acc: 95.3125  s2.loss_bbox: 0.0425\n",
      "12/08 03:04:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 250/1221]  lr: 2.0000e-02  eta: 1:24:24  time: 0.2757  data_time: 0.0079  memory: 2342  grad_norm: 2.2317  loss: 0.8185  loss_rpn_cls: 0.0617  loss_rpn_bbox: 0.0267  s0.loss_cls: 0.2845  s0.acc: 81.2500  s0.loss_bbox: 0.1033  s1.loss_cls: 0.1400  s1.acc: 81.0506  s1.loss_bbox: 0.0897  s2.loss_cls: 0.0650  s2.acc: 83.0291  s2.loss_bbox: 0.0476\n",
      "12/08 03:04:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 300/1221]  lr: 2.0000e-02  eta: 1:24:10  time: 0.2792  data_time: 0.0086  memory: 2343  grad_norm: 2.2038  loss: 0.8123  loss_rpn_cls: 0.0533  loss_rpn_bbox: 0.0268  s0.loss_cls: 0.2791  s0.acc: 93.5547  s0.loss_bbox: 0.1061  s1.loss_cls: 0.1391  s1.acc: 92.8711  s1.loss_bbox: 0.0930  s2.loss_cls: 0.0651  s2.acc: 93.1152  s2.loss_bbox: 0.0499\n",
      "12/08 03:04:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:04:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 350/1221]  lr: 2.0000e-02  eta: 1:23:55  time: 0.2794  data_time: 0.0086  memory: 2342  grad_norm: 2.1421  loss: 0.7800  loss_rpn_cls: 0.0573  loss_rpn_bbox: 0.0282  s0.loss_cls: 0.2640  s0.acc: 95.1172  s0.loss_bbox: 0.0984  s1.loss_cls: 0.1302  s1.acc: 94.6289  s1.loss_bbox: 0.0901  s2.loss_cls: 0.0617  s2.acc: 95.2148  s2.loss_bbox: 0.0500\n",
      "12/08 03:04:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 400/1221]  lr: 2.0000e-02  eta: 1:23:41  time: 0.2802  data_time: 0.0083  memory: 2342  grad_norm: 2.1846  loss: 0.8072  loss_rpn_cls: 0.0682  loss_rpn_bbox: 0.0298  s0.loss_cls: 0.2672  s0.acc: 89.1602  s0.loss_bbox: 0.1001  s1.loss_cls: 0.1373  s1.acc: 89.5486  s1.loss_bbox: 0.0900  s2.loss_cls: 0.0654  s2.acc: 89.9902  s2.loss_bbox: 0.0494\n",
      "12/08 03:05:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 450/1221]  lr: 2.0000e-02  eta: 1:23:27  time: 0.2780  data_time: 0.0084  memory: 2342  grad_norm: 2.2259  loss: 0.8300  loss_rpn_cls: 0.0640  loss_rpn_bbox: 0.0310  s0.loss_cls: 0.2772  s0.acc: 89.4043  s0.loss_bbox: 0.1134  s1.loss_cls: 0.1325  s1.acc: 89.6841  s1.loss_bbox: 0.0982  s2.loss_cls: 0.0612  s2.acc: 89.3827  s2.loss_bbox: 0.0526\n",
      "12/08 03:05:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 500/1221]  lr: 2.0000e-02  eta: 1:23:13  time: 0.2799  data_time: 0.0089  memory: 2342  grad_norm: 2.2639  loss: 0.8700  loss_rpn_cls: 0.0650  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.2923  s0.acc: 90.1855  s0.loss_bbox: 0.1169  s1.loss_cls: 0.1445  s1.acc: 91.3258  s1.loss_bbox: 0.1012  s2.loss_cls: 0.0681  s2.acc: 92.0354  s2.loss_bbox: 0.0545\n",
      "12/08 03:05:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 550/1221]  lr: 2.0000e-02  eta: 1:22:58  time: 0.2771  data_time: 0.0085  memory: 2342  grad_norm: 2.2288  loss: 0.8408  loss_rpn_cls: 0.0568  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.2905  s0.acc: 93.5059  s0.loss_bbox: 0.1089  s1.loss_cls: 0.1430  s1.acc: 93.3105  s1.loss_bbox: 0.0987  s2.loss_cls: 0.0661  s2.acc: 94.1406  s2.loss_bbox: 0.0517\n",
      "12/08 03:05:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 600/1221]  lr: 2.0000e-02  eta: 1:22:44  time: 0.2781  data_time: 0.0086  memory: 2342  grad_norm: 2.2166  loss: 0.9050  loss_rpn_cls: 0.0716  loss_rpn_bbox: 0.0308  s0.loss_cls: 0.3051  s0.acc: 91.7480  s0.loss_bbox: 0.1205  s1.loss_cls: 0.1492  s1.acc: 91.1133  s1.loss_bbox: 0.1030  s2.loss_cls: 0.0696  s2.acc: 90.6738  s2.loss_bbox: 0.0553\n",
      "12/08 03:06:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 650/1221]  lr: 2.0000e-02  eta: 1:22:29  time: 0.2797  data_time: 0.0084  memory: 2342  grad_norm: 2.3704  loss: 0.8444  loss_rpn_cls: 0.0574  loss_rpn_bbox: 0.0293  s0.loss_cls: 0.2915  s0.acc: 89.6973  s0.loss_bbox: 0.1111  s1.loss_cls: 0.1438  s1.acc: 88.2812  s1.loss_bbox: 0.0943  s2.loss_cls: 0.0669  s2.acc: 89.5020  s2.loss_bbox: 0.0500\n",
      "12/08 03:06:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 700/1221]  lr: 2.0000e-02  eta: 1:22:15  time: 0.2773  data_time: 0.0082  memory: 2342  grad_norm: 2.3113  loss: 0.7113  loss_rpn_cls: 0.0496  loss_rpn_bbox: 0.0225  s0.loss_cls: 0.2462  s0.acc: 95.7031  s0.loss_bbox: 0.0893  s1.loss_cls: 0.1230  s1.acc: 96.3867  s1.loss_bbox: 0.0807  s2.loss_cls: 0.0576  s2.acc: 97.1680  s2.loss_bbox: 0.0426\n",
      "12/08 03:06:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 750/1221]  lr: 2.0000e-02  eta: 1:22:00  time: 0.2774  data_time: 0.0083  memory: 2342  grad_norm: 2.0589  loss: 0.7604  loss_rpn_cls: 0.0546  loss_rpn_bbox: 0.0255  s0.loss_cls: 0.2629  s0.acc: 93.5547  s0.loss_bbox: 0.0976  s1.loss_cls: 0.1276  s1.acc: 93.3202  s1.loss_bbox: 0.0853  s2.loss_cls: 0.0599  s2.acc: 91.9568  s2.loss_bbox: 0.0469\n",
      "12/08 03:06:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 800/1221]  lr: 2.0000e-02  eta: 1:21:46  time: 0.2779  data_time: 0.0083  memory: 2342  grad_norm: 2.2737  loss: 0.8782  loss_rpn_cls: 0.0575  loss_rpn_bbox: 0.0299  s0.loss_cls: 0.3058  s0.acc: 87.6953  s0.loss_bbox: 0.1243  s1.loss_cls: 0.1467  s1.acc: 88.8671  s1.loss_bbox: 0.0987  s2.loss_cls: 0.0667  s2.acc: 88.8726  s2.loss_bbox: 0.0486\n",
      "12/08 03:07:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 850/1221]  lr: 2.0000e-02  eta: 1:21:31  time: 0.2757  data_time: 0.0085  memory: 2342  grad_norm: 2.1162  loss: 0.8398  loss_rpn_cls: 0.0578  loss_rpn_bbox: 0.0305  s0.loss_cls: 0.2848  s0.acc: 95.7031  s0.loss_bbox: 0.1149  s1.loss_cls: 0.1387  s1.acc: 94.8242  s1.loss_bbox: 0.0980  s2.loss_cls: 0.0643  s2.acc: 94.8730  s2.loss_bbox: 0.0507\n",
      "12/08 03:07:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 900/1221]  lr: 2.0000e-02  eta: 1:21:17  time: 0.2788  data_time: 0.0086  memory: 2342  grad_norm: 2.1530  loss: 0.7540  loss_rpn_cls: 0.0529  loss_rpn_bbox: 0.0314  s0.loss_cls: 0.2669  s0.acc: 93.7500  s0.loss_bbox: 0.0922  s1.loss_cls: 0.1308  s1.acc: 92.9199  s1.loss_bbox: 0.0775  s2.loss_cls: 0.0613  s2.acc: 92.7734  s2.loss_bbox: 0.0410\n",
      "12/08 03:07:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 950/1221]  lr: 2.0000e-02  eta: 1:21:03  time: 0.2813  data_time: 0.0084  memory: 2342  grad_norm: 2.2476  loss: 0.8740  loss_rpn_cls: 0.0696  loss_rpn_bbox: 0.0298  s0.loss_cls: 0.2960  s0.acc: 89.5020  s0.loss_bbox: 0.1143  s1.loss_cls: 0.1449  s1.acc: 89.3555  s1.loss_bbox: 0.0996  s2.loss_cls: 0.0673  s2.acc: 90.2832  s2.loss_bbox: 0.0526\n",
      "12/08 03:07:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1000/1221]  lr: 2.0000e-02  eta: 1:20:48  time: 0.2760  data_time: 0.0085  memory: 2342  grad_norm: 2.2643  loss: 0.8037  loss_rpn_cls: 0.0602  loss_rpn_bbox: 0.0255  s0.loss_cls: 0.2875  s0.acc: 92.7246  s0.loss_bbox: 0.0979  s1.loss_cls: 0.1381  s1.acc: 92.0898  s1.loss_bbox: 0.0843  s2.loss_cls: 0.0638  s2.acc: 90.0391  s2.loss_bbox: 0.0463\n",
      "12/08 03:07:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1050/1221]  lr: 2.0000e-02  eta: 1:20:34  time: 0.2801  data_time: 0.0083  memory: 2343  grad_norm: 2.0865  loss: 0.7987  loss_rpn_cls: 0.0507  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.2794  s0.acc: 93.9453  s0.loss_bbox: 0.1007  s1.loss_cls: 0.1379  s1.acc: 95.3613  s1.loss_bbox: 0.0891  s2.loss_cls: 0.0651  s2.acc: 94.6289  s2.loss_bbox: 0.0506\n",
      "12/08 03:08:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1100/1221]  lr: 2.0000e-02  eta: 1:20:19  time: 0.2756  data_time: 0.0081  memory: 2342  grad_norm: 2.2115  loss: 0.8438  loss_rpn_cls: 0.0767  loss_rpn_bbox: 0.0370  s0.loss_cls: 0.2834  s0.acc: 90.6738  s0.loss_bbox: 0.1110  s1.loss_cls: 0.1357  s1.acc: 91.4551  s1.loss_bbox: 0.0914  s2.loss_cls: 0.0621  s2.acc: 91.8945  s2.loss_bbox: 0.0466\n",
      "12/08 03:08:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1150/1221]  lr: 2.0000e-02  eta: 1:20:06  time: 0.2808  data_time: 0.0083  memory: 2342  grad_norm: 2.2679  loss: 0.8920  loss_rpn_cls: 0.0660  loss_rpn_bbox: 0.0360  s0.loss_cls: 0.3044  s0.acc: 94.2871  s0.loss_bbox: 0.1146  s1.loss_cls: 0.1503  s1.acc: 91.3947  s1.loss_bbox: 0.0989  s2.loss_cls: 0.0700  s2.acc: 90.1247  s2.loss_bbox: 0.0517\n",
      "12/08 03:08:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1200/1221]  lr: 2.0000e-02  eta: 1:19:51  time: 0.2753  data_time: 0.0085  memory: 2342  grad_norm: 2.2647  loss: 0.8183  loss_rpn_cls: 0.0717  loss_rpn_bbox: 0.0299  s0.loss_cls: 0.2817  s0.acc: 93.6035  s0.loss_bbox: 0.0981  s1.loss_cls: 0.1374  s1.acc: 92.9688  s1.loss_bbox: 0.0885  s2.loss_cls: 0.0637  s2.acc: 93.0664  s2.loss_bbox: 0.0473\n",
      "12/08 03:08:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:08:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
      "12/08 03:09:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][  50/1221]  lr: 2.0000e-02  eta: 1:19:31  time: 0.2833  data_time: 0.0132  memory: 2342  grad_norm: 2.1525  loss: 0.7339  loss_rpn_cls: 0.0426  loss_rpn_bbox: 0.0253  s0.loss_cls: 0.2545  s0.acc: 96.7773  s0.loss_bbox: 0.0920  s1.loss_cls: 0.1269  s1.acc: 97.0215  s1.loss_bbox: 0.0842  s2.loss_cls: 0.0601  s2.acc: 96.0938  s2.loss_bbox: 0.0484\n",
      "12/08 03:09:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 100/1221]  lr: 2.0000e-02  eta: 1:19:16  time: 0.2758  data_time: 0.0086  memory: 2342  grad_norm: 2.5528  loss: 0.8627  loss_rpn_cls: 0.0678  loss_rpn_bbox: 0.0297  s0.loss_cls: 0.2968  s0.acc: 87.7441  s0.loss_bbox: 0.1121  s1.loss_cls: 0.1435  s1.acc: 88.5029  s1.loss_bbox: 0.0948  s2.loss_cls: 0.0672  s2.acc: 89.1879  s2.loss_bbox: 0.0508\n",
      "12/08 03:09:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:09:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 150/1221]  lr: 2.0000e-02  eta: 1:19:02  time: 0.2781  data_time: 0.0081  memory: 2342  grad_norm: 2.1570  loss: 0.8014  loss_rpn_cls: 0.0630  loss_rpn_bbox: 0.0299  s0.loss_cls: 0.2768  s0.acc: 88.9648  s0.loss_bbox: 0.1022  s1.loss_cls: 0.1349  s1.acc: 90.9180  s1.loss_bbox: 0.0865  s2.loss_cls: 0.0630  s2.acc: 92.0410  s2.loss_bbox: 0.0450\n",
      "12/08 03:09:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 200/1221]  lr: 2.0000e-02  eta: 1:18:47  time: 0.2752  data_time: 0.0083  memory: 2342  grad_norm: 2.2454  loss: 0.8085  loss_rpn_cls: 0.0638  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.2755  s0.acc: 87.0605  s0.loss_bbox: 0.1035  s1.loss_cls: 0.1363  s1.acc: 85.8887  s1.loss_bbox: 0.0905  s2.loss_cls: 0.0642  s2.acc: 85.5469  s2.loss_bbox: 0.0474\n",
      "12/08 03:09:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 250/1221]  lr: 2.0000e-02  eta: 1:18:33  time: 0.2779  data_time: 0.0083  memory: 2342  grad_norm: 2.2139  loss: 0.7914  loss_rpn_cls: 0.0483  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.2715  s0.acc: 91.9434  s0.loss_bbox: 0.0993  s1.loss_cls: 0.1373  s1.acc: 92.7622  s1.loss_bbox: 0.0909  s2.loss_cls: 0.0664  s2.acc: 92.2698  s2.loss_bbox: 0.0526\n",
      "12/08 03:10:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 300/1221]  lr: 2.0000e-02  eta: 1:18:19  time: 0.2776  data_time: 0.0082  memory: 2342  grad_norm: 2.6766  loss: 0.8184  loss_rpn_cls: 0.0757  loss_rpn_bbox: 0.0296  s0.loss_cls: 0.2714  s0.acc: 93.1641  s0.loss_bbox: 0.1035  s1.loss_cls: 0.1351  s1.acc: 92.9199  s1.loss_bbox: 0.0910  s2.loss_cls: 0.0632  s2.acc: 93.2617  s2.loss_bbox: 0.0489\n",
      "12/08 03:10:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 350/1221]  lr: 2.0000e-02  eta: 1:18:04  time: 0.2760  data_time: 0.0083  memory: 2342  grad_norm: 2.3117  loss: 0.8596  loss_rpn_cls: 0.0642  loss_rpn_bbox: 0.0334  s0.loss_cls: 0.2965  s0.acc: 90.0391  s0.loss_bbox: 0.1129  s1.loss_cls: 0.1431  s1.acc: 91.1621  s1.loss_bbox: 0.0941  s2.loss_cls: 0.0667  s2.acc: 93.0176  s2.loss_bbox: 0.0487\n",
      "12/08 03:10:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 400/1221]  lr: 2.0000e-02  eta: 1:17:50  time: 0.2776  data_time: 0.0083  memory: 2342  grad_norm: 2.2375  loss: 0.7599  loss_rpn_cls: 0.0595  loss_rpn_bbox: 0.0279  s0.loss_cls: 0.2622  s0.acc: 95.5566  s0.loss_bbox: 0.0927  s1.loss_cls: 0.1307  s1.acc: 94.3359  s1.loss_bbox: 0.0804  s2.loss_cls: 0.0623  s2.acc: 94.4824  s2.loss_bbox: 0.0441\n",
      "12/08 03:10:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 450/1221]  lr: 2.0000e-02  eta: 1:17:35  time: 0.2780  data_time: 0.0086  memory: 2342  grad_norm: 2.0592  loss: 0.7205  loss_rpn_cls: 0.0527  loss_rpn_bbox: 0.0246  s0.loss_cls: 0.2495  s0.acc: 97.9980  s0.loss_bbox: 0.0886  s1.loss_cls: 0.1241  s1.acc: 97.2656  s1.loss_bbox: 0.0806  s2.loss_cls: 0.0582  s2.acc: 96.9238  s2.loss_bbox: 0.0421\n",
      "12/08 03:11:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 500/1221]  lr: 2.0000e-02  eta: 1:17:22  time: 0.2802  data_time: 0.0087  memory: 2343  grad_norm: 2.3422  loss: 0.7684  loss_rpn_cls: 0.0561  loss_rpn_bbox: 0.0238  s0.loss_cls: 0.2636  s0.acc: 94.4336  s0.loss_bbox: 0.0977  s1.loss_cls: 0.1294  s1.acc: 93.2129  s1.loss_bbox: 0.0885  s2.loss_cls: 0.0601  s2.acc: 92.3340  s2.loss_bbox: 0.0493\n",
      "12/08 03:11:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 550/1221]  lr: 2.0000e-02  eta: 1:17:08  time: 0.2805  data_time: 0.0086  memory: 2342  grad_norm: 2.1469  loss: 0.8476  loss_rpn_cls: 0.0629  loss_rpn_bbox: 0.0298  s0.loss_cls: 0.2925  s0.acc: 91.7969  s0.loss_bbox: 0.1076  s1.loss_cls: 0.1444  s1.acc: 90.5762  s1.loss_bbox: 0.0942  s2.loss_cls: 0.0669  s2.acc: 90.7715  s2.loss_bbox: 0.0492\n",
      "12/08 03:11:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 600/1221]  lr: 2.0000e-02  eta: 1:16:53  time: 0.2778  data_time: 0.0086  memory: 2342  grad_norm: 2.1918  loss: 0.8055  loss_rpn_cls: 0.0553  loss_rpn_bbox: 0.0271  s0.loss_cls: 0.2727  s0.acc: 92.6270  s0.loss_bbox: 0.1049  s1.loss_cls: 0.1362  s1.acc: 93.4653  s1.loss_bbox: 0.0942  s2.loss_cls: 0.0643  s2.acc: 93.2697  s2.loss_bbox: 0.0509\n",
      "12/08 03:11:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 650/1221]  lr: 2.0000e-02  eta: 1:16:39  time: 0.2791  data_time: 0.0083  memory: 2342  grad_norm: 2.2790  loss: 0.8340  loss_rpn_cls: 0.0567  loss_rpn_bbox: 0.0292  s0.loss_cls: 0.2841  s0.acc: 83.7891  s0.loss_bbox: 0.1096  s1.loss_cls: 0.1401  s1.acc: 83.8300  s1.loss_bbox: 0.0975  s2.loss_cls: 0.0648  s2.acc: 86.5234  s2.loss_bbox: 0.0519\n",
      "12/08 03:12:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 700/1221]  lr: 2.0000e-02  eta: 1:16:25  time: 0.2786  data_time: 0.0089  memory: 2342  grad_norm: 2.1637  loss: 0.7560  loss_rpn_cls: 0.0606  loss_rpn_bbox: 0.0277  s0.loss_cls: 0.2510  s0.acc: 95.7520  s0.loss_bbox: 0.0977  s1.loss_cls: 0.1246  s1.acc: 95.0684  s1.loss_bbox: 0.0880  s2.loss_cls: 0.0592  s2.acc: 94.6777  s2.loss_bbox: 0.0472\n",
      "12/08 03:12:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 750/1221]  lr: 2.0000e-02  eta: 1:16:11  time: 0.2798  data_time: 0.0084  memory: 2342  grad_norm: 2.3106  loss: 0.8131  loss_rpn_cls: 0.0526  loss_rpn_bbox: 0.0280  s0.loss_cls: 0.2857  s0.acc: 88.8672  s0.loss_bbox: 0.1023  s1.loss_cls: 0.1411  s1.acc: 89.8438  s1.loss_bbox: 0.0894  s2.loss_cls: 0.0662  s2.acc: 91.5039  s2.loss_bbox: 0.0477\n",
      "12/08 03:12:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 800/1221]  lr: 2.0000e-02  eta: 1:15:57  time: 0.2811  data_time: 0.0087  memory: 2342  grad_norm: 2.4358  loss: 0.8005  loss_rpn_cls: 0.0517  loss_rpn_bbox: 0.0252  s0.loss_cls: 0.2712  s0.acc: 91.7969  s0.loss_bbox: 0.1021  s1.loss_cls: 0.1378  s1.acc: 91.6504  s1.loss_bbox: 0.0934  s2.loss_cls: 0.0655  s2.acc: 92.5293  s2.loss_bbox: 0.0535\n",
      "12/08 03:12:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 850/1221]  lr: 2.0000e-02  eta: 1:15:43  time: 0.2783  data_time: 0.0086  memory: 2342  grad_norm: 2.2998  loss: 0.8191  loss_rpn_cls: 0.0567  loss_rpn_bbox: 0.0266  s0.loss_cls: 0.2865  s0.acc: 89.8438  s0.loss_bbox: 0.1081  s1.loss_cls: 0.1386  s1.acc: 91.9922  s1.loss_bbox: 0.0909  s2.loss_cls: 0.0644  s2.acc: 93.7500  s2.loss_bbox: 0.0474\n",
      "12/08 03:12:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 900/1221]  lr: 2.0000e-02  eta: 1:15:29  time: 0.2806  data_time: 0.0085  memory: 2343  grad_norm: 2.2418  loss: 0.8257  loss_rpn_cls: 0.0675  loss_rpn_bbox: 0.0312  s0.loss_cls: 0.2741  s0.acc: 94.2871  s0.loss_bbox: 0.1119  s1.loss_cls: 0.1326  s1.acc: 93.2617  s1.loss_bbox: 0.0964  s2.loss_cls: 0.0610  s2.acc: 93.7988  s2.loss_bbox: 0.0510\n",
      "12/08 03:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 950/1221]  lr: 2.0000e-02  eta: 1:15:16  time: 0.2831  data_time: 0.0084  memory: 2342  grad_norm: 2.4467  loss: 0.8272  loss_rpn_cls: 0.0627  loss_rpn_bbox: 0.0337  s0.loss_cls: 0.2724  s0.acc: 91.7969  s0.loss_bbox: 0.1092  s1.loss_cls: 0.1337  s1.acc: 94.0918  s1.loss_bbox: 0.0995  s2.loss_cls: 0.0621  s2.acc: 93.6523  s2.loss_bbox: 0.0539\n",
      "12/08 03:13:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1000/1221]  lr: 2.0000e-02  eta: 1:15:02  time: 0.2803  data_time: 0.0085  memory: 2342  grad_norm: 2.1163  loss: 0.7493  loss_rpn_cls: 0.0469  loss_rpn_bbox: 0.0226  s0.loss_cls: 0.2574  s0.acc: 91.5039  s0.loss_bbox: 0.0987  s1.loss_cls: 0.1275  s1.acc: 90.5762  s1.loss_bbox: 0.0876  s2.loss_cls: 0.0597  s2.acc: 90.5762  s2.loss_bbox: 0.0490\n",
      "12/08 03:13:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1050/1221]  lr: 2.0000e-02  eta: 1:14:48  time: 0.2815  data_time: 0.0087  memory: 2342  grad_norm: 2.2685  loss: 0.7865  loss_rpn_cls: 0.0571  loss_rpn_bbox: 0.0294  s0.loss_cls: 0.2711  s0.acc: 93.1641  s0.loss_bbox: 0.1029  s1.loss_cls: 0.1337  s1.acc: 92.9688  s1.loss_bbox: 0.0847  s2.loss_cls: 0.0628  s2.acc: 92.3828  s2.loss_bbox: 0.0448\n",
      "12/08 03:13:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1100/1221]  lr: 2.0000e-02  eta: 1:14:34  time: 0.2769  data_time: 0.0085  memory: 2342  grad_norm: 1.9981  loss: 0.7000  loss_rpn_cls: 0.0473  loss_rpn_bbox: 0.0210  s0.loss_cls: 0.2413  s0.acc: 95.3613  s0.loss_bbox: 0.0914  s1.loss_cls: 0.1202  s1.acc: 95.0195  s1.loss_bbox: 0.0799  s2.loss_cls: 0.0565  s2.acc: 96.0449  s2.loss_bbox: 0.0424\n",
      "12/08 03:13:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:14:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1150/1221]  lr: 2.0000e-02  eta: 1:14:20  time: 0.2793  data_time: 0.0085  memory: 2342  grad_norm: 2.3894  loss: 0.9108  loss_rpn_cls: 0.0664  loss_rpn_bbox: 0.0341  s0.loss_cls: 0.3025  s0.acc: 91.1133  s0.loss_bbox: 0.1182  s1.loss_cls: 0.1533  s1.acc: 91.6915  s1.loss_bbox: 0.1062  s2.loss_cls: 0.0734  s2.acc: 90.4335  s2.loss_bbox: 0.0568\n",
      "12/08 03:14:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1200/1221]  lr: 2.0000e-02  eta: 1:14:05  time: 0.2757  data_time: 0.0086  memory: 2343  grad_norm: 2.1450  loss: 0.7187  loss_rpn_cls: 0.0478  loss_rpn_bbox: 0.0273  s0.loss_cls: 0.2391  s0.acc: 87.9883  s0.loss_bbox: 0.0974  s1.loss_cls: 0.1184  s1.acc: 88.0313  s1.loss_bbox: 0.0873  s2.loss_cls: 0.0553  s2.acc: 87.5427  s2.loss_bbox: 0.0461\n",
      "12/08 03:14:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:14:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
      "12/08 03:14:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][  50/1221]  lr: 2.0000e-02  eta: 1:13:46  time: 0.2824  data_time: 0.0119  memory: 2342  grad_norm: 2.0454  loss: 0.6909  loss_rpn_cls: 0.0462  loss_rpn_bbox: 0.0212  s0.loss_cls: 0.2322  s0.acc: 88.3789  s0.loss_bbox: 0.0903  s1.loss_cls: 0.1159  s1.acc: 88.0198  s1.loss_bbox: 0.0820  s2.loss_cls: 0.0558  s2.acc: 88.5092  s2.loss_bbox: 0.0472\n",
      "12/08 03:14:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 100/1221]  lr: 2.0000e-02  eta: 1:13:31  time: 0.2774  data_time: 0.0084  memory: 2342  grad_norm: 2.3126  loss: 0.7814  loss_rpn_cls: 0.0478  loss_rpn_bbox: 0.0291  s0.loss_cls: 0.2595  s0.acc: 92.4316  s0.loss_bbox: 0.1073  s1.loss_cls: 0.1279  s1.acc: 92.6185  s1.loss_bbox: 0.0939  s2.loss_cls: 0.0623  s2.acc: 92.1079  s2.loss_bbox: 0.0535\n",
      "12/08 03:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 150/1221]  lr: 2.0000e-02  eta: 1:13:17  time: 0.2791  data_time: 0.0086  memory: 2342  grad_norm: 2.2729  loss: 0.7713  loss_rpn_cls: 0.0539  loss_rpn_bbox: 0.0259  s0.loss_cls: 0.2633  s0.acc: 89.4043  s0.loss_bbox: 0.1011  s1.loss_cls: 0.1295  s1.acc: 88.1547  s1.loss_bbox: 0.0895  s2.loss_cls: 0.0604  s2.acc: 87.8120  s2.loss_bbox: 0.0476\n",
      "12/08 03:15:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 200/1221]  lr: 2.0000e-02  eta: 1:13:03  time: 0.2774  data_time: 0.0084  memory: 2342  grad_norm: 2.3077  loss: 0.7668  loss_rpn_cls: 0.0498  loss_rpn_bbox: 0.0280  s0.loss_cls: 0.2612  s0.acc: 93.5547  s0.loss_bbox: 0.1047  s1.loss_cls: 0.1235  s1.acc: 93.8965  s1.loss_bbox: 0.0916  s2.loss_cls: 0.0580  s2.acc: 93.6035  s2.loss_bbox: 0.0500\n",
      "12/08 03:15:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 250/1221]  lr: 2.0000e-02  eta: 1:12:49  time: 0.2764  data_time: 0.0086  memory: 2342  grad_norm: 2.4884  loss: 0.8677  loss_rpn_cls: 0.0547  loss_rpn_bbox: 0.0299  s0.loss_cls: 0.2913  s0.acc: 86.2793  s0.loss_bbox: 0.1220  s1.loss_cls: 0.1431  s1.acc: 86.8164  s1.loss_bbox: 0.1052  s2.loss_cls: 0.0667  s2.acc: 89.0137  s2.loss_bbox: 0.0548\n",
      "12/08 03:15:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 300/1221]  lr: 2.0000e-02  eta: 1:12:34  time: 0.2772  data_time: 0.0087  memory: 2342  grad_norm: 2.2774  loss: 0.7362  loss_rpn_cls: 0.0511  loss_rpn_bbox: 0.0245  s0.loss_cls: 0.2518  s0.acc: 89.2578  s0.loss_bbox: 0.0974  s1.loss_cls: 0.1245  s1.acc: 91.1133  s1.loss_bbox: 0.0831  s2.loss_cls: 0.0582  s2.acc: 92.6758  s2.loss_bbox: 0.0456\n",
      "12/08 03:16:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 350/1221]  lr: 2.0000e-02  eta: 1:12:20  time: 0.2768  data_time: 0.0084  memory: 2342  grad_norm: 2.2745  loss: 0.7211  loss_rpn_cls: 0.0462  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.2521  s0.acc: 94.8730  s0.loss_bbox: 0.0893  s1.loss_cls: 0.1247  s1.acc: 95.2590  s1.loss_bbox: 0.0805  s2.loss_cls: 0.0591  s2.acc: 94.7703  s2.loss_bbox: 0.0441\n",
      "12/08 03:16:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 400/1221]  lr: 2.0000e-02  eta: 1:12:06  time: 0.2802  data_time: 0.0086  memory: 2342  grad_norm: 2.1490  loss: 0.7018  loss_rpn_cls: 0.0453  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.2361  s0.acc: 90.1855  s0.loss_bbox: 0.0878  s1.loss_cls: 0.1197  s1.acc: 89.0137  s1.loss_bbox: 0.0820  s2.loss_cls: 0.0575  s2.acc: 88.9160  s2.loss_bbox: 0.0476\n",
      "12/08 03:16:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 450/1221]  lr: 2.0000e-02  eta: 1:11:52  time: 0.2797  data_time: 0.0090  memory: 2342  grad_norm: 2.2878  loss: 0.7117  loss_rpn_cls: 0.0462  loss_rpn_bbox: 0.0243  s0.loss_cls: 0.2429  s0.acc: 91.4062  s0.loss_bbox: 0.0886  s1.loss_cls: 0.1239  s1.acc: 90.4785  s1.loss_bbox: 0.0801  s2.loss_cls: 0.0597  s2.acc: 89.4531  s2.loss_bbox: 0.0460\n",
      "12/08 03:16:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 500/1221]  lr: 2.0000e-02  eta: 1:11:38  time: 0.2779  data_time: 0.0087  memory: 2342  grad_norm: 2.2844  loss: 0.7400  loss_rpn_cls: 0.0520  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.2473  s0.acc: 93.1152  s0.loss_bbox: 0.0960  s1.loss_cls: 0.1231  s1.acc: 93.4082  s1.loss_bbox: 0.0881  s2.loss_cls: 0.0591  s2.acc: 93.7012  s2.loss_bbox: 0.0493\n",
      "12/08 03:17:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 550/1221]  lr: 2.0000e-02  eta: 1:11:24  time: 0.2809  data_time: 0.0085  memory: 2342  grad_norm: 2.2780  loss: 0.7360  loss_rpn_cls: 0.0500  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.2487  s0.acc: 86.1816  s0.loss_bbox: 0.0959  s1.loss_cls: 0.1215  s1.acc: 85.7910  s1.loss_bbox: 0.0867  s2.loss_cls: 0.0569  s2.acc: 87.4023  s2.loss_bbox: 0.0489\n",
      "12/08 03:17:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 600/1221]  lr: 2.0000e-02  eta: 1:11:10  time: 0.2757  data_time: 0.0081  memory: 2342  grad_norm: 2.2183  loss: 0.7335  loss_rpn_cls: 0.0557  loss_rpn_bbox: 0.0254  s0.loss_cls: 0.2475  s0.acc: 91.5039  s0.loss_bbox: 0.0904  s1.loss_cls: 0.1259  s1.acc: 90.6204  s1.loss_bbox: 0.0838  s2.loss_cls: 0.0602  s2.acc: 89.7899  s2.loss_bbox: 0.0447\n",
      "12/08 03:17:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 650/1221]  lr: 2.0000e-02  eta: 1:10:56  time: 0.2792  data_time: 0.0084  memory: 2342  grad_norm: 2.3791  loss: 0.8674  loss_rpn_cls: 0.0646  loss_rpn_bbox: 0.0312  s0.loss_cls: 0.2906  s0.acc: 87.5977  s0.loss_bbox: 0.1155  s1.loss_cls: 0.1419  s1.acc: 88.4766  s1.loss_bbox: 0.0998  s2.loss_cls: 0.0676  s2.acc: 89.2578  s2.loss_bbox: 0.0562\n",
      "12/08 03:17:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 700/1221]  lr: 2.0000e-02  eta: 1:10:41  time: 0.2762  data_time: 0.0083  memory: 2342  grad_norm: 2.2634  loss: 0.8110  loss_rpn_cls: 0.0566  loss_rpn_bbox: 0.0338  s0.loss_cls: 0.2706  s0.acc: 97.6562  s0.loss_bbox: 0.1070  s1.loss_cls: 0.1345  s1.acc: 96.9238  s1.loss_bbox: 0.0956  s2.loss_cls: 0.0626  s2.acc: 98.2910  s2.loss_bbox: 0.0504\n",
      "12/08 03:17:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 750/1221]  lr: 2.0000e-02  eta: 1:10:27  time: 0.2772  data_time: 0.0082  memory: 2342  grad_norm: 2.4502  loss: 0.7742  loss_rpn_cls: 0.0505  loss_rpn_bbox: 0.0245  s0.loss_cls: 0.2677  s0.acc: 95.6055  s0.loss_bbox: 0.0993  s1.loss_cls: 0.1320  s1.acc: 94.5312  s1.loss_bbox: 0.0881  s2.loss_cls: 0.0631  s2.acc: 94.5312  s2.loss_bbox: 0.0491\n",
      "12/08 03:18:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 800/1221]  lr: 2.0000e-02  eta: 1:10:13  time: 0.2789  data_time: 0.0088  memory: 2343  grad_norm: 2.2020  loss: 0.7506  loss_rpn_cls: 0.0501  loss_rpn_bbox: 0.0251  s0.loss_cls: 0.2575  s0.acc: 93.3594  s0.loss_bbox: 0.0970  s1.loss_cls: 0.1270  s1.acc: 94.2385  s1.loss_bbox: 0.0883  s2.loss_cls: 0.0594  s2.acc: 94.7000  s2.loss_bbox: 0.0462\n",
      "12/08 03:18:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 850/1221]  lr: 2.0000e-02  eta: 1:09:59  time: 0.2804  data_time: 0.0086  memory: 2342  grad_norm: 2.2756  loss: 0.8487  loss_rpn_cls: 0.0621  loss_rpn_bbox: 0.0304  s0.loss_cls: 0.2904  s0.acc: 89.5508  s0.loss_bbox: 0.1117  s1.loss_cls: 0.1429  s1.acc: 89.3156  s1.loss_bbox: 0.0943  s2.loss_cls: 0.0674  s2.acc: 89.8130  s2.loss_bbox: 0.0494\n",
      "12/08 03:18:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:18:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 900/1221]  lr: 2.0000e-02  eta: 1:09:45  time: 0.2788  data_time: 0.0086  memory: 2342  grad_norm: 2.2621  loss: 0.7317  loss_rpn_cls: 0.0584  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.2410  s0.acc: 95.1660  s0.loss_bbox: 0.0981  s1.loss_cls: 0.1168  s1.acc: 93.7012  s1.loss_bbox: 0.0864  s2.loss_cls: 0.0545  s2.acc: 92.8711  s2.loss_bbox: 0.0490\n",
      "12/08 03:18:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 950/1221]  lr: 2.0000e-02  eta: 1:09:31  time: 0.2794  data_time: 0.0089  memory: 2342  grad_norm: 2.2991  loss: 0.7168  loss_rpn_cls: 0.0439  loss_rpn_bbox: 0.0226  s0.loss_cls: 0.2516  s0.acc: 93.5059  s0.loss_bbox: 0.0903  s1.loss_cls: 0.1277  s1.acc: 93.5059  s1.loss_bbox: 0.0770  s2.loss_cls: 0.0612  s2.acc: 93.1641  s2.loss_bbox: 0.0426\n",
      "12/08 03:19:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1000/1221]  lr: 2.0000e-02  eta: 1:09:17  time: 0.2817  data_time: 0.0086  memory: 2342  grad_norm: 2.3375  loss: 0.8212  loss_rpn_cls: 0.0556  loss_rpn_bbox: 0.0296  s0.loss_cls: 0.2781  s0.acc: 92.0898  s0.loss_bbox: 0.1083  s1.loss_cls: 0.1375  s1.acc: 90.1367  s1.loss_bbox: 0.0955  s2.loss_cls: 0.0657  s2.acc: 89.5996  s2.loss_bbox: 0.0509\n",
      "12/08 03:19:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1050/1221]  lr: 2.0000e-02  eta: 1:09:03  time: 0.2770  data_time: 0.0084  memory: 2342  grad_norm: 2.4203  loss: 0.7391  loss_rpn_cls: 0.0434  loss_rpn_bbox: 0.0237  s0.loss_cls: 0.2531  s0.acc: 91.4062  s0.loss_bbox: 0.0967  s1.loss_cls: 0.1255  s1.acc: 91.6297  s1.loss_bbox: 0.0887  s2.loss_cls: 0.0589  s2.acc: 91.3065  s2.loss_bbox: 0.0491\n",
      "12/08 03:19:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1100/1221]  lr: 2.0000e-02  eta: 1:08:49  time: 0.2797  data_time: 0.0086  memory: 2342  grad_norm: 2.3430  loss: 0.7919  loss_rpn_cls: 0.0567  loss_rpn_bbox: 0.0249  s0.loss_cls: 0.2712  s0.acc: 94.7266  s0.loss_bbox: 0.0928  s1.loss_cls: 0.1379  s1.acc: 95.1660  s1.loss_bbox: 0.0898  s2.loss_cls: 0.0664  s2.acc: 94.0430  s2.loss_bbox: 0.0523\n",
      "12/08 03:19:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1150/1221]  lr: 2.0000e-02  eta: 1:08:35  time: 0.2806  data_time: 0.0087  memory: 2342  grad_norm: 2.0516  loss: 0.7148  loss_rpn_cls: 0.0581  loss_rpn_bbox: 0.0229  s0.loss_cls: 0.2418  s0.acc: 98.2422  s0.loss_bbox: 0.0879  s1.loss_cls: 0.1208  s1.acc: 97.5586  s1.loss_bbox: 0.0794  s2.loss_cls: 0.0584  s2.acc: 97.8027  s2.loss_bbox: 0.0456\n",
      "12/08 03:20:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1200/1221]  lr: 2.0000e-02  eta: 1:08:21  time: 0.2801  data_time: 0.0089  memory: 2342  grad_norm: 2.2403  loss: 0.7585  loss_rpn_cls: 0.0543  loss_rpn_bbox: 0.0270  s0.loss_cls: 0.2554  s0.acc: 96.3379  s0.loss_bbox: 0.0964  s1.loss_cls: 0.1283  s1.acc: 96.0449  s1.loss_bbox: 0.0873  s2.loss_cls: 0.0615  s2.acc: 96.5820  s2.loss_bbox: 0.0485\n",
      "12/08 03:20:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:20:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
      "12/08 03:20:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][  50/1221]  lr: 2.0000e-02  eta: 1:08:02  time: 0.2859  data_time: 0.0120  memory: 2343  grad_norm: 2.3111  loss: 0.7608  loss_rpn_cls: 0.0567  loss_rpn_bbox: 0.0301  s0.loss_cls: 0.2503  s0.acc: 91.8457  s0.loss_bbox: 0.1000  s1.loss_cls: 0.1253  s1.acc: 91.8945  s1.loss_bbox: 0.0899  s2.loss_cls: 0.0597  s2.acc: 93.7012  s2.loss_bbox: 0.0488\n",
      "12/08 03:20:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 100/1221]  lr: 2.0000e-02  eta: 1:07:48  time: 0.2769  data_time: 0.0089  memory: 2342  grad_norm: 2.5518  loss: 0.7884  loss_rpn_cls: 0.0521  loss_rpn_bbox: 0.0242  s0.loss_cls: 0.2734  s0.acc: 89.0137  s0.loss_bbox: 0.1048  s1.loss_cls: 0.1320  s1.acc: 89.3691  s1.loss_bbox: 0.0899  s2.loss_cls: 0.0619  s2.acc: 91.2202  s2.loss_bbox: 0.0502\n",
      "12/08 03:20:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 150/1221]  lr: 2.0000e-02  eta: 1:07:33  time: 0.2757  data_time: 0.0084  memory: 2343  grad_norm: 2.3336  loss: 0.7419  loss_rpn_cls: 0.0479  loss_rpn_bbox: 0.0253  s0.loss_cls: 0.2520  s0.acc: 95.6543  s0.loss_bbox: 0.0947  s1.loss_cls: 0.1255  s1.acc: 95.5566  s1.loss_bbox: 0.0891  s2.loss_cls: 0.0593  s2.acc: 96.1914  s2.loss_bbox: 0.0481\n",
      "12/08 03:21:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 200/1221]  lr: 2.0000e-02  eta: 1:07:19  time: 0.2788  data_time: 0.0083  memory: 2343  grad_norm: 2.5134  loss: 0.8061  loss_rpn_cls: 0.0498  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.2825  s0.acc: 91.6504  s0.loss_bbox: 0.1020  s1.loss_cls: 0.1381  s1.acc: 91.9823  s1.loss_bbox: 0.0905  s2.loss_cls: 0.0653  s2.acc: 91.9450  s2.loss_bbox: 0.0516\n",
      "12/08 03:21:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 250/1221]  lr: 2.0000e-02  eta: 1:07:05  time: 0.2795  data_time: 0.0083  memory: 2342  grad_norm: 2.3723  loss: 0.7854  loss_rpn_cls: 0.0525  loss_rpn_bbox: 0.0272  s0.loss_cls: 0.2636  s0.acc: 94.1406  s0.loss_bbox: 0.1068  s1.loss_cls: 0.1273  s1.acc: 94.3765  s1.loss_bbox: 0.0938  s2.loss_cls: 0.0608  s2.acc: 94.2647  s2.loss_bbox: 0.0534\n",
      "12/08 03:21:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 300/1221]  lr: 2.0000e-02  eta: 1:06:51  time: 0.2764  data_time: 0.0084  memory: 2342  grad_norm: 2.3117  loss: 0.7284  loss_rpn_cls: 0.0511  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.2504  s0.acc: 97.4121  s0.loss_bbox: 0.0915  s1.loss_cls: 0.1222  s1.acc: 97.5098  s1.loss_bbox: 0.0815  s2.loss_cls: 0.0590  s2.acc: 97.5098  s2.loss_bbox: 0.0465\n",
      "12/08 03:21:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 350/1221]  lr: 2.0000e-02  eta: 1:06:37  time: 0.2773  data_time: 0.0083  memory: 2342  grad_norm: 2.4058  loss: 0.7166  loss_rpn_cls: 0.0492  loss_rpn_bbox: 0.0246  s0.loss_cls: 0.2445  s0.acc: 85.5957  s0.loss_bbox: 0.0902  s1.loss_cls: 0.1213  s1.acc: 85.9529  s1.loss_bbox: 0.0807  s2.loss_cls: 0.0592  s2.acc: 86.5554  s2.loss_bbox: 0.0469\n",
      "12/08 03:22:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 400/1221]  lr: 2.0000e-02  eta: 1:06:23  time: 0.2802  data_time: 0.0086  memory: 2342  grad_norm: 2.3617  loss: 0.7563  loss_rpn_cls: 0.0489  loss_rpn_bbox: 0.0274  s0.loss_cls: 0.2554  s0.acc: 95.8984  s0.loss_bbox: 0.0971  s1.loss_cls: 0.1272  s1.acc: 94.2871  s1.loss_bbox: 0.0896  s2.loss_cls: 0.0601  s2.acc: 94.9707  s2.loss_bbox: 0.0506\n",
      "12/08 03:22:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 450/1221]  lr: 2.0000e-02  eta: 1:06:09  time: 0.2775  data_time: 0.0088  memory: 2343  grad_norm: 2.3588  loss: 0.7234  loss_rpn_cls: 0.0550  loss_rpn_bbox: 0.0263  s0.loss_cls: 0.2417  s0.acc: 92.7246  s0.loss_bbox: 0.0916  s1.loss_cls: 0.1219  s1.acc: 91.1621  s1.loss_bbox: 0.0831  s2.loss_cls: 0.0585  s2.acc: 92.0898  s2.loss_bbox: 0.0454\n",
      "12/08 03:22:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 500/1221]  lr: 2.0000e-02  eta: 1:05:55  time: 0.2780  data_time: 0.0085  memory: 2342  grad_norm: 2.2509  loss: 0.6709  loss_rpn_cls: 0.0425  loss_rpn_bbox: 0.0229  s0.loss_cls: 0.2270  s0.acc: 94.4336  s0.loss_bbox: 0.0872  s1.loss_cls: 0.1115  s1.acc: 93.9941  s1.loss_bbox: 0.0811  s2.loss_cls: 0.0532  s2.acc: 93.7988  s2.loss_bbox: 0.0455\n",
      "12/08 03:22:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 550/1221]  lr: 2.0000e-02  eta: 1:05:41  time: 0.2784  data_time: 0.0086  memory: 2342  grad_norm: 2.2978  loss: 0.7178  loss_rpn_cls: 0.0508  loss_rpn_bbox: 0.0245  s0.loss_cls: 0.2427  s0.acc: 94.2383  s0.loss_bbox: 0.0913  s1.loss_cls: 0.1218  s1.acc: 95.3613  s1.loss_bbox: 0.0827  s2.loss_cls: 0.0581  s2.acc: 95.6543  s2.loss_bbox: 0.0458\n",
      "12/08 03:22:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 600/1221]  lr: 2.0000e-02  eta: 1:05:26  time: 0.2759  data_time: 0.0082  memory: 2343  grad_norm: 2.3541  loss: 0.7582  loss_rpn_cls: 0.0547  loss_rpn_bbox: 0.0275  s0.loss_cls: 0.2566  s0.acc: 93.6035  s0.loss_bbox: 0.0980  s1.loss_cls: 0.1250  s1.acc: 93.1641  s1.loss_bbox: 0.0893  s2.loss_cls: 0.0590  s2.acc: 93.9453  s2.loss_bbox: 0.0481\n",
      "12/08 03:23:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 650/1221]  lr: 2.0000e-02  eta: 1:05:12  time: 0.2765  data_time: 0.0082  memory: 2343  grad_norm: 2.2657  loss: 0.7331  loss_rpn_cls: 0.0456  loss_rpn_bbox: 0.0225  s0.loss_cls: 0.2485  s0.acc: 85.2539  s0.loss_bbox: 0.1010  s1.loss_cls: 0.1219  s1.acc: 86.1623  s1.loss_bbox: 0.0869  s2.loss_cls: 0.0579  s2.acc: 86.4179  s2.loss_bbox: 0.0488\n",
      "12/08 03:23:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:23:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 700/1221]  lr: 2.0000e-02  eta: 1:04:58  time: 0.2766  data_time: 0.0086  memory: 2342  grad_norm: 2.2337  loss: 0.7328  loss_rpn_cls: 0.0477  loss_rpn_bbox: 0.0289  s0.loss_cls: 0.2524  s0.acc: 89.2578  s0.loss_bbox: 0.0932  s1.loss_cls: 0.1245  s1.acc: 89.2558  s1.loss_bbox: 0.0829  s2.loss_cls: 0.0582  s2.acc: 89.4529  s2.loss_bbox: 0.0450\n",
      "12/08 03:23:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 750/1221]  lr: 2.0000e-02  eta: 1:04:44  time: 0.2776  data_time: 0.0082  memory: 2342  grad_norm: 2.2931  loss: 0.7190  loss_rpn_cls: 0.0456  loss_rpn_bbox: 0.0253  s0.loss_cls: 0.2412  s0.acc: 95.1660  s0.loss_bbox: 0.0943  s1.loss_cls: 0.1197  s1.acc: 93.7988  s1.loss_bbox: 0.0855  s2.loss_cls: 0.0578  s2.acc: 93.3105  s2.loss_bbox: 0.0496\n",
      "12/08 03:23:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 800/1221]  lr: 2.0000e-02  eta: 1:04:29  time: 0.2737  data_time: 0.0083  memory: 2342  grad_norm: 2.3507  loss: 0.7539  loss_rpn_cls: 0.0523  loss_rpn_bbox: 0.0243  s0.loss_cls: 0.2521  s0.acc: 93.4082  s0.loss_bbox: 0.0997  s1.loss_cls: 0.1243  s1.acc: 93.2617  s1.loss_bbox: 0.0915  s2.loss_cls: 0.0589  s2.acc: 94.2383  s2.loss_bbox: 0.0509\n",
      "12/08 03:24:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 850/1221]  lr: 2.0000e-02  eta: 1:04:15  time: 0.2773  data_time: 0.0081  memory: 2342  grad_norm: 2.2598  loss: 0.6905  loss_rpn_cls: 0.0487  loss_rpn_bbox: 0.0230  s0.loss_cls: 0.2406  s0.acc: 93.7012  s0.loss_bbox: 0.0858  s1.loss_cls: 0.1196  s1.acc: 93.7931  s1.loss_bbox: 0.0741  s2.loss_cls: 0.0572  s2.acc: 92.4705  s2.loss_bbox: 0.0414\n",
      "12/08 03:24:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 900/1221]  lr: 2.0000e-02  eta: 1:04:01  time: 0.2766  data_time: 0.0081  memory: 2343  grad_norm: 2.3727  loss: 0.7422  loss_rpn_cls: 0.0523  loss_rpn_bbox: 0.0298  s0.loss_cls: 0.2494  s0.acc: 89.7949  s0.loss_bbox: 0.0975  s1.loss_cls: 0.1219  s1.acc: 90.1367  s1.loss_bbox: 0.0867  s2.loss_cls: 0.0580  s2.acc: 92.3828  s2.loss_bbox: 0.0466\n",
      "12/08 03:24:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 950/1221]  lr: 2.0000e-02  eta: 1:03:47  time: 0.2760  data_time: 0.0082  memory: 2342  grad_norm: 2.1644  loss: 0.6793  loss_rpn_cls: 0.0419  loss_rpn_bbox: 0.0264  s0.loss_cls: 0.2299  s0.acc: 93.4570  s0.loss_bbox: 0.0917  s1.loss_cls: 0.1113  s1.acc: 94.3359  s1.loss_bbox: 0.0808  s2.loss_cls: 0.0528  s2.acc: 92.8223  s2.loss_bbox: 0.0445\n",
      "12/08 03:24:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1000/1221]  lr: 2.0000e-02  eta: 1:03:33  time: 0.2793  data_time: 0.0082  memory: 2343  grad_norm: 2.3424  loss: 0.7220  loss_rpn_cls: 0.0475  loss_rpn_bbox: 0.0244  s0.loss_cls: 0.2482  s0.acc: 87.8418  s0.loss_bbox: 0.0899  s1.loss_cls: 0.1257  s1.acc: 87.1000  s1.loss_bbox: 0.0827  s2.loss_cls: 0.0591  s2.acc: 89.2277  s2.loss_bbox: 0.0445\n",
      "12/08 03:25:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1050/1221]  lr: 2.0000e-02  eta: 1:03:19  time: 0.2802  data_time: 0.0086  memory: 2342  grad_norm: 2.3506  loss: 0.7061  loss_rpn_cls: 0.0525  loss_rpn_bbox: 0.0226  s0.loss_cls: 0.2409  s0.acc: 94.9707  s0.loss_bbox: 0.0894  s1.loss_cls: 0.1179  s1.acc: 93.7500  s1.loss_bbox: 0.0808  s2.loss_cls: 0.0565  s2.acc: 94.7754  s2.loss_bbox: 0.0456\n",
      "12/08 03:25:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1100/1221]  lr: 2.0000e-02  eta: 1:03:05  time: 0.2795  data_time: 0.0085  memory: 2342  grad_norm: 2.2614  loss: 0.7193  loss_rpn_cls: 0.0446  loss_rpn_bbox: 0.0287  s0.loss_cls: 0.2447  s0.acc: 97.4121  s0.loss_bbox: 0.0923  s1.loss_cls: 0.1228  s1.acc: 96.0449  s1.loss_bbox: 0.0824  s2.loss_cls: 0.0591  s2.acc: 95.9961  s2.loss_bbox: 0.0447\n",
      "12/08 03:25:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1150/1221]  lr: 2.0000e-02  eta: 1:02:51  time: 0.2756  data_time: 0.0084  memory: 2342  grad_norm: 2.2426  loss: 0.7346  loss_rpn_cls: 0.0543  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.2432  s0.acc: 90.7227  s0.loss_bbox: 0.0960  s1.loss_cls: 0.1186  s1.acc: 90.0391  s1.loss_bbox: 0.0892  s2.loss_cls: 0.0566  s2.acc: 91.2598  s2.loss_bbox: 0.0504\n",
      "12/08 03:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1200/1221]  lr: 2.0000e-02  eta: 1:02:37  time: 0.2793  data_time: 0.0083  memory: 2343  grad_norm: 2.4104  loss: 0.8236  loss_rpn_cls: 0.0541  loss_rpn_bbox: 0.0346  s0.loss_cls: 0.2702  s0.acc: 83.1543  s0.loss_bbox: 0.1127  s1.loss_cls: 0.1330  s1.acc: 82.3644  s1.loss_bbox: 0.1023  s2.loss_cls: 0.0625  s2.acc: 86.3214  s2.loss_bbox: 0.0541\n",
      "12/08 03:25:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:25:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 7 epochs\n",
      "12/08 03:26:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][  50/1221]  lr: 2.0000e-02  eta: 1:02:17  time: 0.2841  data_time: 0.0114  memory: 2342  grad_norm: 2.3395  loss: 0.7666  loss_rpn_cls: 0.0513  loss_rpn_bbox: 0.0283  s0.loss_cls: 0.2596  s0.acc: 91.0645  s0.loss_bbox: 0.1023  s1.loss_cls: 0.1262  s1.acc: 91.2598  s1.loss_bbox: 0.0928  s2.loss_cls: 0.0572  s2.acc: 90.6738  s2.loss_bbox: 0.0490\n",
      "12/08 03:26:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 100/1221]  lr: 2.0000e-02  eta: 1:02:03  time: 0.2780  data_time: 0.0085  memory: 2342  grad_norm: 2.2190  loss: 0.7121  loss_rpn_cls: 0.0423  loss_rpn_bbox: 0.0221  s0.loss_cls: 0.2421  s0.acc: 92.8711  s0.loss_bbox: 0.0930  s1.loss_cls: 0.1188  s1.acc: 94.5022  s1.loss_bbox: 0.0884  s2.loss_cls: 0.0553  s2.acc: 95.3557  s2.loss_bbox: 0.0501\n",
      "12/08 03:26:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 150/1221]  lr: 2.0000e-02  eta: 1:01:49  time: 0.2774  data_time: 0.0085  memory: 2342  grad_norm: 2.2345  loss: 0.6575  loss_rpn_cls: 0.0399  loss_rpn_bbox: 0.0237  s0.loss_cls: 0.2212  s0.acc: 97.8516  s0.loss_bbox: 0.0902  s1.loss_cls: 0.1064  s1.acc: 97.9823  s1.loss_bbox: 0.0810  s2.loss_cls: 0.0505  s2.acc: 99.2593  s2.loss_bbox: 0.0445\n",
      "12/08 03:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 200/1221]  lr: 2.0000e-02  eta: 1:01:35  time: 0.2777  data_time: 0.0082  memory: 2343  grad_norm: 2.2891  loss: 0.6542  loss_rpn_cls: 0.0522  loss_rpn_bbox: 0.0227  s0.loss_cls: 0.2214  s0.acc: 95.4102  s0.loss_bbox: 0.0819  s1.loss_cls: 0.1094  s1.acc: 96.1914  s1.loss_bbox: 0.0729  s2.loss_cls: 0.0524  s2.acc: 95.5566  s2.loss_bbox: 0.0413\n",
      "12/08 03:27:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 250/1221]  lr: 2.0000e-02  eta: 1:01:21  time: 0.2810  data_time: 0.0084  memory: 2343  grad_norm: 2.3469  loss: 0.6896  loss_rpn_cls: 0.0428  loss_rpn_bbox: 0.0215  s0.loss_cls: 0.2344  s0.acc: 97.9980  s0.loss_bbox: 0.0915  s1.loss_cls: 0.1146  s1.acc: 98.4375  s1.loss_bbox: 0.0833  s2.loss_cls: 0.0550  s2.acc: 98.8281  s2.loss_bbox: 0.0465\n",
      "12/08 03:27:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 300/1221]  lr: 2.0000e-02  eta: 1:01:07  time: 0.2782  data_time: 0.0085  memory: 2343  grad_norm: 2.4818  loss: 0.7179  loss_rpn_cls: 0.0485  loss_rpn_bbox: 0.0247  s0.loss_cls: 0.2422  s0.acc: 92.0898  s0.loss_bbox: 0.0929  s1.loss_cls: 0.1196  s1.acc: 91.0645  s1.loss_bbox: 0.0836  s2.loss_cls: 0.0586  s2.acc: 91.7969  s2.loss_bbox: 0.0478\n",
      "12/08 03:27:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 350/1221]  lr: 2.0000e-02  eta: 1:00:53  time: 0.2772  data_time: 0.0084  memory: 2342  grad_norm: 2.2225  loss: 0.6999  loss_rpn_cls: 0.0435  loss_rpn_bbox: 0.0288  s0.loss_cls: 0.2343  s0.acc: 97.2656  s0.loss_bbox: 0.0906  s1.loss_cls: 0.1165  s1.acc: 97.2168  s1.loss_bbox: 0.0830  s2.loss_cls: 0.0552  s2.acc: 96.7773  s2.loss_bbox: 0.0481\n",
      "12/08 03:27:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 400/1221]  lr: 2.0000e-02  eta: 1:00:39  time: 0.2774  data_time: 0.0083  memory: 2342  grad_norm: 2.3386  loss: 0.6606  loss_rpn_cls: 0.0400  loss_rpn_bbox: 0.0216  s0.loss_cls: 0.2258  s0.acc: 84.6191  s0.loss_bbox: 0.0832  s1.loss_cls: 0.1127  s1.acc: 84.8710  s1.loss_bbox: 0.0762  s2.loss_cls: 0.0558  s2.acc: 85.7143  s2.loss_bbox: 0.0452\n",
      "12/08 03:27:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 450/1221]  lr: 2.0000e-02  eta: 1:00:25  time: 0.2775  data_time: 0.0086  memory: 2342  grad_norm: 2.3381  loss: 0.7362  loss_rpn_cls: 0.0457  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.2489  s0.acc: 92.9199  s0.loss_bbox: 0.0997  s1.loss_cls: 0.1221  s1.acc: 91.8417  s1.loss_bbox: 0.0871  s2.loss_cls: 0.0581  s2.acc: 91.4998  s2.loss_bbox: 0.0489\n",
      "12/08 03:27:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:28:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 500/1221]  lr: 2.0000e-02  eta: 1:00:10  time: 0.2737  data_time: 0.0083  memory: 2342  grad_norm: 2.3835  loss: 0.6973  loss_rpn_cls: 0.0467  loss_rpn_bbox: 0.0238  s0.loss_cls: 0.2321  s0.acc: 90.1367  s0.loss_bbox: 0.0899  s1.loss_cls: 0.1167  s1.acc: 89.7537  s1.loss_bbox: 0.0836  s2.loss_cls: 0.0564  s2.acc: 89.6603  s2.loss_bbox: 0.0481\n",
      "12/08 03:28:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 550/1221]  lr: 2.0000e-02  eta: 0:59:56  time: 0.2780  data_time: 0.0084  memory: 2342  grad_norm: 2.4704  loss: 0.7273  loss_rpn_cls: 0.0496  loss_rpn_bbox: 0.0253  s0.loss_cls: 0.2438  s0.acc: 97.7051  s0.loss_bbox: 0.0955  s1.loss_cls: 0.1212  s1.acc: 98.1445  s1.loss_bbox: 0.0878  s2.loss_cls: 0.0573  s2.acc: 98.0469  s2.loss_bbox: 0.0469\n",
      "12/08 03:28:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 600/1221]  lr: 2.0000e-02  eta: 0:59:42  time: 0.2789  data_time: 0.0082  memory: 2342  grad_norm: 2.5927  loss: 0.8212  loss_rpn_cls: 0.0538  loss_rpn_bbox: 0.0293  s0.loss_cls: 0.2876  s0.acc: 89.8926  s0.loss_bbox: 0.1065  s1.loss_cls: 0.1376  s1.acc: 89.7949  s1.loss_bbox: 0.0900  s2.loss_cls: 0.0655  s2.acc: 89.5508  s2.loss_bbox: 0.0507\n",
      "12/08 03:28:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 650/1221]  lr: 2.0000e-02  eta: 0:59:28  time: 0.2770  data_time: 0.0081  memory: 2343  grad_norm: 2.4325  loss: 0.7704  loss_rpn_cls: 0.0543  loss_rpn_bbox: 0.0255  s0.loss_cls: 0.2619  s0.acc: 97.4121  s0.loss_bbox: 0.0978  s1.loss_cls: 0.1275  s1.acc: 97.1191  s1.loss_bbox: 0.0894  s2.loss_cls: 0.0611  s2.acc: 97.5098  s2.loss_bbox: 0.0528\n",
      "12/08 03:29:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 700/1221]  lr: 2.0000e-02  eta: 0:59:14  time: 0.2778  data_time: 0.0084  memory: 2342  grad_norm: 2.3757  loss: 0.6629  loss_rpn_cls: 0.0469  loss_rpn_bbox: 0.0244  s0.loss_cls: 0.2225  s0.acc: 94.8242  s0.loss_bbox: 0.0854  s1.loss_cls: 0.1087  s1.acc: 95.2148  s1.loss_bbox: 0.0785  s2.loss_cls: 0.0520  s2.acc: 96.2402  s2.loss_bbox: 0.0444\n",
      "12/08 03:29:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 750/1221]  lr: 2.0000e-02  eta: 0:59:00  time: 0.2802  data_time: 0.0083  memory: 2342  grad_norm: 2.4250  loss: 0.7546  loss_rpn_cls: 0.0473  loss_rpn_bbox: 0.0300  s0.loss_cls: 0.2548  s0.acc: 90.3320  s0.loss_bbox: 0.0995  s1.loss_cls: 0.1265  s1.acc: 90.9180  s1.loss_bbox: 0.0889  s2.loss_cls: 0.0598  s2.acc: 91.5527  s2.loss_bbox: 0.0479\n",
      "12/08 03:29:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 800/1221]  lr: 2.0000e-02  eta: 0:58:47  time: 0.2806  data_time: 0.0086  memory: 2343  grad_norm: 2.4171  loss: 0.7302  loss_rpn_cls: 0.0539  loss_rpn_bbox: 0.0282  s0.loss_cls: 0.2517  s0.acc: 92.1387  s0.loss_bbox: 0.0919  s1.loss_cls: 0.1212  s1.acc: 92.1520  s1.loss_bbox: 0.0807  s2.loss_cls: 0.0574  s2.acc: 92.0690  s2.loss_bbox: 0.0453\n",
      "12/08 03:29:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 850/1221]  lr: 2.0000e-02  eta: 0:58:33  time: 0.2807  data_time: 0.0086  memory: 2342  grad_norm: 2.2991  loss: 0.7255  loss_rpn_cls: 0.0441  loss_rpn_bbox: 0.0244  s0.loss_cls: 0.2452  s0.acc: 90.9180  s0.loss_bbox: 0.0922  s1.loss_cls: 0.1252  s1.acc: 91.9608  s1.loss_bbox: 0.0843  s2.loss_cls: 0.0616  s2.acc: 93.2386  s2.loss_bbox: 0.0485\n",
      "12/08 03:30:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 900/1221]  lr: 2.0000e-02  eta: 0:58:19  time: 0.2780  data_time: 0.0087  memory: 2342  grad_norm: 2.3357  loss: 0.7325  loss_rpn_cls: 0.0539  loss_rpn_bbox: 0.0335  s0.loss_cls: 0.2419  s0.acc: 92.0898  s0.loss_bbox: 0.0941  s1.loss_cls: 0.1219  s1.acc: 91.3086  s1.loss_bbox: 0.0838  s2.loss_cls: 0.0579  s2.acc: 93.2617  s2.loss_bbox: 0.0455\n",
      "12/08 03:30:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 950/1221]  lr: 2.0000e-02  eta: 0:58:05  time: 0.2794  data_time: 0.0088  memory: 2342  grad_norm: 2.3324  loss: 0.7450  loss_rpn_cls: 0.0462  loss_rpn_bbox: 0.0262  s0.loss_cls: 0.2521  s0.acc: 88.5254  s0.loss_bbox: 0.0981  s1.loss_cls: 0.1238  s1.acc: 88.9652  s1.loss_bbox: 0.0889  s2.loss_cls: 0.0593  s2.acc: 91.7728  s2.loss_bbox: 0.0505\n",
      "12/08 03:30:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1000/1221]  lr: 2.0000e-02  eta: 0:57:51  time: 0.2784  data_time: 0.0089  memory: 2343  grad_norm: 2.1975  loss: 0.6921  loss_rpn_cls: 0.0422  loss_rpn_bbox: 0.0224  s0.loss_cls: 0.2344  s0.acc: 95.1172  s0.loss_bbox: 0.0870  s1.loss_cls: 0.1175  s1.acc: 95.1566  s1.loss_bbox: 0.0824  s2.loss_cls: 0.0580  s2.acc: 95.3545  s2.loss_bbox: 0.0483\n",
      "12/08 03:30:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1050/1221]  lr: 2.0000e-02  eta: 0:57:37  time: 0.2785  data_time: 0.0086  memory: 2342  grad_norm: 2.3313  loss: 0.6909  loss_rpn_cls: 0.0461  loss_rpn_bbox: 0.0244  s0.loss_cls: 0.2359  s0.acc: 89.5508  s0.loss_bbox: 0.0863  s1.loss_cls: 0.1179  s1.acc: 88.4766  s1.loss_bbox: 0.0776  s2.loss_cls: 0.0581  s2.acc: 88.0137  s2.loss_bbox: 0.0446\n",
      "12/08 03:30:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1100/1221]  lr: 2.0000e-02  eta: 0:57:23  time: 0.2785  data_time: 0.0088  memory: 2342  grad_norm: 2.2855  loss: 0.6768  loss_rpn_cls: 0.0476  loss_rpn_bbox: 0.0249  s0.loss_cls: 0.2299  s0.acc: 91.4062  s0.loss_bbox: 0.0862  s1.loss_cls: 0.1127  s1.acc: 89.5996  s1.loss_bbox: 0.0772  s2.loss_cls: 0.0544  s2.acc: 91.5039  s2.loss_bbox: 0.0439\n",
      "12/08 03:31:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1150/1221]  lr: 2.0000e-02  eta: 0:57:09  time: 0.2779  data_time: 0.0087  memory: 2343  grad_norm: 2.4004  loss: 0.6780  loss_rpn_cls: 0.0523  loss_rpn_bbox: 0.0253  s0.loss_cls: 0.2250  s0.acc: 97.1191  s0.loss_bbox: 0.0906  s1.loss_cls: 0.1084  s1.acc: 96.2891  s1.loss_bbox: 0.0796  s2.loss_cls: 0.0518  s2.acc: 97.8516  s2.loss_bbox: 0.0450\n",
      "12/08 03:31:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1200/1221]  lr: 2.0000e-02  eta: 0:56:55  time: 0.2793  data_time: 0.0086  memory: 2342  grad_norm: 2.5814  loss: 0.8324  loss_rpn_cls: 0.0535  loss_rpn_bbox: 0.0327  s0.loss_cls: 0.2831  s0.acc: 88.9648  s0.loss_bbox: 0.1103  s1.loss_cls: 0.1374  s1.acc: 88.4917  s1.loss_bbox: 0.1000  s2.loss_cls: 0.0632  s2.acc: 89.8189  s2.loss_bbox: 0.0521\n",
      "12/08 03:31:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:31:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 8 epochs\n",
      "12/08 03:31:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][  50/1221]  lr: 2.0000e-03  eta: 0:56:35  time: 0.2808  data_time: 0.0122  memory: 2342  grad_norm: 2.1554  loss: 0.6880  loss_rpn_cls: 0.0430  loss_rpn_bbox: 0.0257  s0.loss_cls: 0.2295  s0.acc: 94.1406  s0.loss_bbox: 0.0946  s1.loss_cls: 0.1093  s1.acc: 94.2308  s1.loss_bbox: 0.0853  s2.loss_cls: 0.0523  s2.acc: 93.4450  s2.loss_bbox: 0.0483\n",
      "12/08 03:32:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 100/1221]  lr: 2.0000e-03  eta: 0:56:21  time: 0.2752  data_time: 0.0084  memory: 2343  grad_norm: 2.0468  loss: 0.6089  loss_rpn_cls: 0.0328  loss_rpn_bbox: 0.0236  s0.loss_cls: 0.2075  s0.acc: 93.1641  s0.loss_bbox: 0.0830  s1.loss_cls: 0.0980  s1.acc: 93.7500  s1.loss_bbox: 0.0738  s2.loss_cls: 0.0471  s2.acc: 95.3125  s2.loss_bbox: 0.0431\n",
      "12/08 03:32:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 150/1221]  lr: 2.0000e-03  eta: 0:56:06  time: 0.2752  data_time: 0.0085  memory: 2342  grad_norm: 2.0472  loss: 0.5861  loss_rpn_cls: 0.0317  loss_rpn_bbox: 0.0198  s0.loss_cls: 0.1925  s0.acc: 87.8418  s0.loss_bbox: 0.0799  s1.loss_cls: 0.0973  s1.acc: 89.1530  s1.loss_bbox: 0.0743  s2.loss_cls: 0.0472  s2.acc: 88.9328  s2.loss_bbox: 0.0433\n",
      "12/08 03:32:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 200/1221]  lr: 2.0000e-03  eta: 0:55:52  time: 0.2773  data_time: 0.0089  memory: 2342  grad_norm: 2.0273  loss: 0.5956  loss_rpn_cls: 0.0297  loss_rpn_bbox: 0.0205  s0.loss_cls: 0.1979  s0.acc: 88.7695  s0.loss_bbox: 0.0831  s1.loss_cls: 0.0954  s1.acc: 90.4218  s1.loss_bbox: 0.0766  s2.loss_cls: 0.0468  s2.acc: 90.4762  s2.loss_bbox: 0.0456\n",
      "12/08 03:32:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:32:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 250/1221]  lr: 2.0000e-03  eta: 0:55:38  time: 0.2761  data_time: 0.0085  memory: 2342  grad_norm: 2.0171  loss: 0.5796  loss_rpn_cls: 0.0319  loss_rpn_bbox: 0.0191  s0.loss_cls: 0.1914  s0.acc: 97.4609  s0.loss_bbox: 0.0815  s1.loss_cls: 0.0914  s1.acc: 97.5586  s1.loss_bbox: 0.0754  s2.loss_cls: 0.0452  s2.acc: 98.5840  s2.loss_bbox: 0.0438\n",
      "12/08 03:32:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 300/1221]  lr: 2.0000e-03  eta: 0:55:24  time: 0.2741  data_time: 0.0080  memory: 2343  grad_norm: 2.1332  loss: 0.6330  loss_rpn_cls: 0.0349  loss_rpn_bbox: 0.0219  s0.loss_cls: 0.2100  s0.acc: 95.5566  s0.loss_bbox: 0.0879  s1.loss_cls: 0.1004  s1.acc: 96.2890  s1.loss_bbox: 0.0802  s2.loss_cls: 0.0493  s2.acc: 96.4268  s2.loss_bbox: 0.0484\n",
      "12/08 03:33:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 350/1221]  lr: 2.0000e-03  eta: 0:55:10  time: 0.2775  data_time: 0.0084  memory: 2342  grad_norm: 2.1766  loss: 0.6175  loss_rpn_cls: 0.0304  loss_rpn_bbox: 0.0223  s0.loss_cls: 0.2082  s0.acc: 94.2871  s0.loss_bbox: 0.0850  s1.loss_cls: 0.1004  s1.acc: 94.7754  s1.loss_bbox: 0.0766  s2.loss_cls: 0.0498  s2.acc: 95.8984  s2.loss_bbox: 0.0448\n",
      "12/08 03:33:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 400/1221]  lr: 2.0000e-03  eta: 0:54:56  time: 0.2768  data_time: 0.0086  memory: 2342  grad_norm: 2.1241  loss: 0.5989  loss_rpn_cls: 0.0343  loss_rpn_bbox: 0.0225  s0.loss_cls: 0.1980  s0.acc: 90.7715  s0.loss_bbox: 0.0796  s1.loss_cls: 0.0968  s1.acc: 91.6625  s1.loss_bbox: 0.0744  s2.loss_cls: 0.0482  s2.acc: 91.7582  s2.loss_bbox: 0.0452\n",
      "12/08 03:33:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 450/1221]  lr: 2.0000e-03  eta: 0:54:42  time: 0.2774  data_time: 0.0084  memory: 2343  grad_norm: 2.0121  loss: 0.5219  loss_rpn_cls: 0.0280  loss_rpn_bbox: 0.0160  s0.loss_cls: 0.1740  s0.acc: 91.3574  s0.loss_bbox: 0.0728  s1.loss_cls: 0.0838  s1.acc: 91.7969  s1.loss_bbox: 0.0663  s2.loss_cls: 0.0408  s2.acc: 93.6523  s2.loss_bbox: 0.0404\n",
      "12/08 03:33:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 500/1221]  lr: 2.0000e-03  eta: 0:54:28  time: 0.2764  data_time: 0.0081  memory: 2342  grad_norm: 2.2598  loss: 0.6569  loss_rpn_cls: 0.0352  loss_rpn_bbox: 0.0250  s0.loss_cls: 0.2151  s0.acc: 88.7207  s0.loss_bbox: 0.0935  s1.loss_cls: 0.1042  s1.acc: 90.1228  s1.loss_bbox: 0.0831  s2.loss_cls: 0.0514  s2.acc: 89.7247  s2.loss_bbox: 0.0493\n",
      "12/08 03:34:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 550/1221]  lr: 2.0000e-03  eta: 0:54:13  time: 0.2750  data_time: 0.0084  memory: 2342  grad_norm: 2.0414  loss: 0.5813  loss_rpn_cls: 0.0359  loss_rpn_bbox: 0.0208  s0.loss_cls: 0.1881  s0.acc: 90.2344  s0.loss_bbox: 0.0854  s1.loss_cls: 0.0896  s1.acc: 87.7228  s1.loss_bbox: 0.0756  s2.loss_cls: 0.0433  s2.acc: 86.2376  s2.loss_bbox: 0.0426\n",
      "12/08 03:34:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 600/1221]  lr: 2.0000e-03  eta: 0:53:59  time: 0.2788  data_time: 0.0089  memory: 2342  grad_norm: 2.1939  loss: 0.5941  loss_rpn_cls: 0.0379  loss_rpn_bbox: 0.0229  s0.loss_cls: 0.1971  s0.acc: 90.5762  s0.loss_bbox: 0.0814  s1.loss_cls: 0.0953  s1.acc: 88.3301  s1.loss_bbox: 0.0710  s2.loss_cls: 0.0463  s2.acc: 87.5488  s2.loss_bbox: 0.0424\n",
      "12/08 03:34:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 650/1221]  lr: 2.0000e-03  eta: 0:53:45  time: 0.2781  data_time: 0.0088  memory: 2343  grad_norm: 2.1200  loss: 0.5776  loss_rpn_cls: 0.0339  loss_rpn_bbox: 0.0201  s0.loss_cls: 0.1930  s0.acc: 96.5332  s0.loss_bbox: 0.0787  s1.loss_cls: 0.0932  s1.acc: 95.6543  s1.loss_bbox: 0.0712  s2.loss_cls: 0.0456  s2.acc: 97.3145  s2.loss_bbox: 0.0419\n",
      "12/08 03:34:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 700/1221]  lr: 2.0000e-03  eta: 0:53:31  time: 0.2756  data_time: 0.0089  memory: 2342  grad_norm: 2.1615  loss: 0.5457  loss_rpn_cls: 0.0257  loss_rpn_bbox: 0.0183  s0.loss_cls: 0.1835  s0.acc: 97.1680  s0.loss_bbox: 0.0716  s1.loss_cls: 0.0887  s1.acc: 97.4609  s1.loss_bbox: 0.0707  s2.loss_cls: 0.0440  s2.acc: 97.6562  s2.loss_bbox: 0.0432\n",
      "12/08 03:35:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 750/1221]  lr: 2.0000e-03  eta: 0:53:17  time: 0.2762  data_time: 0.0084  memory: 2342  grad_norm: 2.1093  loss: 0.5608  loss_rpn_cls: 0.0312  loss_rpn_bbox: 0.0200  s0.loss_cls: 0.1900  s0.acc: 93.4082  s0.loss_bbox: 0.0786  s1.loss_cls: 0.0900  s1.acc: 93.9273  s1.loss_bbox: 0.0685  s2.loss_cls: 0.0437  s2.acc: 93.1649  s2.loss_bbox: 0.0389\n",
      "12/08 03:35:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 800/1221]  lr: 2.0000e-03  eta: 0:53:03  time: 0.2766  data_time: 0.0087  memory: 2342  grad_norm: 2.1397  loss: 0.5458  loss_rpn_cls: 0.0280  loss_rpn_bbox: 0.0185  s0.loss_cls: 0.1846  s0.acc: 88.3301  s0.loss_bbox: 0.0733  s1.loss_cls: 0.0893  s1.acc: 88.0424  s1.loss_bbox: 0.0678  s2.loss_cls: 0.0441  s2.acc: 88.7935  s2.loss_bbox: 0.0402\n",
      "12/08 03:35:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 850/1221]  lr: 2.0000e-03  eta: 0:52:49  time: 0.2756  data_time: 0.0087  memory: 2342  grad_norm: 2.0884  loss: 0.5414  loss_rpn_cls: 0.0335  loss_rpn_bbox: 0.0233  s0.loss_cls: 0.1760  s0.acc: 96.7773  s0.loss_bbox: 0.0735  s1.loss_cls: 0.0846  s1.acc: 95.8496  s1.loss_bbox: 0.0680  s2.loss_cls: 0.0406  s2.acc: 95.7520  s2.loss_bbox: 0.0419\n",
      "12/08 03:35:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 900/1221]  lr: 2.0000e-03  eta: 0:52:35  time: 0.2770  data_time: 0.0088  memory: 2342  grad_norm: 2.1347  loss: 0.5590  loss_rpn_cls: 0.0303  loss_rpn_bbox: 0.0213  s0.loss_cls: 0.1835  s0.acc: 97.2656  s0.loss_bbox: 0.0753  s1.loss_cls: 0.0905  s1.acc: 96.9727  s1.loss_bbox: 0.0715  s2.loss_cls: 0.0456  s2.acc: 97.0703  s2.loss_bbox: 0.0411\n",
      "12/08 03:35:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 950/1221]  lr: 2.0000e-03  eta: 0:52:21  time: 0.2761  data_time: 0.0088  memory: 2342  grad_norm: 2.0900  loss: 0.4876  loss_rpn_cls: 0.0252  loss_rpn_bbox: 0.0158  s0.loss_cls: 0.1679  s0.acc: 97.7539  s0.loss_bbox: 0.0600  s1.loss_cls: 0.0818  s1.acc: 97.3145  s1.loss_bbox: 0.0591  s2.loss_cls: 0.0409  s2.acc: 96.3379  s2.loss_bbox: 0.0369\n",
      "12/08 03:36:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1000/1221]  lr: 2.0000e-03  eta: 0:52:07  time: 0.2753  data_time: 0.0086  memory: 2342  grad_norm: 2.0859  loss: 0.4711  loss_rpn_cls: 0.0248  loss_rpn_bbox: 0.0154  s0.loss_cls: 0.1611  s0.acc: 92.1387  s0.loss_bbox: 0.0585  s1.loss_cls: 0.0796  s1.acc: 91.7536  s1.loss_bbox: 0.0573  s2.loss_cls: 0.0400  s2.acc: 92.5852  s2.loss_bbox: 0.0344\n",
      "12/08 03:36:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1050/1221]  lr: 2.0000e-03  eta: 0:51:53  time: 0.2777  data_time: 0.0087  memory: 2342  grad_norm: 2.1279  loss: 0.5183  loss_rpn_cls: 0.0249  loss_rpn_bbox: 0.0160  s0.loss_cls: 0.1709  s0.acc: 91.6016  s0.loss_bbox: 0.0703  s1.loss_cls: 0.0854  s1.acc: 91.7210  s1.loss_bbox: 0.0673  s2.loss_cls: 0.0421  s2.acc: 91.7459  s2.loss_bbox: 0.0414\n",
      "12/08 03:36:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1100/1221]  lr: 2.0000e-03  eta: 0:51:39  time: 0.2784  data_time: 0.0086  memory: 2342  grad_norm: 2.2228  loss: 0.5682  loss_rpn_cls: 0.0286  loss_rpn_bbox: 0.0184  s0.loss_cls: 0.1925  s0.acc: 92.4805  s0.loss_bbox: 0.0782  s1.loss_cls: 0.0937  s1.acc: 94.0313  s1.loss_bbox: 0.0691  s2.loss_cls: 0.0464  s2.acc: 94.4227  s2.loss_bbox: 0.0413\n",
      "12/08 03:36:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1150/1221]  lr: 2.0000e-03  eta: 0:51:25  time: 0.2755  data_time: 0.0084  memory: 2343  grad_norm: 2.1313  loss: 0.5391  loss_rpn_cls: 0.0293  loss_rpn_bbox: 0.0190  s0.loss_cls: 0.1793  s0.acc: 96.4355  s0.loss_bbox: 0.0781  s1.loss_cls: 0.0841  s1.acc: 96.8563  s1.loss_bbox: 0.0680  s2.loss_cls: 0.0408  s2.acc: 96.1058  s2.loss_bbox: 0.0404\n",
      "12/08 03:37:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1200/1221]  lr: 2.0000e-03  eta: 0:51:11  time: 0.2770  data_time: 0.0084  memory: 2342  grad_norm: 2.3141  loss: 0.6315  loss_rpn_cls: 0.0338  loss_rpn_bbox: 0.0197  s0.loss_cls: 0.2088  s0.acc: 97.7051  s0.loss_bbox: 0.0900  s1.loss_cls: 0.1002  s1.acc: 96.9238  s1.loss_bbox: 0.0815  s2.loss_cls: 0.0500  s2.acc: 96.9727  s2.loss_bbox: 0.0475\n",
      "12/08 03:37:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:37:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
      "12/08 03:37:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:37:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][  50/1221]  lr: 2.0000e-03  eta: 0:50:51  time: 0.2845  data_time: 0.0121  memory: 2342  grad_norm: 2.3614  loss: 0.6002  loss_rpn_cls: 0.0355  loss_rpn_bbox: 0.0213  s0.loss_cls: 0.2009  s0.acc: 96.3867  s0.loss_bbox: 0.0816  s1.loss_cls: 0.0961  s1.acc: 97.2999  s1.loss_bbox: 0.0739  s2.loss_cls: 0.0470  s2.acc: 98.0864  s2.loss_bbox: 0.0438\n",
      "12/08 03:37:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 100/1221]  lr: 2.0000e-03  eta: 0:50:37  time: 0.2742  data_time: 0.0086  memory: 2343  grad_norm: 2.1908  loss: 0.5031  loss_rpn_cls: 0.0268  loss_rpn_bbox: 0.0170  s0.loss_cls: 0.1686  s0.acc: 94.4336  s0.loss_bbox: 0.0684  s1.loss_cls: 0.0809  s1.acc: 95.9863  s1.loss_bbox: 0.0640  s2.loss_cls: 0.0395  s2.acc: 96.0688  s2.loss_bbox: 0.0378\n",
      "12/08 03:37:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 150/1221]  lr: 2.0000e-03  eta: 0:50:22  time: 0.2730  data_time: 0.0085  memory: 2342  grad_norm: 2.0880  loss: 0.5096  loss_rpn_cls: 0.0260  loss_rpn_bbox: 0.0174  s0.loss_cls: 0.1680  s0.acc: 92.7246  s0.loss_bbox: 0.0696  s1.loss_cls: 0.0799  s1.acc: 93.0630  s1.loss_bbox: 0.0671  s2.loss_cls: 0.0397  s2.acc: 92.6017  s2.loss_bbox: 0.0418\n",
      "12/08 03:38:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 200/1221]  lr: 2.0000e-03  eta: 0:50:08  time: 0.2735  data_time: 0.0084  memory: 2342  grad_norm: 2.0885  loss: 0.4660  loss_rpn_cls: 0.0252  loss_rpn_bbox: 0.0156  s0.loss_cls: 0.1562  s0.acc: 96.1426  s0.loss_bbox: 0.0638  s1.loss_cls: 0.0760  s1.acc: 95.3225  s1.loss_bbox: 0.0572  s2.loss_cls: 0.0381  s2.acc: 94.8667  s2.loss_bbox: 0.0339\n",
      "12/08 03:38:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 250/1221]  lr: 2.0000e-03  eta: 0:49:54  time: 0.2799  data_time: 0.0086  memory: 2342  grad_norm: 2.1667  loss: 0.5409  loss_rpn_cls: 0.0253  loss_rpn_bbox: 0.0200  s0.loss_cls: 0.1795  s0.acc: 93.9453  s0.loss_bbox: 0.0761  s1.loss_cls: 0.0852  s1.acc: 95.4500  s1.loss_bbox: 0.0704  s2.loss_cls: 0.0425  s2.acc: 95.6171  s2.loss_bbox: 0.0420\n",
      "12/08 03:38:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 300/1221]  lr: 2.0000e-03  eta: 0:49:40  time: 0.2758  data_time: 0.0084  memory: 2342  grad_norm: 2.2294  loss: 0.5593  loss_rpn_cls: 0.0308  loss_rpn_bbox: 0.0216  s0.loss_cls: 0.1805  s0.acc: 94.6289  s0.loss_bbox: 0.0807  s1.loss_cls: 0.0862  s1.acc: 93.3399  s1.loss_bbox: 0.0735  s2.loss_cls: 0.0420  s2.acc: 93.5199  s2.loss_bbox: 0.0441\n",
      "12/08 03:38:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 350/1221]  lr: 2.0000e-03  eta: 0:49:26  time: 0.2767  data_time: 0.0088  memory: 2342  grad_norm: 2.0799  loss: 0.4954  loss_rpn_cls: 0.0250  loss_rpn_bbox: 0.0186  s0.loss_cls: 0.1625  s0.acc: 95.2148  s0.loss_bbox: 0.0693  s1.loss_cls: 0.0777  s1.acc: 96.0039  s1.loss_bbox: 0.0649  s2.loss_cls: 0.0387  s2.acc: 95.8519  s2.loss_bbox: 0.0388\n",
      "12/08 03:39:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 400/1221]  lr: 2.0000e-03  eta: 0:49:12  time: 0.2774  data_time: 0.0086  memory: 2342  grad_norm: 2.1737  loss: 0.5280  loss_rpn_cls: 0.0248  loss_rpn_bbox: 0.0184  s0.loss_cls: 0.1711  s0.acc: 93.7500  s0.loss_bbox: 0.0756  s1.loss_cls: 0.0818  s1.acc: 93.3631  s1.loss_bbox: 0.0730  s2.loss_cls: 0.0404  s2.acc: 94.5636  s2.loss_bbox: 0.0429\n",
      "12/08 03:39:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 450/1221]  lr: 2.0000e-03  eta: 0:48:58  time: 0.2764  data_time: 0.0087  memory: 2342  grad_norm: 2.1391  loss: 0.5068  loss_rpn_cls: 0.0271  loss_rpn_bbox: 0.0189  s0.loss_cls: 0.1687  s0.acc: 93.0664  s0.loss_bbox: 0.0709  s1.loss_cls: 0.0788  s1.acc: 94.0974  s1.loss_bbox: 0.0653  s2.loss_cls: 0.0389  s2.acc: 93.9706  s2.loss_bbox: 0.0383\n",
      "12/08 03:39:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 500/1221]  lr: 2.0000e-03  eta: 0:48:44  time: 0.2750  data_time: 0.0083  memory: 2342  grad_norm: 2.1995  loss: 0.4922  loss_rpn_cls: 0.0276  loss_rpn_bbox: 0.0163  s0.loss_cls: 0.1616  s0.acc: 92.8223  s0.loss_bbox: 0.0696  s1.loss_cls: 0.0776  s1.acc: 93.5816  s1.loss_bbox: 0.0639  s2.loss_cls: 0.0384  s2.acc: 91.9157  s2.loss_bbox: 0.0372\n",
      "12/08 03:39:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 550/1221]  lr: 2.0000e-03  eta: 0:48:30  time: 0.2767  data_time: 0.0078  memory: 2342  grad_norm: 2.2656  loss: 0.5386  loss_rpn_cls: 0.0258  loss_rpn_bbox: 0.0199  s0.loss_cls: 0.1771  s0.acc: 89.8438  s0.loss_bbox: 0.0755  s1.loss_cls: 0.0845  s1.acc: 89.0045  s1.loss_bbox: 0.0703  s2.loss_cls: 0.0421  s2.acc: 87.3950  s2.loss_bbox: 0.0434\n",
      "12/08 03:40:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 600/1221]  lr: 2.0000e-03  eta: 0:48:16  time: 0.2747  data_time: 0.0082  memory: 2342  grad_norm: 2.2351  loss: 0.5391  loss_rpn_cls: 0.0269  loss_rpn_bbox: 0.0179  s0.loss_cls: 0.1744  s0.acc: 92.1875  s0.loss_bbox: 0.0747  s1.loss_cls: 0.0849  s1.acc: 92.3423  s1.loss_bbox: 0.0723  s2.loss_cls: 0.0429  s2.acc: 92.2577  s2.loss_bbox: 0.0451\n",
      "12/08 03:40:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 650/1221]  lr: 2.0000e-03  eta: 0:48:02  time: 0.2786  data_time: 0.0085  memory: 2343  grad_norm: 2.2916  loss: 0.5297  loss_rpn_cls: 0.0266  loss_rpn_bbox: 0.0179  s0.loss_cls: 0.1798  s0.acc: 93.7500  s0.loss_bbox: 0.0746  s1.loss_cls: 0.0838  s1.acc: 95.3580  s1.loss_bbox: 0.0676  s2.loss_cls: 0.0399  s2.acc: 95.4816  s2.loss_bbox: 0.0395\n",
      "12/08 03:40:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 700/1221]  lr: 2.0000e-03  eta: 0:47:48  time: 0.2764  data_time: 0.0085  memory: 2342  grad_norm: 2.1768  loss: 0.5261  loss_rpn_cls: 0.0262  loss_rpn_bbox: 0.0192  s0.loss_cls: 0.1747  s0.acc: 97.8027  s0.loss_bbox: 0.0733  s1.loss_cls: 0.0833  s1.acc: 96.9727  s1.loss_bbox: 0.0671  s2.loss_cls: 0.0420  s2.acc: 95.9961  s2.loss_bbox: 0.0403\n",
      "12/08 03:40:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 750/1221]  lr: 2.0000e-03  eta: 0:47:34  time: 0.2754  data_time: 0.0084  memory: 2342  grad_norm: 2.2544  loss: 0.5332  loss_rpn_cls: 0.0240  loss_rpn_bbox: 0.0208  s0.loss_cls: 0.1787  s0.acc: 91.7480  s0.loss_bbox: 0.0752  s1.loss_cls: 0.0844  s1.acc: 93.0610  s1.loss_bbox: 0.0691  s2.loss_cls: 0.0405  s2.acc: 93.7867  s2.loss_bbox: 0.0405\n",
      "12/08 03:40:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 800/1221]  lr: 2.0000e-03  eta: 0:47:20  time: 0.2751  data_time: 0.0085  memory: 2343  grad_norm: 2.2792  loss: 0.5701  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0183  s0.loss_cls: 0.1874  s0.acc: 95.9473  s0.loss_bbox: 0.0814  s1.loss_cls: 0.0868  s1.acc: 96.6309  s1.loss_bbox: 0.0756  s2.loss_cls: 0.0431  s2.acc: 95.9961  s2.loss_bbox: 0.0469\n",
      "12/08 03:41:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 850/1221]  lr: 2.0000e-03  eta: 0:47:06  time: 0.2786  data_time: 0.0088  memory: 2342  grad_norm: 2.4355  loss: 0.5976  loss_rpn_cls: 0.0328  loss_rpn_bbox: 0.0205  s0.loss_cls: 0.1979  s0.acc: 92.9688  s0.loss_bbox: 0.0846  s1.loss_cls: 0.0931  s1.acc: 92.3902  s1.loss_bbox: 0.0770  s2.loss_cls: 0.0460  s2.acc: 92.9272  s2.loss_bbox: 0.0456\n",
      "12/08 03:41:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 900/1221]  lr: 2.0000e-03  eta: 0:46:52  time: 0.2776  data_time: 0.0088  memory: 2343  grad_norm: 2.3351  loss: 0.5486  loss_rpn_cls: 0.0275  loss_rpn_bbox: 0.0180  s0.loss_cls: 0.1794  s0.acc: 93.3594  s0.loss_bbox: 0.0780  s1.loss_cls: 0.0854  s1.acc: 93.9453  s1.loss_bbox: 0.0731  s2.loss_cls: 0.0424  s2.acc: 92.9688  s2.loss_bbox: 0.0446\n",
      "12/08 03:41:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 950/1221]  lr: 2.0000e-03  eta: 0:46:38  time: 0.2741  data_time: 0.0087  memory: 2343  grad_norm: 2.2734  loss: 0.4854  loss_rpn_cls: 0.0220  loss_rpn_bbox: 0.0148  s0.loss_cls: 0.1600  s0.acc: 93.7988  s0.loss_bbox: 0.0709  s1.loss_cls: 0.0759  s1.acc: 93.7346  s1.loss_bbox: 0.0641  s2.loss_cls: 0.0382  s2.acc: 93.3399  s2.loss_bbox: 0.0395\n",
      "12/08 03:41:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1000/1221]  lr: 2.0000e-03  eta: 0:46:23  time: 0.2736  data_time: 0.0088  memory: 2342  grad_norm: 2.2240  loss: 0.4643  loss_rpn_cls: 0.0223  loss_rpn_bbox: 0.0158  s0.loss_cls: 0.1590  s0.acc: 95.7031  s0.loss_bbox: 0.0608  s1.loss_cls: 0.0777  s1.acc: 96.5332  s1.loss_bbox: 0.0559  s2.loss_cls: 0.0387  s2.acc: 95.8984  s2.loss_bbox: 0.0341\n",
      "12/08 03:41:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:42:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1050/1221]  lr: 2.0000e-03  eta: 0:46:09  time: 0.2744  data_time: 0.0086  memory: 2343  grad_norm: 2.4496  loss: 0.5423  loss_rpn_cls: 0.0297  loss_rpn_bbox: 0.0205  s0.loss_cls: 0.1751  s0.acc: 91.2598  s0.loss_bbox: 0.0740  s1.loss_cls: 0.0854  s1.acc: 90.2344  s1.loss_bbox: 0.0717  s2.loss_cls: 0.0421  s2.acc: 90.6738  s2.loss_bbox: 0.0437\n",
      "12/08 03:42:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1100/1221]  lr: 2.0000e-03  eta: 0:45:55  time: 0.2780  data_time: 0.0088  memory: 2342  grad_norm: 2.3418  loss: 0.5486  loss_rpn_cls: 0.0265  loss_rpn_bbox: 0.0179  s0.loss_cls: 0.1871  s0.acc: 97.8027  s0.loss_bbox: 0.0730  s1.loss_cls: 0.0900  s1.acc: 96.8750  s1.loss_bbox: 0.0678  s2.loss_cls: 0.0443  s2.acc: 95.7520  s2.loss_bbox: 0.0420\n",
      "12/08 03:42:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1150/1221]  lr: 2.0000e-03  eta: 0:45:41  time: 0.2763  data_time: 0.0085  memory: 2343  grad_norm: 2.3503  loss: 0.5666  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0209  s0.loss_cls: 0.1882  s0.acc: 98.1445  s0.loss_bbox: 0.0793  s1.loss_cls: 0.0901  s1.acc: 98.2910  s1.loss_bbox: 0.0712  s2.loss_cls: 0.0439  s2.acc: 98.5840  s2.loss_bbox: 0.0410\n",
      "12/08 03:42:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1200/1221]  lr: 2.0000e-03  eta: 0:45:27  time: 0.2754  data_time: 0.0085  memory: 2342  grad_norm: 2.1111  loss: 0.5023  loss_rpn_cls: 0.0254  loss_rpn_bbox: 0.0182  s0.loss_cls: 0.1700  s0.acc: 96.6797  s0.loss_bbox: 0.0707  s1.loss_cls: 0.0784  s1.acc: 96.6650  s1.loss_bbox: 0.0632  s2.loss_cls: 0.0382  s2.acc: 97.3516  s2.loss_bbox: 0.0382\n",
      "12/08 03:42:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:42:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\n",
      "12/08 03:43:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][  50/1221]  lr: 2.0000e-03  eta: 0:45:07  time: 0.2790  data_time: 0.0118  memory: 2342  grad_norm: 2.2414  loss: 0.5018  loss_rpn_cls: 0.0275  loss_rpn_bbox: 0.0192  s0.loss_cls: 0.1661  s0.acc: 92.1387  s0.loss_bbox: 0.0698  s1.loss_cls: 0.0786  s1.acc: 93.8278  s1.loss_bbox: 0.0626  s2.loss_cls: 0.0397  s2.acc: 93.6350  s2.loss_bbox: 0.0385\n",
      "12/08 03:43:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 100/1221]  lr: 2.0000e-03  eta: 0:44:53  time: 0.2757  data_time: 0.0090  memory: 2342  grad_norm: 2.3779  loss: 0.5635  loss_rpn_cls: 0.0287  loss_rpn_bbox: 0.0210  s0.loss_cls: 0.1830  s0.acc: 89.0137  s0.loss_bbox: 0.0832  s1.loss_cls: 0.0844  s1.acc: 89.4551  s1.loss_bbox: 0.0751  s2.loss_cls: 0.0429  s2.acc: 89.1797  s2.loss_bbox: 0.0452\n",
      "12/08 03:43:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 150/1221]  lr: 2.0000e-03  eta: 0:44:39  time: 0.2738  data_time: 0.0086  memory: 2342  grad_norm: 2.4046  loss: 0.5376  loss_rpn_cls: 0.0256  loss_rpn_bbox: 0.0176  s0.loss_cls: 0.1747  s0.acc: 97.6562  s0.loss_bbox: 0.0767  s1.loss_cls: 0.0841  s1.acc: 97.1191  s1.loss_bbox: 0.0733  s2.loss_cls: 0.0422  s2.acc: 96.8262  s2.loss_bbox: 0.0434\n",
      "12/08 03:43:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 200/1221]  lr: 2.0000e-03  eta: 0:44:25  time: 0.2775  data_time: 0.0083  memory: 2343  grad_norm: 2.1791  loss: 0.4769  loss_rpn_cls: 0.0237  loss_rpn_bbox: 0.0170  s0.loss_cls: 0.1556  s0.acc: 94.4336  s0.loss_bbox: 0.0683  s1.loss_cls: 0.0720  s1.acc: 95.2069  s1.loss_bbox: 0.0652  s2.loss_cls: 0.0357  s2.acc: 94.9669  s2.loss_bbox: 0.0394\n",
      "12/08 03:44:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 250/1221]  lr: 2.0000e-03  eta: 0:44:11  time: 0.2740  data_time: 0.0084  memory: 2343  grad_norm: 2.2869  loss: 0.4640  loss_rpn_cls: 0.0196  loss_rpn_bbox: 0.0139  s0.loss_cls: 0.1584  s0.acc: 93.7012  s0.loss_bbox: 0.0620  s1.loss_cls: 0.0752  s1.acc: 93.7035  s1.loss_bbox: 0.0586  s2.loss_cls: 0.0383  s2.acc: 93.3366  s2.loss_bbox: 0.0380\n",
      "12/08 03:44:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 300/1221]  lr: 2.0000e-03  eta: 0:43:57  time: 0.2767  data_time: 0.0088  memory: 2342  grad_norm: 2.3463  loss: 0.5270  loss_rpn_cls: 0.0253  loss_rpn_bbox: 0.0179  s0.loss_cls: 0.1726  s0.acc: 94.0430  s0.loss_bbox: 0.0767  s1.loss_cls: 0.0797  s1.acc: 94.4858  s1.loss_bbox: 0.0718  s2.loss_cls: 0.0393  s2.acc: 94.2815  s2.loss_bbox: 0.0438\n",
      "12/08 03:44:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 350/1221]  lr: 2.0000e-03  eta: 0:43:43  time: 0.2777  data_time: 0.0086  memory: 2342  grad_norm: 2.3771  loss: 0.5081  loss_rpn_cls: 0.0238  loss_rpn_bbox: 0.0168  s0.loss_cls: 0.1712  s0.acc: 97.2168  s0.loss_bbox: 0.0710  s1.loss_cls: 0.0819  s1.acc: 97.0703  s1.loss_bbox: 0.0640  s2.loss_cls: 0.0406  s2.acc: 98.0957  s2.loss_bbox: 0.0389\n",
      "12/08 03:44:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 400/1221]  lr: 2.0000e-03  eta: 0:43:29  time: 0.2759  data_time: 0.0089  memory: 2342  grad_norm: 2.3602  loss: 0.5340  loss_rpn_cls: 0.0300  loss_rpn_bbox: 0.0202  s0.loss_cls: 0.1711  s0.acc: 95.9473  s0.loss_bbox: 0.0766  s1.loss_cls: 0.0822  s1.acc: 95.2637  s1.loss_bbox: 0.0705  s2.loss_cls: 0.0412  s2.acc: 95.1961  s2.loss_bbox: 0.0422\n",
      "12/08 03:44:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 450/1221]  lr: 2.0000e-03  eta: 0:43:15  time: 0.2735  data_time: 0.0085  memory: 2342  grad_norm: 2.3807  loss: 0.6011  loss_rpn_cls: 0.0304  loss_rpn_bbox: 0.0236  s0.loss_cls: 0.1902  s0.acc: 89.9414  s0.loss_bbox: 0.0942  s1.loss_cls: 0.0883  s1.acc: 91.4412  s1.loss_bbox: 0.0832  s2.loss_cls: 0.0434  s2.acc: 93.7070  s2.loss_bbox: 0.0477\n",
      "12/08 03:45:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 500/1221]  lr: 2.0000e-03  eta: 0:43:01  time: 0.2776  data_time: 0.0084  memory: 2343  grad_norm: 2.3592  loss: 0.5331  loss_rpn_cls: 0.0241  loss_rpn_bbox: 0.0183  s0.loss_cls: 0.1821  s0.acc: 98.0469  s0.loss_bbox: 0.0758  s1.loss_cls: 0.0859  s1.acc: 98.6328  s1.loss_bbox: 0.0664  s2.loss_cls: 0.0413  s2.acc: 98.7793  s2.loss_bbox: 0.0392\n",
      "12/08 03:45:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 550/1221]  lr: 2.0000e-03  eta: 0:42:47  time: 0.2764  data_time: 0.0088  memory: 2342  grad_norm: 2.0861  loss: 0.4431  loss_rpn_cls: 0.0203  loss_rpn_bbox: 0.0174  s0.loss_cls: 0.1458  s0.acc: 96.2402  s0.loss_bbox: 0.0652  s1.loss_cls: 0.0672  s1.acc: 97.6605  s1.loss_bbox: 0.0594  s2.loss_cls: 0.0326  s2.acc: 98.4414  s2.loss_bbox: 0.0350\n",
      "12/08 03:45:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 600/1221]  lr: 2.0000e-03  eta: 0:42:33  time: 0.2752  data_time: 0.0082  memory: 2342  grad_norm: 2.3717  loss: 0.5216  loss_rpn_cls: 0.0232  loss_rpn_bbox: 0.0197  s0.loss_cls: 0.1705  s0.acc: 94.3848  s0.loss_bbox: 0.0747  s1.loss_cls: 0.0798  s1.acc: 95.0869  s1.loss_bbox: 0.0714  s2.loss_cls: 0.0392  s2.acc: 95.6414  s2.loss_bbox: 0.0431\n",
      "12/08 03:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 650/1221]  lr: 2.0000e-03  eta: 0:42:19  time: 0.2759  data_time: 0.0085  memory: 2342  grad_norm: 2.2172  loss: 0.4754  loss_rpn_cls: 0.0217  loss_rpn_bbox: 0.0185  s0.loss_cls: 0.1543  s0.acc: 92.6270  s0.loss_bbox: 0.0667  s1.loss_cls: 0.0737  s1.acc: 94.0918  s1.loss_bbox: 0.0647  s2.loss_cls: 0.0364  s2.acc: 91.9434  s2.loss_bbox: 0.0393\n",
      "12/08 03:46:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 700/1221]  lr: 2.0000e-03  eta: 0:42:05  time: 0.2760  data_time: 0.0089  memory: 2342  grad_norm: 2.5064  loss: 0.5403  loss_rpn_cls: 0.0251  loss_rpn_bbox: 0.0193  s0.loss_cls: 0.1787  s0.acc: 94.9219  s0.loss_bbox: 0.0777  s1.loss_cls: 0.0840  s1.acc: 93.1152  s1.loss_bbox: 0.0713  s2.loss_cls: 0.0414  s2.acc: 93.3105  s2.loss_bbox: 0.0427\n",
      "12/08 03:46:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 750/1221]  lr: 2.0000e-03  eta: 0:41:51  time: 0.2747  data_time: 0.0088  memory: 2342  grad_norm: 2.2963  loss: 0.4772  loss_rpn_cls: 0.0229  loss_rpn_bbox: 0.0165  s0.loss_cls: 0.1626  s0.acc: 98.4375  s0.loss_bbox: 0.0640  s1.loss_cls: 0.0753  s1.acc: 98.9258  s1.loss_bbox: 0.0612  s2.loss_cls: 0.0369  s2.acc: 99.6582  s2.loss_bbox: 0.0377\n",
      "12/08 03:46:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:46:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 800/1221]  lr: 2.0000e-03  eta: 0:41:37  time: 0.2749  data_time: 0.0085  memory: 2342  grad_norm: 2.3082  loss: 0.4821  loss_rpn_cls: 0.0245  loss_rpn_bbox: 0.0194  s0.loss_cls: 0.1594  s0.acc: 92.5293  s0.loss_bbox: 0.0669  s1.loss_cls: 0.0760  s1.acc: 93.0914  s1.loss_bbox: 0.0610  s2.loss_cls: 0.0375  s2.acc: 92.9570  s2.loss_bbox: 0.0373\n",
      "12/08 03:46:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 850/1221]  lr: 2.0000e-03  eta: 0:41:23  time: 0.2760  data_time: 0.0085  memory: 2342  grad_norm: 2.3290  loss: 0.4644  loss_rpn_cls: 0.0245  loss_rpn_bbox: 0.0177  s0.loss_cls: 0.1501  s0.acc: 96.7285  s0.loss_bbox: 0.0658  s1.loss_cls: 0.0722  s1.acc: 97.4609  s1.loss_bbox: 0.0613  s2.loss_cls: 0.0354  s2.acc: 96.5820  s2.loss_bbox: 0.0374\n",
      "12/08 03:47:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 900/1221]  lr: 2.0000e-03  eta: 0:41:09  time: 0.2747  data_time: 0.0085  memory: 2342  grad_norm: 2.4396  loss: 0.5397  loss_rpn_cls: 0.0284  loss_rpn_bbox: 0.0202  s0.loss_cls: 0.1803  s0.acc: 90.5762  s0.loss_bbox: 0.0748  s1.loss_cls: 0.0846  s1.acc: 92.3924  s1.loss_bbox: 0.0680  s2.loss_cls: 0.0423  s2.acc: 91.7004  s2.loss_bbox: 0.0412\n",
      "12/08 03:47:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 950/1221]  lr: 2.0000e-03  eta: 0:40:55  time: 0.2751  data_time: 0.0085  memory: 2342  grad_norm: 2.3115  loss: 0.5024  loss_rpn_cls: 0.0229  loss_rpn_bbox: 0.0188  s0.loss_cls: 0.1628  s0.acc: 98.8281  s0.loss_bbox: 0.0735  s1.loss_cls: 0.0788  s1.acc: 98.2910  s1.loss_bbox: 0.0665  s2.loss_cls: 0.0399  s2.acc: 98.5840  s2.loss_bbox: 0.0391\n",
      "12/08 03:47:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1000/1221]  lr: 2.0000e-03  eta: 0:40:41  time: 0.2762  data_time: 0.0086  memory: 2342  grad_norm: 2.5207  loss: 0.5112  loss_rpn_cls: 0.0242  loss_rpn_bbox: 0.0157  s0.loss_cls: 0.1759  s0.acc: 95.8984  s0.loss_bbox: 0.0677  s1.loss_cls: 0.0833  s1.acc: 96.3565  s1.loss_bbox: 0.0628  s2.loss_cls: 0.0414  s2.acc: 96.8333  s2.loss_bbox: 0.0401\n",
      "12/08 03:47:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1050/1221]  lr: 2.0000e-03  eta: 0:40:27  time: 0.2747  data_time: 0.0085  memory: 2343  grad_norm: 2.2762  loss: 0.4626  loss_rpn_cls: 0.0207  loss_rpn_bbox: 0.0166  s0.loss_cls: 0.1565  s0.acc: 97.9492  s0.loss_bbox: 0.0656  s1.loss_cls: 0.0738  s1.acc: 97.5098  s1.loss_bbox: 0.0581  s2.loss_cls: 0.0362  s2.acc: 97.6074  s2.loss_bbox: 0.0353\n",
      "12/08 03:47:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1100/1221]  lr: 2.0000e-03  eta: 0:40:13  time: 0.2757  data_time: 0.0086  memory: 2343  grad_norm: 2.3316  loss: 0.4820  loss_rpn_cls: 0.0212  loss_rpn_bbox: 0.0157  s0.loss_cls: 0.1650  s0.acc: 93.5547  s0.loss_bbox: 0.0674  s1.loss_cls: 0.0753  s1.acc: 94.8242  s1.loss_bbox: 0.0619  s2.loss_cls: 0.0378  s2.acc: 94.1406  s2.loss_bbox: 0.0377\n",
      "12/08 03:48:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1150/1221]  lr: 2.0000e-03  eta: 0:39:59  time: 0.2741  data_time: 0.0084  memory: 2343  grad_norm: 2.4540  loss: 0.5146  loss_rpn_cls: 0.0258  loss_rpn_bbox: 0.0185  s0.loss_cls: 0.1724  s0.acc: 98.6328  s0.loss_bbox: 0.0701  s1.loss_cls: 0.0820  s1.acc: 97.7051  s1.loss_bbox: 0.0647  s2.loss_cls: 0.0417  s2.acc: 97.7051  s2.loss_bbox: 0.0395\n",
      "12/08 03:48:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1200/1221]  lr: 2.0000e-03  eta: 0:39:45  time: 0.2755  data_time: 0.0084  memory: 2342  grad_norm: 2.2472  loss: 0.4111  loss_rpn_cls: 0.0213  loss_rpn_bbox: 0.0151  s0.loss_cls: 0.1345  s0.acc: 97.4121  s0.loss_bbox: 0.0593  s1.loss_cls: 0.0635  s1.acc: 97.9492  s1.loss_bbox: 0.0533  s2.loss_cls: 0.0318  s2.acc: 96.1914  s2.loss_bbox: 0.0323\n",
      "12/08 03:48:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:48:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 11 epochs\n",
      "12/08 03:48:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][  50/1221]  lr: 2.0000e-04  eta: 0:39:25  time: 0.2784  data_time: 0.0121  memory: 2342  grad_norm: 2.3499  loss: 0.5090  loss_rpn_cls: 0.0224  loss_rpn_bbox: 0.0189  s0.loss_cls: 0.1713  s0.acc: 94.2871  s0.loss_bbox: 0.0706  s1.loss_cls: 0.0803  s1.acc: 94.0858  s1.loss_bbox: 0.0644  s2.loss_cls: 0.0409  s2.acc: 93.6578  s2.loss_bbox: 0.0402\n",
      "12/08 03:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 100/1221]  lr: 2.0000e-04  eta: 0:39:11  time: 0.2757  data_time: 0.0088  memory: 2342  grad_norm: 2.4420  loss: 0.5377  loss_rpn_cls: 0.0259  loss_rpn_bbox: 0.0177  s0.loss_cls: 0.1765  s0.acc: 91.0156  s0.loss_bbox: 0.0774  s1.loss_cls: 0.0804  s1.acc: 93.1705  s1.loss_bbox: 0.0741  s2.loss_cls: 0.0396  s2.acc: 92.6148  s2.loss_bbox: 0.0461\n",
      "12/08 03:49:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 150/1221]  lr: 2.0000e-04  eta: 0:38:57  time: 0.2742  data_time: 0.0084  memory: 2343  grad_norm: 2.2207  loss: 0.5047  loss_rpn_cls: 0.0219  loss_rpn_bbox: 0.0189  s0.loss_cls: 0.1681  s0.acc: 95.2148  s0.loss_bbox: 0.0738  s1.loss_cls: 0.0753  s1.acc: 95.4079  s1.loss_bbox: 0.0686  s2.loss_cls: 0.0372  s2.acc: 95.4568  s2.loss_bbox: 0.0409\n",
      "12/08 03:49:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 200/1221]  lr: 2.0000e-04  eta: 0:38:43  time: 0.2765  data_time: 0.0083  memory: 2342  grad_norm: 2.3177  loss: 0.4902  loss_rpn_cls: 0.0235  loss_rpn_bbox: 0.0186  s0.loss_cls: 0.1600  s0.acc: 99.5117  s0.loss_bbox: 0.0714  s1.loss_cls: 0.0747  s1.acc: 99.4629  s1.loss_bbox: 0.0653  s2.loss_cls: 0.0373  s2.acc: 99.8047  s2.loss_bbox: 0.0394\n",
      "12/08 03:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 250/1221]  lr: 2.0000e-04  eta: 0:38:29  time: 0.2739  data_time: 0.0084  memory: 2342  grad_norm: 2.1819  loss: 0.4188  loss_rpn_cls: 0.0181  loss_rpn_bbox: 0.0146  s0.loss_cls: 0.1398  s0.acc: 91.1133  s0.loss_bbox: 0.0585  s1.loss_cls: 0.0664  s1.acc: 92.5049  s1.loss_bbox: 0.0544  s2.loss_cls: 0.0327  s2.acc: 92.1365  s2.loss_bbox: 0.0343\n",
      "12/08 03:49:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 300/1221]  lr: 2.0000e-04  eta: 0:38:15  time: 0.2793  data_time: 0.0083  memory: 2342  grad_norm: 2.3356  loss: 0.5185  loss_rpn_cls: 0.0266  loss_rpn_bbox: 0.0205  s0.loss_cls: 0.1656  s0.acc: 97.0215  s0.loss_bbox: 0.0773  s1.loss_cls: 0.0778  s1.acc: 96.7773  s1.loss_bbox: 0.0700  s2.loss_cls: 0.0380  s2.acc: 95.1660  s2.loss_bbox: 0.0427\n",
      "12/08 03:50:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 350/1221]  lr: 2.0000e-04  eta: 0:38:01  time: 0.2764  data_time: 0.0082  memory: 2342  grad_norm: 2.2648  loss: 0.4496  loss_rpn_cls: 0.0223  loss_rpn_bbox: 0.0144  s0.loss_cls: 0.1484  s0.acc: 91.4062  s0.loss_bbox: 0.0650  s1.loss_cls: 0.0667  s1.acc: 92.1066  s1.loss_bbox: 0.0608  s2.loss_cls: 0.0330  s2.acc: 92.2584  s2.loss_bbox: 0.0391\n",
      "12/08 03:50:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 400/1221]  lr: 2.0000e-04  eta: 0:37:47  time: 0.2759  data_time: 0.0083  memory: 2343  grad_norm: 2.2078  loss: 0.4765  loss_rpn_cls: 0.0198  loss_rpn_bbox: 0.0189  s0.loss_cls: 0.1525  s0.acc: 94.1406  s0.loss_bbox: 0.0709  s1.loss_cls: 0.0717  s1.acc: 95.2872  s1.loss_bbox: 0.0679  s2.loss_cls: 0.0354  s2.acc: 95.1423  s2.loss_bbox: 0.0396\n",
      "12/08 03:50:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 450/1221]  lr: 2.0000e-04  eta: 0:37:33  time: 0.2749  data_time: 0.0086  memory: 2342  grad_norm: 2.1993  loss: 0.4263  loss_rpn_cls: 0.0187  loss_rpn_bbox: 0.0160  s0.loss_cls: 0.1436  s0.acc: 93.2617  s0.loss_bbox: 0.0597  s1.loss_cls: 0.0660  s1.acc: 94.4922  s1.loss_bbox: 0.0540  s2.loss_cls: 0.0335  s2.acc: 95.1382  s2.loss_bbox: 0.0349\n",
      "12/08 03:50:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 500/1221]  lr: 2.0000e-04  eta: 0:37:19  time: 0.2771  data_time: 0.0083  memory: 2343  grad_norm: 2.2876  loss: 0.4921  loss_rpn_cls: 0.0219  loss_rpn_bbox: 0.0196  s0.loss_cls: 0.1613  s0.acc: 96.6309  s0.loss_bbox: 0.0711  s1.loss_cls: 0.0747  s1.acc: 97.6562  s1.loss_bbox: 0.0651  s2.loss_cls: 0.0371  s2.acc: 98.0957  s2.loss_bbox: 0.0412\n",
      "12/08 03:51:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 550/1221]  lr: 2.0000e-04  eta: 0:37:05  time: 0.2761  data_time: 0.0085  memory: 2342  grad_norm: 2.2685  loss: 0.4533  loss_rpn_cls: 0.0209  loss_rpn_bbox: 0.0169  s0.loss_cls: 0.1444  s0.acc: 97.4609  s0.loss_bbox: 0.0683  s1.loss_cls: 0.0658  s1.acc: 97.4121  s1.loss_bbox: 0.0642  s2.loss_cls: 0.0319  s2.acc: 97.7051  s2.loss_bbox: 0.0408\n",
      "12/08 03:51:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:51:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 600/1221]  lr: 2.0000e-04  eta: 0:36:51  time: 0.2763  data_time: 0.0083  memory: 2342  grad_norm: 2.3712  loss: 0.5019  loss_rpn_cls: 0.0248  loss_rpn_bbox: 0.0191  s0.loss_cls: 0.1617  s0.acc: 96.8262  s0.loss_bbox: 0.0716  s1.loss_cls: 0.0759  s1.acc: 96.6797  s1.loss_bbox: 0.0690  s2.loss_cls: 0.0384  s2.acc: 96.7285  s2.loss_bbox: 0.0416\n",
      "12/08 03:51:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 650/1221]  lr: 2.0000e-04  eta: 0:36:37  time: 0.2744  data_time: 0.0082  memory: 2342  grad_norm: 2.1512  loss: 0.3882  loss_rpn_cls: 0.0159  loss_rpn_bbox: 0.0125  s0.loss_cls: 0.1296  s0.acc: 98.8281  s0.loss_bbox: 0.0541  s1.loss_cls: 0.0624  s1.acc: 99.4576  s1.loss_bbox: 0.0521  s2.loss_cls: 0.0314  s2.acc: 99.4062  s2.loss_bbox: 0.0302\n",
      "12/08 03:51:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 700/1221]  lr: 2.0000e-04  eta: 0:36:23  time: 0.2749  data_time: 0.0085  memory: 2342  grad_norm: 2.2466  loss: 0.4494  loss_rpn_cls: 0.0218  loss_rpn_bbox: 0.0140  s0.loss_cls: 0.1518  s0.acc: 93.5547  s0.loss_bbox: 0.0658  s1.loss_cls: 0.0695  s1.acc: 94.4637  s1.loss_bbox: 0.0571  s2.loss_cls: 0.0341  s2.acc: 95.2593  s2.loss_bbox: 0.0351\n",
      "12/08 03:52:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 750/1221]  lr: 2.0000e-04  eta: 0:36:09  time: 0.2763  data_time: 0.0085  memory: 2342  grad_norm: 2.2299  loss: 0.4722  loss_rpn_cls: 0.0210  loss_rpn_bbox: 0.0167  s0.loss_cls: 0.1565  s0.acc: 96.9727  s0.loss_bbox: 0.0698  s1.loss_cls: 0.0711  s1.acc: 97.2656  s1.loss_bbox: 0.0638  s2.loss_cls: 0.0352  s2.acc: 96.9727  s2.loss_bbox: 0.0381\n",
      "12/08 03:52:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 800/1221]  lr: 2.0000e-04  eta: 0:35:55  time: 0.2754  data_time: 0.0084  memory: 2342  grad_norm: 2.3516  loss: 0.4391  loss_rpn_cls: 0.0181  loss_rpn_bbox: 0.0146  s0.loss_cls: 0.1428  s0.acc: 97.5098  s0.loss_bbox: 0.0655  s1.loss_cls: 0.0668  s1.acc: 97.5098  s1.loss_bbox: 0.0595  s2.loss_cls: 0.0338  s2.acc: 97.6562  s2.loss_bbox: 0.0380\n",
      "12/08 03:52:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 850/1221]  lr: 2.0000e-04  eta: 0:35:41  time: 0.2752  data_time: 0.0087  memory: 2342  grad_norm: 2.2783  loss: 0.4500  loss_rpn_cls: 0.0200  loss_rpn_bbox: 0.0145  s0.loss_cls: 0.1464  s0.acc: 95.9961  s0.loss_bbox: 0.0657  s1.loss_cls: 0.0678  s1.acc: 97.1093  s1.loss_bbox: 0.0616  s2.loss_cls: 0.0346  s2.acc: 96.7679  s2.loss_bbox: 0.0394\n",
      "12/08 03:52:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 900/1221]  lr: 2.0000e-04  eta: 0:35:27  time: 0.2742  data_time: 0.0087  memory: 2342  grad_norm: 2.5539  loss: 0.5168  loss_rpn_cls: 0.0264  loss_rpn_bbox: 0.0165  s0.loss_cls: 0.1726  s0.acc: 95.3125  s0.loss_bbox: 0.0745  s1.loss_cls: 0.0798  s1.acc: 95.9325  s1.loss_bbox: 0.0685  s2.loss_cls: 0.0390  s2.acc: 96.1975  s2.loss_bbox: 0.0395\n",
      "12/08 03:52:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 950/1221]  lr: 2.0000e-04  eta: 0:35:13  time: 0.2755  data_time: 0.0084  memory: 2342  grad_norm: 2.1730  loss: 0.4312  loss_rpn_cls: 0.0184  loss_rpn_bbox: 0.0149  s0.loss_cls: 0.1425  s0.acc: 94.6289  s0.loss_bbox: 0.0629  s1.loss_cls: 0.0659  s1.acc: 93.9831  s1.loss_bbox: 0.0582  s2.loss_cls: 0.0336  s2.acc: 93.8308  s2.loss_bbox: 0.0348\n",
      "12/08 03:53:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1000/1221]  lr: 2.0000e-04  eta: 0:34:59  time: 0.2754  data_time: 0.0087  memory: 2342  grad_norm: 2.4014  loss: 0.5206  loss_rpn_cls: 0.0275  loss_rpn_bbox: 0.0222  s0.loss_cls: 0.1709  s0.acc: 98.2910  s0.loss_bbox: 0.0759  s1.loss_cls: 0.0803  s1.acc: 97.5098  s1.loss_bbox: 0.0666  s2.loss_cls: 0.0394  s2.acc: 97.5098  s2.loss_bbox: 0.0377\n",
      "12/08 03:53:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1050/1221]  lr: 2.0000e-04  eta: 0:34:45  time: 0.2750  data_time: 0.0083  memory: 2342  grad_norm: 2.4672  loss: 0.5617  loss_rpn_cls: 0.0273  loss_rpn_bbox: 0.0193  s0.loss_cls: 0.1844  s0.acc: 95.5566  s0.loss_bbox: 0.0825  s1.loss_cls: 0.0868  s1.acc: 96.4355  s1.loss_bbox: 0.0739  s2.loss_cls: 0.0433  s2.acc: 96.9727  s2.loss_bbox: 0.0442\n",
      "12/08 03:53:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1100/1221]  lr: 2.0000e-04  eta: 0:34:31  time: 0.2744  data_time: 0.0086  memory: 2343  grad_norm: 2.2438  loss: 0.4918  loss_rpn_cls: 0.0283  loss_rpn_bbox: 0.0233  s0.loss_cls: 0.1590  s0.acc: 92.2363  s0.loss_bbox: 0.0701  s1.loss_cls: 0.0723  s1.acc: 92.6019  s1.loss_bbox: 0.0642  s2.loss_cls: 0.0353  s2.acc: 93.6460  s2.loss_bbox: 0.0393\n",
      "12/08 03:53:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1150/1221]  lr: 2.0000e-04  eta: 0:34:17  time: 0.2749  data_time: 0.0088  memory: 2342  grad_norm: 2.2204  loss: 0.4749  loss_rpn_cls: 0.0218  loss_rpn_bbox: 0.0175  s0.loss_cls: 0.1510  s0.acc: 93.8965  s0.loss_bbox: 0.0734  s1.loss_cls: 0.0708  s1.acc: 93.4443  s1.loss_bbox: 0.0667  s2.loss_cls: 0.0351  s2.acc: 93.2961  s2.loss_bbox: 0.0387\n",
      "12/08 03:54:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1200/1221]  lr: 2.0000e-04  eta: 0:34:03  time: 0.2724  data_time: 0.0082  memory: 2342  grad_norm: 2.4095  loss: 0.5054  loss_rpn_cls: 0.0238  loss_rpn_bbox: 0.0189  s0.loss_cls: 0.1644  s0.acc: 97.8516  s0.loss_bbox: 0.0755  s1.loss_cls: 0.0767  s1.acc: 98.2910  s1.loss_bbox: 0.0664  s2.loss_cls: 0.0384  s2.acc: 97.9492  s2.loss_bbox: 0.0412\n",
      "12/08 03:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12 epochs\n",
      "12/08 03:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][  50/1221]  lr: 2.0000e-04  eta: 0:33:43  time: 0.2772  data_time: 0.0121  memory: 2343  grad_norm: 2.2970  loss: 0.4944  loss_rpn_cls: 0.0195  loss_rpn_bbox: 0.0181  s0.loss_cls: 0.1646  s0.acc: 95.2637  s0.loss_bbox: 0.0720  s1.loss_cls: 0.0777  s1.acc: 95.6158  s1.loss_bbox: 0.0652  s2.loss_cls: 0.0391  s2.acc: 96.8488  s2.loss_bbox: 0.0381\n",
      "12/08 03:54:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 100/1221]  lr: 2.0000e-04  eta: 0:33:29  time: 0.2743  data_time: 0.0084  memory: 2343  grad_norm: 2.3089  loss: 0.4847  loss_rpn_cls: 0.0201  loss_rpn_bbox: 0.0168  s0.loss_cls: 0.1594  s0.acc: 98.0957  s0.loss_bbox: 0.0700  s1.loss_cls: 0.0759  s1.acc: 98.4804  s1.loss_bbox: 0.0650  s2.loss_cls: 0.0380  s2.acc: 98.5749  s2.loss_bbox: 0.0395\n",
      "12/08 03:54:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 150/1221]  lr: 2.0000e-04  eta: 0:33:15  time: 0.2766  data_time: 0.0088  memory: 2342  grad_norm: 2.2747  loss: 0.4643  loss_rpn_cls: 0.0230  loss_rpn_bbox: 0.0177  s0.loss_cls: 0.1536  s0.acc: 92.6758  s0.loss_bbox: 0.0670  s1.loss_cls: 0.0691  s1.acc: 93.6578  s1.loss_bbox: 0.0612  s2.loss_cls: 0.0335  s2.acc: 94.4963  s2.loss_bbox: 0.0390\n",
      "12/08 03:55:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 200/1221]  lr: 2.0000e-04  eta: 0:33:01  time: 0.2775  data_time: 0.0087  memory: 2342  grad_norm: 2.3226  loss: 0.5346  loss_rpn_cls: 0.0245  loss_rpn_bbox: 0.0191  s0.loss_cls: 0.1736  s0.acc: 91.4062  s0.loss_bbox: 0.0832  s1.loss_cls: 0.0794  s1.acc: 93.0176  s1.loss_bbox: 0.0722  s2.loss_cls: 0.0390  s2.acc: 93.4570  s2.loss_bbox: 0.0435\n",
      "12/08 03:55:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 250/1221]  lr: 2.0000e-04  eta: 0:32:47  time: 0.2794  data_time: 0.0083  memory: 2342  grad_norm: 2.2289  loss: 0.4805  loss_rpn_cls: 0.0252  loss_rpn_bbox: 0.0192  s0.loss_cls: 0.1574  s0.acc: 94.7266  s0.loss_bbox: 0.0728  s1.loss_cls: 0.0693  s1.acc: 96.0411  s1.loss_bbox: 0.0633  s2.loss_cls: 0.0347  s2.acc: 96.6585  s2.loss_bbox: 0.0387\n",
      "12/08 03:55:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 300/1221]  lr: 2.0000e-04  eta: 0:32:33  time: 0.2744  data_time: 0.0085  memory: 2342  grad_norm: 2.0423  loss: 0.4094  loss_rpn_cls: 0.0180  loss_rpn_bbox: 0.0156  s0.loss_cls: 0.1342  s0.acc: 92.3828  s0.loss_bbox: 0.0606  s1.loss_cls: 0.0604  s1.acc: 93.0514  s1.loss_bbox: 0.0560  s2.loss_cls: 0.0300  s2.acc: 93.2794  s2.loss_bbox: 0.0345\n",
      "12/08 03:55:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:55:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 350/1221]  lr: 2.0000e-04  eta: 0:32:19  time: 0.2753  data_time: 0.0086  memory: 2343  grad_norm: 2.3835  loss: 0.4803  loss_rpn_cls: 0.0232  loss_rpn_bbox: 0.0183  s0.loss_cls: 0.1565  s0.acc: 93.4570  s0.loss_bbox: 0.0699  s1.loss_cls: 0.0719  s1.acc: 94.0945  s1.loss_bbox: 0.0645  s2.loss_cls: 0.0361  s2.acc: 93.7377  s2.loss_bbox: 0.0399\n",
      "12/08 03:56:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 400/1221]  lr: 2.0000e-04  eta: 0:32:05  time: 0.2749  data_time: 0.0086  memory: 2342  grad_norm: 2.3219  loss: 0.4578  loss_rpn_cls: 0.0209  loss_rpn_bbox: 0.0154  s0.loss_cls: 0.1468  s0.acc: 95.8008  s0.loss_bbox: 0.0669  s1.loss_cls: 0.0686  s1.acc: 96.1136  s1.loss_bbox: 0.0650  s2.loss_cls: 0.0346  s2.acc: 97.1986  s2.loss_bbox: 0.0397\n",
      "12/08 03:56:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 450/1221]  lr: 2.0000e-04  eta: 0:31:52  time: 0.2752  data_time: 0.0089  memory: 2342  grad_norm: 2.2090  loss: 0.3881  loss_rpn_cls: 0.0203  loss_rpn_bbox: 0.0134  s0.loss_cls: 0.1320  s0.acc: 97.9492  s0.loss_bbox: 0.0534  s1.loss_cls: 0.0610  s1.acc: 97.1191  s1.loss_bbox: 0.0474  s2.loss_cls: 0.0300  s2.acc: 97.8027  s2.loss_bbox: 0.0305\n",
      "12/08 03:56:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 500/1221]  lr: 2.0000e-04  eta: 0:31:38  time: 0.2741  data_time: 0.0088  memory: 2343  grad_norm: 2.1752  loss: 0.4157  loss_rpn_cls: 0.0201  loss_rpn_bbox: 0.0143  s0.loss_cls: 0.1357  s0.acc: 96.4844  s0.loss_bbox: 0.0584  s1.loss_cls: 0.0636  s1.acc: 97.2656  s1.loss_bbox: 0.0552  s2.loss_cls: 0.0326  s2.acc: 97.4609  s2.loss_bbox: 0.0358\n",
      "12/08 03:56:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 550/1221]  lr: 2.0000e-04  eta: 0:31:24  time: 0.2731  data_time: 0.0083  memory: 2343  grad_norm: 2.3094  loss: 0.4776  loss_rpn_cls: 0.0229  loss_rpn_bbox: 0.0193  s0.loss_cls: 0.1568  s0.acc: 95.5566  s0.loss_bbox: 0.0680  s1.loss_cls: 0.0726  s1.acc: 96.3366  s1.loss_bbox: 0.0628  s2.loss_cls: 0.0366  s2.acc: 96.3239  s2.loss_bbox: 0.0388\n",
      "12/08 03:56:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 600/1221]  lr: 2.0000e-04  eta: 0:31:10  time: 0.2749  data_time: 0.0084  memory: 2342  grad_norm: 2.4119  loss: 0.5136  loss_rpn_cls: 0.0248  loss_rpn_bbox: 0.0173  s0.loss_cls: 0.1669  s0.acc: 91.1133  s0.loss_bbox: 0.0786  s1.loss_cls: 0.0782  s1.acc: 92.0415  s1.loss_bbox: 0.0688  s2.loss_cls: 0.0379  s2.acc: 93.0084  s2.loss_bbox: 0.0412\n",
      "12/08 03:57:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 650/1221]  lr: 2.0000e-04  eta: 0:30:56  time: 0.2764  data_time: 0.0086  memory: 2342  grad_norm: 2.2944  loss: 0.4642  loss_rpn_cls: 0.0221  loss_rpn_bbox: 0.0169  s0.loss_cls: 0.1495  s0.acc: 92.5293  s0.loss_bbox: 0.0688  s1.loss_cls: 0.0702  s1.acc: 93.8315  s1.loss_bbox: 0.0633  s2.loss_cls: 0.0343  s2.acc: 95.1232  s2.loss_bbox: 0.0390\n",
      "12/08 03:57:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 700/1221]  lr: 2.0000e-04  eta: 0:30:42  time: 0.2767  data_time: 0.0088  memory: 2342  grad_norm: 2.4155  loss: 0.4928  loss_rpn_cls: 0.0215  loss_rpn_bbox: 0.0178  s0.loss_cls: 0.1626  s0.acc: 97.2168  s0.loss_bbox: 0.0735  s1.loss_cls: 0.0748  s1.acc: 97.6039  s1.loss_bbox: 0.0659  s2.loss_cls: 0.0369  s2.acc: 97.7832  s2.loss_bbox: 0.0398\n",
      "12/08 03:57:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 750/1221]  lr: 2.0000e-04  eta: 0:30:28  time: 0.2758  data_time: 0.0086  memory: 2343  grad_norm: 2.3371  loss: 0.4717  loss_rpn_cls: 0.0231  loss_rpn_bbox: 0.0161  s0.loss_cls: 0.1531  s0.acc: 93.3594  s0.loss_bbox: 0.0692  s1.loss_cls: 0.0726  s1.acc: 92.9842  s1.loss_bbox: 0.0635  s2.loss_cls: 0.0357  s2.acc: 93.1628  s2.loss_bbox: 0.0384\n",
      "12/08 03:57:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 800/1221]  lr: 2.0000e-04  eta: 0:30:14  time: 0.2728  data_time: 0.0086  memory: 2342  grad_norm: 2.1905  loss: 0.4097  loss_rpn_cls: 0.0159  loss_rpn_bbox: 0.0153  s0.loss_cls: 0.1317  s0.acc: 94.0430  s0.loss_bbox: 0.0608  s1.loss_cls: 0.0608  s1.acc: 93.8735  s1.loss_bbox: 0.0582  s2.loss_cls: 0.0312  s2.acc: 93.0542  s2.loss_bbox: 0.0357\n",
      "12/08 03:58:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 850/1221]  lr: 2.0000e-04  eta: 0:30:00  time: 0.2746  data_time: 0.0086  memory: 2342  grad_norm: 2.4244  loss: 0.4718  loss_rpn_cls: 0.0226  loss_rpn_bbox: 0.0159  s0.loss_cls: 0.1547  s0.acc: 91.7969  s0.loss_bbox: 0.0657  s1.loss_cls: 0.0718  s1.acc: 92.2963  s1.loss_bbox: 0.0645  s2.loss_cls: 0.0363  s2.acc: 93.2279  s2.loss_bbox: 0.0404\n",
      "12/08 03:58:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 900/1221]  lr: 2.0000e-04  eta: 0:29:46  time: 0.2752  data_time: 0.0085  memory: 2343  grad_norm: 2.5419  loss: 0.5688  loss_rpn_cls: 0.0263  loss_rpn_bbox: 0.0211  s0.loss_cls: 0.1864  s0.acc: 92.9199  s0.loss_bbox: 0.0860  s1.loss_cls: 0.0855  s1.acc: 93.1542  s1.loss_bbox: 0.0770  s2.loss_cls: 0.0420  s2.acc: 92.9406  s2.loss_bbox: 0.0445\n",
      "12/08 03:58:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 950/1221]  lr: 2.0000e-04  eta: 0:29:32  time: 0.2742  data_time: 0.0086  memory: 2342  grad_norm: 2.2641  loss: 0.4708  loss_rpn_cls: 0.0240  loss_rpn_bbox: 0.0192  s0.loss_cls: 0.1520  s0.acc: 95.6543  s0.loss_bbox: 0.0677  s1.loss_cls: 0.0706  s1.acc: 95.6457  s1.loss_bbox: 0.0624  s2.loss_cls: 0.0362  s2.acc: 95.7107  s2.loss_bbox: 0.0386\n",
      "12/08 03:58:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1000/1221]  lr: 2.0000e-04  eta: 0:29:18  time: 0.2735  data_time: 0.0082  memory: 2343  grad_norm: 2.4216  loss: 0.5089  loss_rpn_cls: 0.0237  loss_rpn_bbox: 0.0198  s0.loss_cls: 0.1673  s0.acc: 94.9219  s0.loss_bbox: 0.0722  s1.loss_cls: 0.0799  s1.acc: 94.8174  s1.loss_bbox: 0.0652  s2.loss_cls: 0.0403  s2.acc: 94.6066  s2.loss_bbox: 0.0405\n",
      "12/08 03:59:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1050/1221]  lr: 2.0000e-04  eta: 0:29:04  time: 0.2758  data_time: 0.0089  memory: 2342  grad_norm: 2.2495  loss: 0.4281  loss_rpn_cls: 0.0193  loss_rpn_bbox: 0.0151  s0.loss_cls: 0.1406  s0.acc: 95.0684  s0.loss_bbox: 0.0649  s1.loss_cls: 0.0638  s1.acc: 95.4388  s1.loss_bbox: 0.0587  s2.loss_cls: 0.0309  s2.acc: 96.4179  s2.loss_bbox: 0.0347\n",
      "12/08 03:59:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1100/1221]  lr: 2.0000e-04  eta: 0:28:50  time: 0.2743  data_time: 0.0086  memory: 2342  grad_norm: 2.5464  loss: 0.4884  loss_rpn_cls: 0.0211  loss_rpn_bbox: 0.0171  s0.loss_cls: 0.1585  s0.acc: 89.2578  s0.loss_bbox: 0.0710  s1.loss_cls: 0.0744  s1.acc: 89.5639  s1.loss_bbox: 0.0668  s2.loss_cls: 0.0370  s2.acc: 88.0626  s2.loss_bbox: 0.0426\n",
      "12/08 03:59:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1150/1221]  lr: 2.0000e-04  eta: 0:28:36  time: 0.2776  data_time: 0.0092  memory: 2342  grad_norm: 2.3138  loss: 0.5014  loss_rpn_cls: 0.0234  loss_rpn_bbox: 0.0210  s0.loss_cls: 0.1613  s0.acc: 96.0938  s0.loss_bbox: 0.0764  s1.loss_cls: 0.0740  s1.acc: 95.8984  s1.loss_bbox: 0.0688  s2.loss_cls: 0.0366  s2.acc: 97.6528  s2.loss_bbox: 0.0400\n",
      "12/08 03:59:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][1200/1221]  lr: 2.0000e-04  eta: 0:28:22  time: 0.2753  data_time: 0.0083  memory: 2342  grad_norm: 2.2526  loss: 0.4157  loss_rpn_cls: 0.0218  loss_rpn_bbox: 0.0142  s0.loss_cls: 0.1394  s0.acc: 98.1445  s0.loss_bbox: 0.0557  s1.loss_cls: 0.0648  s1.acc: 98.7305  s1.loss_bbox: 0.0541  s2.loss_cls: 0.0322  s2.acc: 99.5117  s2.loss_bbox: 0.0335\n",
      "12/08 03:59:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 03:59:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 13 epochs\n",
      "12/08 04:00:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][  50/1221]  lr: 2.0000e-04  eta: 0:28:02  time: 0.2793  data_time: 0.0124  memory: 2342  grad_norm: 2.4314  loss: 0.4463  loss_rpn_cls: 0.0206  loss_rpn_bbox: 0.0161  s0.loss_cls: 0.1473  s0.acc: 91.3086  s0.loss_bbox: 0.0643  s1.loss_cls: 0.0684  s1.acc: 91.6453  s1.loss_bbox: 0.0593  s2.loss_cls: 0.0339  s2.acc: 91.3713  s2.loss_bbox: 0.0363\n",
      "12/08 04:00:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 100/1221]  lr: 2.0000e-04  eta: 0:27:48  time: 0.2749  data_time: 0.0089  memory: 2342  grad_norm: 2.2491  loss: 0.3949  loss_rpn_cls: 0.0173  loss_rpn_bbox: 0.0143  s0.loss_cls: 0.1288  s0.acc: 97.5586  s0.loss_bbox: 0.0533  s1.loss_cls: 0.0619  s1.acc: 97.0105  s1.loss_bbox: 0.0533  s2.loss_cls: 0.0318  s2.acc: 97.6954  s2.loss_bbox: 0.0342\n",
      "12/08 04:00:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 04:00:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 150/1221]  lr: 2.0000e-04  eta: 0:27:34  time: 0.2768  data_time: 0.0089  memory: 2343  grad_norm: 2.5257  loss: 0.5012  loss_rpn_cls: 0.0218  loss_rpn_bbox: 0.0169  s0.loss_cls: 0.1668  s0.acc: 92.7734  s0.loss_bbox: 0.0743  s1.loss_cls: 0.0762  s1.acc: 93.5020  s1.loss_bbox: 0.0665  s2.loss_cls: 0.0373  s2.acc: 94.8046  s2.loss_bbox: 0.0414\n",
      "12/08 04:00:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 200/1221]  lr: 2.0000e-04  eta: 0:27:21  time: 0.2787  data_time: 0.0085  memory: 2342  grad_norm: 2.2169  loss: 0.4376  loss_rpn_cls: 0.0173  loss_rpn_bbox: 0.0164  s0.loss_cls: 0.1446  s0.acc: 90.3809  s0.loss_bbox: 0.0610  s1.loss_cls: 0.0693  s1.acc: 90.4933  s1.loss_bbox: 0.0580  s2.loss_cls: 0.0344  s2.acc: 90.3916  s2.loss_bbox: 0.0367\n",
      "12/08 04:00:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 250/1221]  lr: 2.0000e-04  eta: 0:27:07  time: 0.2753  data_time: 0.0085  memory: 2343  grad_norm: 2.2215  loss: 0.4339  loss_rpn_cls: 0.0195  loss_rpn_bbox: 0.0145  s0.loss_cls: 0.1401  s0.acc: 95.7031  s0.loss_bbox: 0.0645  s1.loss_cls: 0.0646  s1.acc: 96.6127  s1.loss_bbox: 0.0602  s2.loss_cls: 0.0322  s2.acc: 97.1555  s2.loss_bbox: 0.0384\n",
      "12/08 04:01:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 300/1221]  lr: 2.0000e-04  eta: 0:26:53  time: 0.2737  data_time: 0.0086  memory: 2342  grad_norm: 2.3789  loss: 0.4838  loss_rpn_cls: 0.0230  loss_rpn_bbox: 0.0166  s0.loss_cls: 0.1569  s0.acc: 95.2148  s0.loss_bbox: 0.0740  s1.loss_cls: 0.0744  s1.acc: 95.1303  s1.loss_bbox: 0.0635  s2.loss_cls: 0.0363  s2.acc: 95.6757  s2.loss_bbox: 0.0391\n",
      "12/08 04:01:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 350/1221]  lr: 2.0000e-04  eta: 0:26:39  time: 0.2776  data_time: 0.0091  memory: 2343  grad_norm: 2.3626  loss: 0.5098  loss_rpn_cls: 0.0249  loss_rpn_bbox: 0.0224  s0.loss_cls: 0.1668  s0.acc: 97.7539  s0.loss_bbox: 0.0733  s1.loss_cls: 0.0783  s1.acc: 96.9238  s1.loss_bbox: 0.0662  s2.loss_cls: 0.0383  s2.acc: 97.9492  s2.loss_bbox: 0.0395\n",
      "12/08 04:01:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 400/1221]  lr: 2.0000e-04  eta: 0:26:25  time: 0.2761  data_time: 0.0093  memory: 2342  grad_norm: 2.4610  loss: 0.4775  loss_rpn_cls: 0.0249  loss_rpn_bbox: 0.0167  s0.loss_cls: 0.1612  s0.acc: 95.1172  s0.loss_bbox: 0.0636  s1.loss_cls: 0.0758  s1.acc: 95.0417  s1.loss_bbox: 0.0596  s2.loss_cls: 0.0380  s2.acc: 96.5960  s2.loss_bbox: 0.0377\n",
      "12/08 04:01:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 450/1221]  lr: 2.0000e-04  eta: 0:26:11  time: 0.2759  data_time: 0.0085  memory: 2342  grad_norm: 2.2934  loss: 0.5049  loss_rpn_cls: 0.0255  loss_rpn_bbox: 0.0181  s0.loss_cls: 0.1630  s0.acc: 93.7988  s0.loss_bbox: 0.0766  s1.loss_cls: 0.0734  s1.acc: 94.4858  s1.loss_bbox: 0.0697  s2.loss_cls: 0.0366  s2.acc: 94.2615  s2.loss_bbox: 0.0420\n",
      "12/08 04:02:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 500/1221]  lr: 2.0000e-04  eta: 0:25:57  time: 0.2745  data_time: 0.0085  memory: 2343  grad_norm: 2.2308  loss: 0.4524  loss_rpn_cls: 0.0204  loss_rpn_bbox: 0.0164  s0.loss_cls: 0.1518  s0.acc: 93.6035  s0.loss_bbox: 0.0653  s1.loss_cls: 0.0697  s1.acc: 94.8250  s1.loss_bbox: 0.0587  s2.loss_cls: 0.0336  s2.acc: 95.1952  s2.loss_bbox: 0.0364\n",
      "12/08 04:02:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 550/1221]  lr: 2.0000e-04  eta: 0:25:43  time: 0.2778  data_time: 0.0086  memory: 2342  grad_norm: 2.2266  loss: 0.5039  loss_rpn_cls: 0.0250  loss_rpn_bbox: 0.0208  s0.loss_cls: 0.1593  s0.acc: 94.3848  s0.loss_bbox: 0.0767  s1.loss_cls: 0.0718  s1.acc: 93.9424  s1.loss_bbox: 0.0714  s2.loss_cls: 0.0354  s2.acc: 93.4524  s2.loss_bbox: 0.0434\n",
      "12/08 04:02:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 600/1221]  lr: 2.0000e-04  eta: 0:25:29  time: 0.2752  data_time: 0.0085  memory: 2342  grad_norm: 2.2512  loss: 0.4312  loss_rpn_cls: 0.0217  loss_rpn_bbox: 0.0156  s0.loss_cls: 0.1421  s0.acc: 93.5059  s0.loss_bbox: 0.0579  s1.loss_cls: 0.0689  s1.acc: 92.7175  s1.loss_bbox: 0.0557  s2.loss_cls: 0.0344  s2.acc: 93.4931  s2.loss_bbox: 0.0348\n",
      "12/08 04:02:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 650/1221]  lr: 2.0000e-04  eta: 0:25:15  time: 0.2750  data_time: 0.0083  memory: 2342  grad_norm: 2.3358  loss: 0.4812  loss_rpn_cls: 0.0224  loss_rpn_bbox: 0.0178  s0.loss_cls: 0.1563  s0.acc: 93.5059  s0.loss_bbox: 0.0720  s1.loss_cls: 0.0712  s1.acc: 93.0152  s1.loss_bbox: 0.0655  s2.loss_cls: 0.0352  s2.acc: 91.8387  s2.loss_bbox: 0.0407\n",
      "12/08 04:03:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 700/1221]  lr: 2.0000e-04  eta: 0:25:01  time: 0.2756  data_time: 0.0086  memory: 2342  grad_norm: 2.2305  loss: 0.4354  loss_rpn_cls: 0.0197  loss_rpn_bbox: 0.0176  s0.loss_cls: 0.1394  s0.acc: 93.6523  s0.loss_bbox: 0.0647  s1.loss_cls: 0.0645  s1.acc: 93.5338  s1.loss_bbox: 0.0604  s2.loss_cls: 0.0324  s2.acc: 93.4542  s2.loss_bbox: 0.0368\n",
      "12/08 04:03:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 750/1221]  lr: 2.0000e-04  eta: 0:24:47  time: 0.2751  data_time: 0.0085  memory: 2342  grad_norm: 2.4831  loss: 0.5030  loss_rpn_cls: 0.0244  loss_rpn_bbox: 0.0210  s0.loss_cls: 0.1623  s0.acc: 91.8945  s0.loss_bbox: 0.0738  s1.loss_cls: 0.0763  s1.acc: 92.2363  s1.loss_bbox: 0.0679  s2.loss_cls: 0.0380  s2.acc: 91.7969  s2.loss_bbox: 0.0394\n",
      "12/08 04:03:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 800/1221]  lr: 2.0000e-04  eta: 0:24:33  time: 0.2744  data_time: 0.0082  memory: 2342  grad_norm: 2.2101  loss: 0.4185  loss_rpn_cls: 0.0201  loss_rpn_bbox: 0.0160  s0.loss_cls: 0.1377  s0.acc: 97.4609  s0.loss_bbox: 0.0596  s1.loss_cls: 0.0648  s1.acc: 97.7051  s1.loss_bbox: 0.0548  s2.loss_cls: 0.0325  s2.acc: 97.5586  s2.loss_bbox: 0.0330\n",
      "12/08 04:03:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 850/1221]  lr: 2.0000e-04  eta: 0:24:19  time: 0.2740  data_time: 0.0085  memory: 2342  grad_norm: 2.2378  loss: 0.4557  loss_rpn_cls: 0.0206  loss_rpn_bbox: 0.0167  s0.loss_cls: 0.1477  s0.acc: 91.2109  s0.loss_bbox: 0.0673  s1.loss_cls: 0.0682  s1.acc: 92.9895  s1.loss_bbox: 0.0621  s2.loss_cls: 0.0340  s2.acc: 94.3753  s2.loss_bbox: 0.0391\n",
      "12/08 04:03:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 900/1221]  lr: 2.0000e-04  eta: 0:24:05  time: 0.2757  data_time: 0.0084  memory: 2343  grad_norm: 2.5069  loss: 0.4749  loss_rpn_cls: 0.0252  loss_rpn_bbox: 0.0170  s0.loss_cls: 0.1602  s0.acc: 97.1680  s0.loss_bbox: 0.0662  s1.loss_cls: 0.0730  s1.acc: 98.1445  s1.loss_bbox: 0.0596  s2.loss_cls: 0.0368  s2.acc: 97.4609  s2.loss_bbox: 0.0369\n",
      "12/08 04:04:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 950/1221]  lr: 2.0000e-04  eta: 0:23:52  time: 0.2765  data_time: 0.0085  memory: 2342  grad_norm: 2.4082  loss: 0.4845  loss_rpn_cls: 0.0237  loss_rpn_bbox: 0.0168  s0.loss_cls: 0.1538  s0.acc: 95.4102  s0.loss_bbox: 0.0734  s1.loss_cls: 0.0712  s1.acc: 97.2125  s1.loss_bbox: 0.0686  s2.loss_cls: 0.0355  s2.acc: 97.1698  s2.loss_bbox: 0.0414\n",
      "12/08 04:04:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1000/1221]  lr: 2.0000e-04  eta: 0:23:38  time: 0.2755  data_time: 0.0085  memory: 2343  grad_norm: 2.3484  loss: 0.4604  loss_rpn_cls: 0.0192  loss_rpn_bbox: 0.0149  s0.loss_cls: 0.1530  s0.acc: 90.0879  s0.loss_bbox: 0.0709  s1.loss_cls: 0.0695  s1.acc: 90.9091  s1.loss_bbox: 0.0615  s2.loss_cls: 0.0339  s2.acc: 88.8726  s2.loss_bbox: 0.0373\n",
      "12/08 04:04:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1050/1221]  lr: 2.0000e-04  eta: 0:23:24  time: 0.2738  data_time: 0.0086  memory: 2342  grad_norm: 2.3590  loss: 0.4803  loss_rpn_cls: 0.0222  loss_rpn_bbox: 0.0162  s0.loss_cls: 0.1557  s0.acc: 95.5566  s0.loss_bbox: 0.0724  s1.loss_cls: 0.0720  s1.acc: 95.6287  s1.loss_bbox: 0.0667  s2.loss_cls: 0.0362  s2.acc: 94.7213  s2.loss_bbox: 0.0389\n",
      "12/08 04:04:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1100/1221]  lr: 2.0000e-04  eta: 0:23:10  time: 0.2747  data_time: 0.0083  memory: 2343  grad_norm: 2.3607  loss: 0.4480  loss_rpn_cls: 0.0183  loss_rpn_bbox: 0.0170  s0.loss_cls: 0.1466  s0.acc: 94.7266  s0.loss_bbox: 0.0672  s1.loss_cls: 0.0677  s1.acc: 94.4336  s1.loss_bbox: 0.0618  s2.loss_cls: 0.0334  s2.acc: 94.3359  s2.loss_bbox: 0.0359\n",
      "12/08 04:05:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 04:05:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1150/1221]  lr: 2.0000e-04  eta: 0:22:56  time: 0.2756  data_time: 0.0087  memory: 2342  grad_norm: 2.4741  loss: 0.4928  loss_rpn_cls: 0.0234  loss_rpn_bbox: 0.0194  s0.loss_cls: 0.1634  s0.acc: 97.1191  s0.loss_bbox: 0.0712  s1.loss_cls: 0.0760  s1.acc: 96.5332  s1.loss_bbox: 0.0641  s2.loss_cls: 0.0379  s2.acc: 95.8496  s2.loss_bbox: 0.0374\n",
      "12/08 04:05:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][1200/1221]  lr: 2.0000e-04  eta: 0:22:42  time: 0.2760  data_time: 0.0084  memory: 2342  grad_norm: 2.3634  loss: 0.4890  loss_rpn_cls: 0.0221  loss_rpn_bbox: 0.0183  s0.loss_cls: 0.1577  s0.acc: 97.7539  s0.loss_bbox: 0.0732  s1.loss_cls: 0.0715  s1.acc: 97.6074  s1.loss_bbox: 0.0693  s2.loss_cls: 0.0352  s2.acc: 97.1680  s2.loss_bbox: 0.0417\n",
      "12/08 04:05:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 04:05:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 14 epochs\n",
      "12/08 04:05:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][  50/1221]  lr: 2.0000e-04  eta: 0:22:22  time: 0.2777  data_time: 0.0116  memory: 2342  grad_norm: 2.3245  loss: 0.4524  loss_rpn_cls: 0.0202  loss_rpn_bbox: 0.0188  s0.loss_cls: 0.1499  s0.acc: 90.2344  s0.loss_bbox: 0.0655  s1.loss_cls: 0.0692  s1.acc: 91.1868  s1.loss_bbox: 0.0582  s2.loss_cls: 0.0348  s2.acc: 91.0359  s2.loss_bbox: 0.0358\n",
      "12/08 04:05:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 100/1221]  lr: 2.0000e-04  eta: 0:22:08  time: 0.2771  data_time: 0.0082  memory: 2342  grad_norm: 2.2064  loss: 0.4320  loss_rpn_cls: 0.0195  loss_rpn_bbox: 0.0172  s0.loss_cls: 0.1390  s0.acc: 91.5527  s0.loss_bbox: 0.0653  s1.loss_cls: 0.0625  s1.acc: 92.7156  s1.loss_bbox: 0.0596  s2.loss_cls: 0.0312  s2.acc: 91.8703  s2.loss_bbox: 0.0377\n",
      "12/08 04:06:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 150/1221]  lr: 2.0000e-04  eta: 0:21:54  time: 0.2754  data_time: 0.0087  memory: 2343  grad_norm: 2.2678  loss: 0.4151  loss_rpn_cls: 0.0174  loss_rpn_bbox: 0.0143  s0.loss_cls: 0.1398  s0.acc: 99.7070  s0.loss_bbox: 0.0597  s1.loss_cls: 0.0628  s1.acc: 99.6582  s1.loss_bbox: 0.0561  s2.loss_cls: 0.0313  s2.acc: 99.8047  s2.loss_bbox: 0.0337\n",
      "12/08 04:06:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 200/1221]  lr: 2.0000e-04  eta: 0:21:40  time: 0.2727  data_time: 0.0084  memory: 2342  grad_norm: 2.2568  loss: 0.4209  loss_rpn_cls: 0.0213  loss_rpn_bbox: 0.0143  s0.loss_cls: 0.1406  s0.acc: 97.1191  s0.loss_bbox: 0.0594  s1.loss_cls: 0.0638  s1.acc: 97.4232  s1.loss_bbox: 0.0548  s2.loss_cls: 0.0315  s2.acc: 97.7160  s2.loss_bbox: 0.0352\n",
      "12/08 04:06:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 250/1221]  lr: 2.0000e-04  eta: 0:21:26  time: 0.2745  data_time: 0.0085  memory: 2342  grad_norm: 2.4646  loss: 0.4813  loss_rpn_cls: 0.0232  loss_rpn_bbox: 0.0178  s0.loss_cls: 0.1603  s0.acc: 92.3340  s0.loss_bbox: 0.0682  s1.loss_cls: 0.0746  s1.acc: 94.5436  s1.loss_bbox: 0.0613  s2.loss_cls: 0.0379  s2.acc: 94.0476  s2.loss_bbox: 0.0381\n",
      "12/08 04:06:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 300/1221]  lr: 2.0000e-04  eta: 0:21:13  time: 0.2766  data_time: 0.0084  memory: 2342  grad_norm: 2.3190  loss: 0.4538  loss_rpn_cls: 0.0215  loss_rpn_bbox: 0.0160  s0.loss_cls: 0.1477  s0.acc: 94.9219  s0.loss_bbox: 0.0668  s1.loss_cls: 0.0674  s1.acc: 95.0655  s1.loss_bbox: 0.0621  s2.loss_cls: 0.0334  s2.acc: 94.1386  s2.loss_bbox: 0.0388\n",
      "12/08 04:07:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 350/1221]  lr: 2.0000e-04  eta: 0:20:59  time: 0.2751  data_time: 0.0086  memory: 2343  grad_norm: 2.3637  loss: 0.4728  loss_rpn_cls: 0.0197  loss_rpn_bbox: 0.0165  s0.loss_cls: 0.1483  s0.acc: 96.4355  s0.loss_bbox: 0.0708  s1.loss_cls: 0.0717  s1.acc: 95.5566  s1.loss_bbox: 0.0678  s2.loss_cls: 0.0358  s2.acc: 95.6543  s2.loss_bbox: 0.0422\n",
      "12/08 04:07:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 400/1221]  lr: 2.0000e-04  eta: 0:20:45  time: 0.2801  data_time: 0.0084  memory: 2342  grad_norm: 2.3495  loss: 0.4814  loss_rpn_cls: 0.0216  loss_rpn_bbox: 0.0176  s0.loss_cls: 0.1605  s0.acc: 94.8730  s0.loss_bbox: 0.0714  s1.loss_cls: 0.0728  s1.acc: 94.6237  s1.loss_bbox: 0.0630  s2.loss_cls: 0.0358  s2.acc: 95.7478  s2.loss_bbox: 0.0385\n",
      "12/08 04:07:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 450/1221]  lr: 2.0000e-04  eta: 0:20:31  time: 0.2764  data_time: 0.0089  memory: 2342  grad_norm: 2.4873  loss: 0.5204  loss_rpn_cls: 0.0238  loss_rpn_bbox: 0.0179  s0.loss_cls: 0.1677  s0.acc: 90.9180  s0.loss_bbox: 0.0769  s1.loss_cls: 0.0784  s1.acc: 89.5378  s1.loss_bbox: 0.0724  s2.loss_cls: 0.0392  s2.acc: 88.9627  s2.loss_bbox: 0.0441\n",
      "12/08 04:07:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 500/1221]  lr: 2.0000e-04  eta: 0:20:17  time: 0.2783  data_time: 0.0090  memory: 2343  grad_norm: 2.3968  loss: 0.5001  loss_rpn_cls: 0.0251  loss_rpn_bbox: 0.0185  s0.loss_cls: 0.1605  s0.acc: 97.2168  s0.loss_bbox: 0.0762  s1.loss_cls: 0.0717  s1.acc: 97.5586  s1.loss_bbox: 0.0706  s2.loss_cls: 0.0353  s2.acc: 98.0957  s2.loss_bbox: 0.0422\n",
      "12/08 04:08:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 550/1221]  lr: 2.0000e-04  eta: 0:20:03  time: 0.2767  data_time: 0.0088  memory: 2342  grad_norm: 2.4165  loss: 0.4946  loss_rpn_cls: 0.0244  loss_rpn_bbox: 0.0193  s0.loss_cls: 0.1606  s0.acc: 90.0391  s0.loss_bbox: 0.0739  s1.loss_cls: 0.0731  s1.acc: 87.7158  s1.loss_bbox: 0.0671  s2.loss_cls: 0.0361  s2.acc: 88.3629  s2.loss_bbox: 0.0402\n",
      "12/08 04:08:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 600/1221]  lr: 2.0000e-04  eta: 0:19:49  time: 0.2771  data_time: 0.0090  memory: 2343  grad_norm: 2.2632  loss: 0.4432  loss_rpn_cls: 0.0190  loss_rpn_bbox: 0.0160  s0.loss_cls: 0.1466  s0.acc: 94.8730  s0.loss_bbox: 0.0631  s1.loss_cls: 0.0688  s1.acc: 95.4613  s1.loss_bbox: 0.0591  s2.loss_cls: 0.0347  s2.acc: 95.3672  s2.loss_bbox: 0.0358\n",
      "12/08 04:08:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 650/1221]  lr: 2.0000e-04  eta: 0:19:35  time: 0.2755  data_time: 0.0084  memory: 2343  grad_norm: 2.0826  loss: 0.3814  loss_rpn_cls: 0.0200  loss_rpn_bbox: 0.0145  s0.loss_cls: 0.1239  s0.acc: 98.1445  s0.loss_bbox: 0.0560  s1.loss_cls: 0.0567  s1.acc: 97.9492  s1.loss_bbox: 0.0509  s2.loss_cls: 0.0282  s2.acc: 95.4102  s2.loss_bbox: 0.0311\n",
      "12/08 04:08:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 700/1221]  lr: 2.0000e-04  eta: 0:19:21  time: 0.2766  data_time: 0.0080  memory: 2343  grad_norm: 2.5050  loss: 0.5085  loss_rpn_cls: 0.0234  loss_rpn_bbox: 0.0212  s0.loss_cls: 0.1729  s0.acc: 99.0723  s0.loss_bbox: 0.0727  s1.loss_cls: 0.0771  s1.acc: 98.2422  s1.loss_bbox: 0.0642  s2.loss_cls: 0.0377  s2.acc: 98.0469  s2.loss_bbox: 0.0393\n",
      "12/08 04:08:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 750/1221]  lr: 2.0000e-04  eta: 0:19:08  time: 0.2780  data_time: 0.0082  memory: 2342  grad_norm: 2.4914  loss: 0.5272  loss_rpn_cls: 0.0246  loss_rpn_bbox: 0.0196  s0.loss_cls: 0.1710  s0.acc: 97.4121  s0.loss_bbox: 0.0808  s1.loss_cls: 0.0793  s1.acc: 98.0129  s1.loss_bbox: 0.0715  s2.loss_cls: 0.0386  s2.acc: 97.9031  s2.loss_bbox: 0.0418\n",
      "12/08 04:09:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 800/1221]  lr: 2.0000e-04  eta: 0:18:54  time: 0.2754  data_time: 0.0086  memory: 2342  grad_norm: 2.4108  loss: 0.4882  loss_rpn_cls: 0.0205  loss_rpn_bbox: 0.0182  s0.loss_cls: 0.1558  s0.acc: 92.2363  s0.loss_bbox: 0.0740  s1.loss_cls: 0.0706  s1.acc: 92.3828  s1.loss_bbox: 0.0703  s2.loss_cls: 0.0360  s2.acc: 92.2852  s2.loss_bbox: 0.0429\n",
      "12/08 04:09:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 850/1221]  lr: 2.0000e-04  eta: 0:18:40  time: 0.2772  data_time: 0.0087  memory: 2342  grad_norm: 2.5435  loss: 0.5643  loss_rpn_cls: 0.0264  loss_rpn_bbox: 0.0276  s0.loss_cls: 0.1844  s0.acc: 94.2383  s0.loss_bbox: 0.0834  s1.loss_cls: 0.0854  s1.acc: 94.9951  s1.loss_bbox: 0.0740  s2.loss_cls: 0.0411  s2.acc: 95.2311  s2.loss_bbox: 0.0421\n",
      "12/08 04:09:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 900/1221]  lr: 2.0000e-04  eta: 0:18:26  time: 0.2751  data_time: 0.0086  memory: 2342  grad_norm: 2.1978  loss: 0.3942  loss_rpn_cls: 0.0180  loss_rpn_bbox: 0.0125  s0.loss_cls: 0.1327  s0.acc: 96.8750  s0.loss_bbox: 0.0525  s1.loss_cls: 0.0628  s1.acc: 95.3613  s1.loss_bbox: 0.0509  s2.loss_cls: 0.0320  s2.acc: 94.7266  s2.loss_bbox: 0.0328\n",
      "12/08 04:09:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 04:09:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 950/1221]  lr: 2.0000e-04  eta: 0:18:12  time: 0.2769  data_time: 0.0088  memory: 2343  grad_norm: 2.4607  loss: 0.4523  loss_rpn_cls: 0.0233  loss_rpn_bbox: 0.0135  s0.loss_cls: 0.1454  s0.acc: 99.2676  s0.loss_bbox: 0.0666  s1.loss_cls: 0.0687  s1.acc: 99.5605  s1.loss_bbox: 0.0622  s2.loss_cls: 0.0343  s2.acc: 99.3164  s2.loss_bbox: 0.0384\n",
      "12/08 04:10:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1000/1221]  lr: 2.0000e-04  eta: 0:17:58  time: 0.2747  data_time: 0.0086  memory: 2342  grad_norm: 2.4811  loss: 0.5215  loss_rpn_cls: 0.0222  loss_rpn_bbox: 0.0199  s0.loss_cls: 0.1685  s0.acc: 97.5586  s0.loss_bbox: 0.0811  s1.loss_cls: 0.0754  s1.acc: 97.6562  s1.loss_bbox: 0.0723  s2.loss_cls: 0.0379  s2.acc: 97.5586  s2.loss_bbox: 0.0442\n",
      "12/08 04:10:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1050/1221]  lr: 2.0000e-04  eta: 0:17:44  time: 0.2747  data_time: 0.0086  memory: 2342  grad_norm: 2.2137  loss: 0.3991  loss_rpn_cls: 0.0169  loss_rpn_bbox: 0.0138  s0.loss_cls: 0.1323  s0.acc: 93.1641  s0.loss_bbox: 0.0576  s1.loss_cls: 0.0602  s1.acc: 92.6745  s1.loss_bbox: 0.0534  s2.loss_cls: 0.0307  s2.acc: 92.4131  s2.loss_bbox: 0.0342\n",
      "12/08 04:10:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1100/1221]  lr: 2.0000e-04  eta: 0:17:30  time: 0.2754  data_time: 0.0089  memory: 2342  grad_norm: 2.3683  loss: 0.4770  loss_rpn_cls: 0.0257  loss_rpn_bbox: 0.0181  s0.loss_cls: 0.1545  s0.acc: 98.0957  s0.loss_bbox: 0.0697  s1.loss_cls: 0.0716  s1.acc: 97.4121  s1.loss_bbox: 0.0633  s2.loss_cls: 0.0351  s2.acc: 96.6797  s2.loss_bbox: 0.0389\n",
      "12/08 04:10:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1150/1221]  lr: 2.0000e-04  eta: 0:17:16  time: 0.2754  data_time: 0.0087  memory: 2343  grad_norm: 2.3168  loss: 0.4688  loss_rpn_cls: 0.0224  loss_rpn_bbox: 0.0180  s0.loss_cls: 0.1507  s0.acc: 94.6289  s0.loss_bbox: 0.0721  s1.loss_cls: 0.0699  s1.acc: 95.5401  s1.loss_bbox: 0.0639  s2.loss_cls: 0.0349  s2.acc: 96.1975  s2.loss_bbox: 0.0369\n",
      "12/08 04:11:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][1200/1221]  lr: 2.0000e-04  eta: 0:17:02  time: 0.2755  data_time: 0.0090  memory: 2342  grad_norm: 2.3588  loss: 0.4159  loss_rpn_cls: 0.0173  loss_rpn_bbox: 0.0149  s0.loss_cls: 0.1361  s0.acc: 95.1660  s0.loss_bbox: 0.0598  s1.loss_cls: 0.0625  s1.acc: 95.1980  s1.loss_bbox: 0.0570  s2.loss_cls: 0.0322  s2.acc: 95.0224  s2.loss_bbox: 0.0361\n",
      "12/08 04:11:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 04:11:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 15 epochs\n",
      "12/08 04:11:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][  50/1221]  lr: 2.0000e-04  eta: 0:16:43  time: 0.2798  data_time: 0.0122  memory: 2342  grad_norm: 2.3465  loss: 0.4606  loss_rpn_cls: 0.0194  loss_rpn_bbox: 0.0170  s0.loss_cls: 0.1477  s0.acc: 94.0918  s0.loss_bbox: 0.0726  s1.loss_cls: 0.0667  s1.acc: 93.9861  s1.loss_bbox: 0.0650  s2.loss_cls: 0.0328  s2.acc: 93.6627  s2.loss_bbox: 0.0394\n",
      "12/08 04:11:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 100/1221]  lr: 2.0000e-04  eta: 0:16:29  time: 0.2770  data_time: 0.0086  memory: 2343  grad_norm: 2.4039  loss: 0.4508  loss_rpn_cls: 0.0206  loss_rpn_bbox: 0.0167  s0.loss_cls: 0.1477  s0.acc: 95.2637  s0.loss_bbox: 0.0672  s1.loss_cls: 0.0681  s1.acc: 95.9373  s1.loss_bbox: 0.0595  s2.loss_cls: 0.0339  s2.acc: 96.5737  s2.loss_bbox: 0.0369\n",
      "12/08 04:11:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 150/1221]  lr: 2.0000e-04  eta: 0:16:15  time: 0.2758  data_time: 0.0086  memory: 2343  grad_norm: 2.1218  loss: 0.4174  loss_rpn_cls: 0.0176  loss_rpn_bbox: 0.0157  s0.loss_cls: 0.1372  s0.acc: 98.6816  s0.loss_bbox: 0.0622  s1.loss_cls: 0.0626  s1.acc: 98.1934  s1.loss_bbox: 0.0563  s2.loss_cls: 0.0309  s2.acc: 99.2188  s2.loss_bbox: 0.0349\n",
      "12/08 04:12:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 200/1221]  lr: 2.0000e-04  eta: 0:16:01  time: 0.2757  data_time: 0.0087  memory: 2342  grad_norm: 2.0524  loss: 0.3383  loss_rpn_cls: 0.0130  loss_rpn_bbox: 0.0129  s0.loss_cls: 0.1109  s0.acc: 96.5332  s0.loss_bbox: 0.0506  s1.loss_cls: 0.0497  s1.acc: 97.3105  s1.loss_bbox: 0.0463  s2.loss_cls: 0.0248  s2.acc: 98.4789  s2.loss_bbox: 0.0303\n",
      "12/08 04:12:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 250/1221]  lr: 2.0000e-04  eta: 0:15:47  time: 0.2767  data_time: 0.0087  memory: 2342  grad_norm: 2.3740  loss: 0.4095  loss_rpn_cls: 0.0197  loss_rpn_bbox: 0.0158  s0.loss_cls: 0.1368  s0.acc: 94.0918  s0.loss_bbox: 0.0600  s1.loss_cls: 0.0626  s1.acc: 95.4880  s1.loss_bbox: 0.0521  s2.loss_cls: 0.0309  s2.acc: 95.5078  s2.loss_bbox: 0.0316\n",
      "12/08 04:12:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 300/1221]  lr: 2.0000e-04  eta: 0:15:33  time: 0.2746  data_time: 0.0086  memory: 2343  grad_norm: 2.3295  loss: 0.4329  loss_rpn_cls: 0.0174  loss_rpn_bbox: 0.0141  s0.loss_cls: 0.1430  s0.acc: 97.1680  s0.loss_bbox: 0.0630  s1.loss_cls: 0.0647  s1.acc: 96.7773  s1.loss_bbox: 0.0610  s2.loss_cls: 0.0324  s2.acc: 96.5332  s2.loss_bbox: 0.0372\n",
      "12/08 04:12:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 350/1221]  lr: 2.0000e-04  eta: 0:15:19  time: 0.2750  data_time: 0.0087  memory: 2342  grad_norm: 2.3981  loss: 0.4578  loss_rpn_cls: 0.0198  loss_rpn_bbox: 0.0147  s0.loss_cls: 0.1539  s0.acc: 96.9238  s0.loss_bbox: 0.0670  s1.loss_cls: 0.0695  s1.acc: 96.6634  s1.loss_bbox: 0.0624  s2.loss_cls: 0.0342  s2.acc: 97.2536  s2.loss_bbox: 0.0364\n",
      "12/08 04:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 400/1221]  lr: 2.0000e-04  eta: 0:15:05  time: 0.2801  data_time: 0.0087  memory: 2342  grad_norm: 2.5285  loss: 0.4859  loss_rpn_cls: 0.0252  loss_rpn_bbox: 0.0171  s0.loss_cls: 0.1589  s0.acc: 96.9727  s0.loss_bbox: 0.0686  s1.loss_cls: 0.0739  s1.acc: 97.9980  s1.loss_bbox: 0.0654  s2.loss_cls: 0.0367  s2.acc: 97.9492  s2.loss_bbox: 0.0400\n",
      "12/08 04:13:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 450/1221]  lr: 2.0000e-04  eta: 0:14:52  time: 0.2768  data_time: 0.0087  memory: 2343  grad_norm: 2.5399  loss: 0.5356  loss_rpn_cls: 0.0241  loss_rpn_bbox: 0.0205  s0.loss_cls: 0.1743  s0.acc: 93.7500  s0.loss_bbox: 0.0799  s1.loss_cls: 0.0796  s1.acc: 93.8553  s1.loss_bbox: 0.0724  s2.loss_cls: 0.0394  s2.acc: 93.4988  s2.loss_bbox: 0.0455\n",
      "12/08 04:13:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 500/1221]  lr: 2.0000e-04  eta: 0:14:38  time: 0.2748  data_time: 0.0084  memory: 2342  grad_norm: 2.3110  loss: 0.4473  loss_rpn_cls: 0.0209  loss_rpn_bbox: 0.0157  s0.loss_cls: 0.1461  s0.acc: 97.1191  s0.loss_bbox: 0.0646  s1.loss_cls: 0.0700  s1.acc: 96.4355  s1.loss_bbox: 0.0604  s2.loss_cls: 0.0342  s2.acc: 95.7031  s2.loss_bbox: 0.0355\n",
      "12/08 04:13:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 550/1221]  lr: 2.0000e-04  eta: 0:14:24  time: 0.2756  data_time: 0.0085  memory: 2342  grad_norm: 2.5819  loss: 0.5398  loss_rpn_cls: 0.0231  loss_rpn_bbox: 0.0202  s0.loss_cls: 0.1749  s0.acc: 97.4609  s0.loss_bbox: 0.0824  s1.loss_cls: 0.0798  s1.acc: 98.7090  s1.loss_bbox: 0.0740  s2.loss_cls: 0.0398  s2.acc: 98.6981  s2.loss_bbox: 0.0457\n",
      "12/08 04:13:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 600/1221]  lr: 2.0000e-04  eta: 0:14:10  time: 0.2776  data_time: 0.0086  memory: 2343  grad_norm: 2.4839  loss: 0.4883  loss_rpn_cls: 0.0234  loss_rpn_bbox: 0.0206  s0.loss_cls: 0.1580  s0.acc: 96.9238  s0.loss_bbox: 0.0687  s1.loss_cls: 0.0731  s1.acc: 96.8262  s1.loss_bbox: 0.0656  s2.loss_cls: 0.0367  s2.acc: 97.3633  s2.loss_bbox: 0.0423\n",
      "12/08 04:14:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 650/1221]  lr: 2.0000e-04  eta: 0:13:56  time: 0.2755  data_time: 0.0081  memory: 2342  grad_norm: 2.5726  loss: 0.5092  loss_rpn_cls: 0.0259  loss_rpn_bbox: 0.0176  s0.loss_cls: 0.1693  s0.acc: 95.3125  s0.loss_bbox: 0.0759  s1.loss_cls: 0.0761  s1.acc: 97.2826  s1.loss_bbox: 0.0663  s2.loss_cls: 0.0375  s2.acc: 97.8293  s2.loss_bbox: 0.0406\n",
      "12/08 04:14:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 04:14:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 700/1221]  lr: 2.0000e-04  eta: 0:13:42  time: 0.2763  data_time: 0.0086  memory: 2342  grad_norm: 2.3648  loss: 0.4674  loss_rpn_cls: 0.0204  loss_rpn_bbox: 0.0163  s0.loss_cls: 0.1515  s0.acc: 99.1211  s0.loss_bbox: 0.0690  s1.loss_cls: 0.0715  s1.acc: 99.2188  s1.loss_bbox: 0.0647  s2.loss_cls: 0.0354  s2.acc: 99.5605  s2.loss_bbox: 0.0386\n",
      "12/08 04:14:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 750/1221]  lr: 2.0000e-04  eta: 0:13:28  time: 0.2768  data_time: 0.0088  memory: 2343  grad_norm: 2.3213  loss: 0.4017  loss_rpn_cls: 0.0186  loss_rpn_bbox: 0.0137  s0.loss_cls: 0.1325  s0.acc: 93.3105  s0.loss_bbox: 0.0577  s1.loss_cls: 0.0625  s1.acc: 93.4410  s1.loss_bbox: 0.0526  s2.loss_cls: 0.0308  s2.acc: 94.1895  s2.loss_bbox: 0.0334\n",
      "12/08 04:14:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 800/1221]  lr: 2.0000e-04  eta: 0:13:14  time: 0.2738  data_time: 0.0083  memory: 2342  grad_norm: 2.5546  loss: 0.5222  loss_rpn_cls: 0.0298  loss_rpn_bbox: 0.0192  s0.loss_cls: 0.1695  s0.acc: 95.8496  s0.loss_bbox: 0.0745  s1.loss_cls: 0.0770  s1.acc: 96.2451  s1.loss_bbox: 0.0700  s2.loss_cls: 0.0392  s2.acc: 96.8379  s2.loss_bbox: 0.0430\n",
      "12/08 04:15:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 850/1221]  lr: 2.0000e-04  eta: 0:13:00  time: 0.2769  data_time: 0.0081  memory: 2342  grad_norm: 2.3329  loss: 0.4458  loss_rpn_cls: 0.0200  loss_rpn_bbox: 0.0147  s0.loss_cls: 0.1471  s0.acc: 94.7266  s0.loss_bbox: 0.0640  s1.loss_cls: 0.0684  s1.acc: 93.3105  s1.loss_bbox: 0.0611  s2.loss_cls: 0.0335  s2.acc: 93.8477  s2.loss_bbox: 0.0368\n",
      "12/08 04:15:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 900/1221]  lr: 2.0000e-04  eta: 0:12:46  time: 0.2760  data_time: 0.0084  memory: 2342  grad_norm: 2.3856  loss: 0.5134  loss_rpn_cls: 0.0252  loss_rpn_bbox: 0.0213  s0.loss_cls: 0.1630  s0.acc: 98.3887  s0.loss_bbox: 0.0798  s1.loss_cls: 0.0746  s1.acc: 99.0234  s1.loss_bbox: 0.0706  s2.loss_cls: 0.0374  s2.acc: 99.0723  s2.loss_bbox: 0.0418\n",
      "12/08 04:15:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 950/1221]  lr: 2.0000e-04  eta: 0:12:33  time: 0.2724  data_time: 0.0082  memory: 2342  grad_norm: 2.2851  loss: 0.4335  loss_rpn_cls: 0.0218  loss_rpn_bbox: 0.0162  s0.loss_cls: 0.1404  s0.acc: 94.8730  s0.loss_bbox: 0.0657  s1.loss_cls: 0.0621  s1.acc: 96.2069  s1.loss_bbox: 0.0589  s2.loss_cls: 0.0305  s2.acc: 95.9626  s2.loss_bbox: 0.0378\n",
      "12/08 04:15:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1000/1221]  lr: 2.0000e-04  eta: 0:12:19  time: 0.2742  data_time: 0.0084  memory: 2342  grad_norm: 2.2503  loss: 0.4175  loss_rpn_cls: 0.0224  loss_rpn_bbox: 0.0165  s0.loss_cls: 0.1379  s0.acc: 96.6309  s0.loss_bbox: 0.0592  s1.loss_cls: 0.0619  s1.acc: 96.7285  s1.loss_bbox: 0.0542  s2.loss_cls: 0.0313  s2.acc: 96.5820  s2.loss_bbox: 0.0341\n",
      "12/08 04:15:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1050/1221]  lr: 2.0000e-04  eta: 0:12:05  time: 0.2765  data_time: 0.0085  memory: 2342  grad_norm: 2.3964  loss: 0.4711  loss_rpn_cls: 0.0221  loss_rpn_bbox: 0.0198  s0.loss_cls: 0.1508  s0.acc: 96.9727  s0.loss_bbox: 0.0713  s1.loss_cls: 0.0701  s1.acc: 96.5820  s1.loss_bbox: 0.0618  s2.loss_cls: 0.0358  s2.acc: 96.3379  s2.loss_bbox: 0.0394\n",
      "12/08 04:16:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1100/1221]  lr: 2.0000e-04  eta: 0:11:51  time: 0.2758  data_time: 0.0088  memory: 2342  grad_norm: 2.5231  loss: 0.4487  loss_rpn_cls: 0.0248  loss_rpn_bbox: 0.0175  s0.loss_cls: 0.1464  s0.acc: 98.6816  s0.loss_bbox: 0.0623  s1.loss_cls: 0.0687  s1.acc: 97.1680  s1.loss_bbox: 0.0586  s2.loss_cls: 0.0349  s2.acc: 97.4121  s2.loss_bbox: 0.0356\n",
      "12/08 04:16:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1150/1221]  lr: 2.0000e-04  eta: 0:11:37  time: 0.2744  data_time: 0.0086  memory: 2342  grad_norm: 2.5021  loss: 0.5473  loss_rpn_cls: 0.0283  loss_rpn_bbox: 0.0242  s0.loss_cls: 0.1753  s0.acc: 95.2148  s0.loss_bbox: 0.0821  s1.loss_cls: 0.0810  s1.acc: 95.5172  s1.loss_bbox: 0.0728  s2.loss_cls: 0.0397  s2.acc: 95.2918  s2.loss_bbox: 0.0439\n",
      "12/08 04:16:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][1200/1221]  lr: 2.0000e-04  eta: 0:11:23  time: 0.2751  data_time: 0.0086  memory: 2342  grad_norm: 2.4479  loss: 0.4484  loss_rpn_cls: 0.0191  loss_rpn_bbox: 0.0144  s0.loss_cls: 0.1510  s0.acc: 97.1191  s0.loss_bbox: 0.0635  s1.loss_cls: 0.0696  s1.acc: 96.7285  s1.loss_bbox: 0.0601  s2.loss_cls: 0.0346  s2.acc: 96.9727  s2.loss_bbox: 0.0360\n",
      "12/08 04:16:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 04:16:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 16 epochs\n",
      "12/08 04:17:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][  50/1221]  lr: 2.0000e-04  eta: 0:11:03  time: 0.2824  data_time: 0.0117  memory: 2343  grad_norm: 2.3466  loss: 0.4718  loss_rpn_cls: 0.0251  loss_rpn_bbox: 0.0195  s0.loss_cls: 0.1537  s0.acc: 96.2891  s0.loss_bbox: 0.0692  s1.loss_cls: 0.0710  s1.acc: 96.0449  s1.loss_bbox: 0.0616  s2.loss_cls: 0.0348  s2.acc: 95.3613  s2.loss_bbox: 0.0369\n",
      "12/08 04:17:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 100/1221]  lr: 2.0000e-04  eta: 0:10:50  time: 0.2771  data_time: 0.0086  memory: 2342  grad_norm: 2.6316  loss: 0.5227  loss_rpn_cls: 0.0246  loss_rpn_bbox: 0.0198  s0.loss_cls: 0.1725  s0.acc: 98.7305  s0.loss_bbox: 0.0769  s1.loss_cls: 0.0790  s1.acc: 98.8281  s1.loss_bbox: 0.0684  s2.loss_cls: 0.0389  s2.acc: 98.5840  s2.loss_bbox: 0.0425\n",
      "12/08 04:17:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 150/1221]  lr: 2.0000e-04  eta: 0:10:36  time: 0.2770  data_time: 0.0090  memory: 2343  grad_norm: 2.3681  loss: 0.4986  loss_rpn_cls: 0.0224  loss_rpn_bbox: 0.0199  s0.loss_cls: 0.1567  s0.acc: 93.9453  s0.loss_bbox: 0.0756  s1.loss_cls: 0.0717  s1.acc: 93.8386  s1.loss_bbox: 0.0726  s2.loss_cls: 0.0357  s2.acc: 93.6461  s2.loss_bbox: 0.0439\n",
      "12/08 04:17:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 200/1221]  lr: 2.0000e-04  eta: 0:10:22  time: 0.2757  data_time: 0.0090  memory: 2342  grad_norm: 2.3562  loss: 0.4769  loss_rpn_cls: 0.0209  loss_rpn_bbox: 0.0180  s0.loss_cls: 0.1558  s0.acc: 88.5742  s0.loss_bbox: 0.0723  s1.loss_cls: 0.0705  s1.acc: 90.3323  s1.loss_bbox: 0.0641  s2.loss_cls: 0.0348  s2.acc: 90.0955  s2.loss_bbox: 0.0405\n",
      "12/08 04:17:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 250/1221]  lr: 2.0000e-04  eta: 0:10:08  time: 0.2760  data_time: 0.0086  memory: 2342  grad_norm: 2.4607  loss: 0.4730  loss_rpn_cls: 0.0203  loss_rpn_bbox: 0.0150  s0.loss_cls: 0.1536  s0.acc: 94.8242  s0.loss_bbox: 0.0717  s1.loss_cls: 0.0718  s1.acc: 94.4336  s1.loss_bbox: 0.0660  s2.loss_cls: 0.0350  s2.acc: 94.3359  s2.loss_bbox: 0.0397\n",
      "12/08 04:18:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 300/1221]  lr: 2.0000e-04  eta: 0:09:54  time: 0.2767  data_time: 0.0086  memory: 2342  grad_norm: 2.3484  loss: 0.4554  loss_rpn_cls: 0.0204  loss_rpn_bbox: 0.0151  s0.loss_cls: 0.1489  s0.acc: 94.8242  s0.loss_bbox: 0.0669  s1.loss_cls: 0.0686  s1.acc: 95.2639  s1.loss_bbox: 0.0629  s2.loss_cls: 0.0339  s2.acc: 95.6650  s2.loss_bbox: 0.0386\n",
      "12/08 04:18:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 350/1221]  lr: 2.0000e-04  eta: 0:09:40  time: 0.2785  data_time: 0.0087  memory: 2343  grad_norm: 2.3756  loss: 0.4437  loss_rpn_cls: 0.0198  loss_rpn_bbox: 0.0153  s0.loss_cls: 0.1443  s0.acc: 93.3105  s0.loss_bbox: 0.0640  s1.loss_cls: 0.0680  s1.acc: 94.5158  s1.loss_bbox: 0.0607  s2.loss_cls: 0.0337  s2.acc: 93.1784  s2.loss_bbox: 0.0379\n",
      "12/08 04:18:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 400/1221]  lr: 2.0000e-04  eta: 0:09:26  time: 0.2792  data_time: 0.0085  memory: 2342  grad_norm: 2.3157  loss: 0.4690  loss_rpn_cls: 0.0241  loss_rpn_bbox: 0.0201  s0.loss_cls: 0.1547  s0.acc: 95.5078  s0.loss_bbox: 0.0699  s1.loss_cls: 0.0697  s1.acc: 96.8348  s1.loss_bbox: 0.0604  s2.loss_cls: 0.0340  s2.acc: 97.5211  s2.loss_bbox: 0.0362\n",
      "12/08 04:18:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 450/1221]  lr: 2.0000e-04  eta: 0:09:12  time: 0.2777  data_time: 0.0085  memory: 2342  grad_norm: 2.5423  loss: 0.4715  loss_rpn_cls: 0.0218  loss_rpn_bbox: 0.0175  s0.loss_cls: 0.1552  s0.acc: 90.9668  s0.loss_bbox: 0.0679  s1.loss_cls: 0.0709  s1.acc: 91.4356  s1.loss_bbox: 0.0633  s2.loss_cls: 0.0360  s2.acc: 90.4150  s2.loss_bbox: 0.0389\n",
      "12/08 04:18:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 04:19:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 500/1221]  lr: 2.0000e-04  eta: 0:08:58  time: 0.2774  data_time: 0.0087  memory: 2342  grad_norm: 2.4871  loss: 0.5010  loss_rpn_cls: 0.0235  loss_rpn_bbox: 0.0194  s0.loss_cls: 0.1615  s0.acc: 98.4375  s0.loss_bbox: 0.0759  s1.loss_cls: 0.0735  s1.acc: 99.3164  s1.loss_bbox: 0.0688  s2.loss_cls: 0.0364  s2.acc: 99.7070  s2.loss_bbox: 0.0422\n",
      "12/08 04:19:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 550/1221]  lr: 2.0000e-04  eta: 0:08:45  time: 0.2745  data_time: 0.0085  memory: 2342  grad_norm: 2.4571  loss: 0.4648  loss_rpn_cls: 0.0218  loss_rpn_bbox: 0.0154  s0.loss_cls: 0.1515  s0.acc: 96.6797  s0.loss_bbox: 0.0699  s1.loss_cls: 0.0697  s1.acc: 97.8516  s1.loss_bbox: 0.0634  s2.loss_cls: 0.0348  s2.acc: 97.2168  s2.loss_bbox: 0.0383\n",
      "12/08 04:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 600/1221]  lr: 2.0000e-04  eta: 0:08:31  time: 0.2775  data_time: 0.0086  memory: 2342  grad_norm: 2.3906  loss: 0.4792  loss_rpn_cls: 0.0203  loss_rpn_bbox: 0.0177  s0.loss_cls: 0.1536  s0.acc: 96.7773  s0.loss_bbox: 0.0746  s1.loss_cls: 0.0714  s1.acc: 96.4339  s1.loss_bbox: 0.0662  s2.loss_cls: 0.0360  s2.acc: 96.3915  s2.loss_bbox: 0.0395\n",
      "12/08 04:19:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 650/1221]  lr: 2.0000e-04  eta: 0:08:17  time: 0.2740  data_time: 0.0085  memory: 2342  grad_norm: 2.5524  loss: 0.4942  loss_rpn_cls: 0.0231  loss_rpn_bbox: 0.0159  s0.loss_cls: 0.1650  s0.acc: 91.3086  s0.loss_bbox: 0.0704  s1.loss_cls: 0.0762  s1.acc: 91.4300  s1.loss_bbox: 0.0653  s2.loss_cls: 0.0375  s2.acc: 90.4028  s2.loss_bbox: 0.0406\n",
      "12/08 04:20:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 700/1221]  lr: 2.0000e-04  eta: 0:08:03  time: 0.2752  data_time: 0.0084  memory: 2342  grad_norm: 2.2513  loss: 0.3867  loss_rpn_cls: 0.0183  loss_rpn_bbox: 0.0138  s0.loss_cls: 0.1296  s0.acc: 95.3125  s0.loss_bbox: 0.0566  s1.loss_cls: 0.0583  s1.acc: 95.2148  s1.loss_bbox: 0.0499  s2.loss_cls: 0.0284  s2.acc: 95.1660  s2.loss_bbox: 0.0319\n",
      "12/08 04:20:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 750/1221]  lr: 2.0000e-04  eta: 0:07:49  time: 0.2752  data_time: 0.0083  memory: 2342  grad_norm: 2.3665  loss: 0.4623  loss_rpn_cls: 0.0196  loss_rpn_bbox: 0.0172  s0.loss_cls: 0.1496  s0.acc: 99.2188  s0.loss_bbox: 0.0692  s1.loss_cls: 0.0682  s1.acc: 99.2188  s1.loss_bbox: 0.0646  s2.loss_cls: 0.0340  s2.acc: 99.6094  s2.loss_bbox: 0.0400\n",
      "12/08 04:20:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 800/1221]  lr: 2.0000e-04  eta: 0:07:35  time: 0.2749  data_time: 0.0086  memory: 2342  grad_norm: 2.3474  loss: 0.4114  loss_rpn_cls: 0.0158  loss_rpn_bbox: 0.0166  s0.loss_cls: 0.1366  s0.acc: 97.9004  s0.loss_bbox: 0.0582  s1.loss_cls: 0.0634  s1.acc: 98.8770  s1.loss_bbox: 0.0552  s2.loss_cls: 0.0314  s2.acc: 98.7793  s2.loss_bbox: 0.0341\n",
      "12/08 04:20:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 850/1221]  lr: 2.0000e-04  eta: 0:07:21  time: 0.2746  data_time: 0.0085  memory: 2342  grad_norm: 2.4908  loss: 0.3939  loss_rpn_cls: 0.0148  loss_rpn_bbox: 0.0145  s0.loss_cls: 0.1307  s0.acc: 96.9727  s0.loss_bbox: 0.0556  s1.loss_cls: 0.0620  s1.acc: 97.7455  s1.loss_bbox: 0.0515  s2.loss_cls: 0.0319  s2.acc: 98.0343  s2.loss_bbox: 0.0329\n",
      "12/08 04:20:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 900/1221]  lr: 2.0000e-04  eta: 0:07:07  time: 0.2787  data_time: 0.0088  memory: 2342  grad_norm: 2.2627  loss: 0.4070  loss_rpn_cls: 0.0174  loss_rpn_bbox: 0.0159  s0.loss_cls: 0.1345  s0.acc: 96.0938  s0.loss_bbox: 0.0585  s1.loss_cls: 0.0613  s1.acc: 96.6797  s1.loss_bbox: 0.0546  s2.loss_cls: 0.0306  s2.acc: 96.0938  s2.loss_bbox: 0.0343\n",
      "12/08 04:21:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 950/1221]  lr: 2.0000e-04  eta: 0:06:54  time: 0.2762  data_time: 0.0086  memory: 2342  grad_norm: 2.4530  loss: 0.4696  loss_rpn_cls: 0.0214  loss_rpn_bbox: 0.0168  s0.loss_cls: 0.1526  s0.acc: 96.3867  s0.loss_bbox: 0.0699  s1.loss_cls: 0.0697  s1.acc: 97.8734  s1.loss_bbox: 0.0653  s2.loss_cls: 0.0342  s2.acc: 98.5171  s2.loss_bbox: 0.0396\n",
      "12/08 04:21:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1000/1221]  lr: 2.0000e-04  eta: 0:06:40  time: 0.2780  data_time: 0.0089  memory: 2342  grad_norm: 2.4337  loss: 0.5027  loss_rpn_cls: 0.0267  loss_rpn_bbox: 0.0205  s0.loss_cls: 0.1548  s0.acc: 95.9473  s0.loss_bbox: 0.0772  s1.loss_cls: 0.0731  s1.acc: 95.9898  s1.loss_bbox: 0.0723  s2.loss_cls: 0.0363  s2.acc: 95.8227  s2.loss_bbox: 0.0418\n",
      "12/08 04:21:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1050/1221]  lr: 2.0000e-04  eta: 0:06:26  time: 0.2762  data_time: 0.0087  memory: 2342  grad_norm: 2.2134  loss: 0.4032  loss_rpn_cls: 0.0168  loss_rpn_bbox: 0.0173  s0.loss_cls: 0.1306  s0.acc: 94.9707  s0.loss_bbox: 0.0615  s1.loss_cls: 0.0583  s1.acc: 95.0025  s1.loss_bbox: 0.0558  s2.loss_cls: 0.0284  s2.acc: 95.4110  s2.loss_bbox: 0.0345\n",
      "12/08 04:21:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1100/1221]  lr: 2.0000e-04  eta: 0:06:12  time: 0.2737  data_time: 0.0083  memory: 2343  grad_norm: 2.2564  loss: 0.4172  loss_rpn_cls: 0.0185  loss_rpn_bbox: 0.0163  s0.loss_cls: 0.1371  s0.acc: 96.8750  s0.loss_bbox: 0.0608  s1.loss_cls: 0.0629  s1.acc: 95.7520  s1.loss_bbox: 0.0561  s2.loss_cls: 0.0313  s2.acc: 96.4355  s2.loss_bbox: 0.0341\n",
      "12/08 04:22:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1150/1221]  lr: 2.0000e-04  eta: 0:05:58  time: 0.2743  data_time: 0.0082  memory: 2342  grad_norm: 2.4907  loss: 0.4961  loss_rpn_cls: 0.0242  loss_rpn_bbox: 0.0187  s0.loss_cls: 0.1589  s0.acc: 97.8027  s0.loss_bbox: 0.0738  s1.loss_cls: 0.0739  s1.acc: 96.4355  s1.loss_bbox: 0.0687  s2.loss_cls: 0.0365  s2.acc: 95.8008  s2.loss_bbox: 0.0415\n",
      "12/08 04:22:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][1200/1221]  lr: 2.0000e-04  eta: 0:05:44  time: 0.2735  data_time: 0.0084  memory: 2343  grad_norm: 2.3721  loss: 0.4188  loss_rpn_cls: 0.0201  loss_rpn_bbox: 0.0156  s0.loss_cls: 0.1365  s0.acc: 92.4316  s0.loss_bbox: 0.0599  s1.loss_cls: 0.0640  s1.acc: 92.8047  s1.loss_bbox: 0.0561  s2.loss_cls: 0.0318  s2.acc: 91.7728  s2.loss_bbox: 0.0347\n",
      "12/08 04:22:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 04:22:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 17 epochs\n",
      "12/08 04:22:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][  50/1221]  lr: 2.0000e-04  eta: 0:05:24  time: 0.2798  data_time: 0.0128  memory: 2342  grad_norm: 2.4453  loss: 0.4532  loss_rpn_cls: 0.0205  loss_rpn_bbox: 0.0164  s0.loss_cls: 0.1467  s0.acc: 94.2383  s0.loss_bbox: 0.0665  s1.loss_cls: 0.0680  s1.acc: 94.1724  s1.loss_bbox: 0.0627  s2.loss_cls: 0.0340  s2.acc: 95.2544  s2.loss_bbox: 0.0383\n",
      "12/08 04:22:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 100/1221]  lr: 2.0000e-04  eta: 0:05:11  time: 0.2729  data_time: 0.0083  memory: 2342  grad_norm: 2.2659  loss: 0.4179  loss_rpn_cls: 0.0201  loss_rpn_bbox: 0.0151  s0.loss_cls: 0.1383  s0.acc: 96.5820  s0.loss_bbox: 0.0603  s1.loss_cls: 0.0627  s1.acc: 98.0493  s1.loss_bbox: 0.0557  s2.loss_cls: 0.0310  s2.acc: 96.9398  s2.loss_bbox: 0.0345\n",
      "12/08 04:23:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 150/1221]  lr: 2.0000e-04  eta: 0:04:57  time: 0.2765  data_time: 0.0090  memory: 2343  grad_norm: 2.4479  loss: 0.4694  loss_rpn_cls: 0.0216  loss_rpn_bbox: 0.0166  s0.loss_cls: 0.1523  s0.acc: 89.9902  s0.loss_bbox: 0.0704  s1.loss_cls: 0.0697  s1.acc: 90.9677  s1.loss_bbox: 0.0651  s2.loss_cls: 0.0345  s2.acc: 92.1618  s2.loss_bbox: 0.0392\n",
      "12/08 04:23:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 200/1221]  lr: 2.0000e-04  eta: 0:04:43  time: 0.2732  data_time: 0.0081  memory: 2343  grad_norm: 2.2766  loss: 0.4170  loss_rpn_cls: 0.0212  loss_rpn_bbox: 0.0138  s0.loss_cls: 0.1332  s0.acc: 97.3145  s0.loss_bbox: 0.0622  s1.loss_cls: 0.0624  s1.acc: 97.1093  s1.loss_bbox: 0.0584  s2.loss_cls: 0.0306  s2.acc: 95.9354  s2.loss_bbox: 0.0353\n",
      "12/08 04:23:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 04:23:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 250/1221]  lr: 2.0000e-04  eta: 0:04:29  time: 0.2763  data_time: 0.0086  memory: 2342  grad_norm: 2.3700  loss: 0.4334  loss_rpn_cls: 0.0178  loss_rpn_bbox: 0.0154  s0.loss_cls: 0.1423  s0.acc: 90.9180  s0.loss_bbox: 0.0646  s1.loss_cls: 0.0645  s1.acc: 90.7211  s1.loss_bbox: 0.0597  s2.loss_cls: 0.0322  s2.acc: 91.1572  s2.loss_bbox: 0.0370\n",
      "12/08 04:23:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 300/1221]  lr: 2.0000e-04  eta: 0:04:15  time: 0.2758  data_time: 0.0088  memory: 2343  grad_norm: 2.4719  loss: 0.4862  loss_rpn_cls: 0.0268  loss_rpn_bbox: 0.0192  s0.loss_cls: 0.1570  s0.acc: 94.5801  s0.loss_bbox: 0.0733  s1.loss_cls: 0.0720  s1.acc: 94.8768  s1.loss_bbox: 0.0638  s2.loss_cls: 0.0351  s2.acc: 94.1523  s2.loss_bbox: 0.0389\n",
      "12/08 04:24:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 350/1221]  lr: 2.0000e-04  eta: 0:04:01  time: 0.2745  data_time: 0.0086  memory: 2342  grad_norm: 2.3044  loss: 0.4062  loss_rpn_cls: 0.0190  loss_rpn_bbox: 0.0157  s0.loss_cls: 0.1354  s0.acc: 97.7539  s0.loss_bbox: 0.0591  s1.loss_cls: 0.0601  s1.acc: 97.5586  s1.loss_bbox: 0.0527  s2.loss_cls: 0.0302  s2.acc: 96.9238  s2.loss_bbox: 0.0340\n",
      "12/08 04:24:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 400/1221]  lr: 2.0000e-04  eta: 0:03:47  time: 0.2752  data_time: 0.0084  memory: 2342  grad_norm: 2.4566  loss: 0.4976  loss_rpn_cls: 0.0253  loss_rpn_bbox: 0.0201  s0.loss_cls: 0.1616  s0.acc: 96.3379  s0.loss_bbox: 0.0734  s1.loss_cls: 0.0736  s1.acc: 95.9506  s1.loss_bbox: 0.0668  s2.loss_cls: 0.0361  s2.acc: 96.5243  s2.loss_bbox: 0.0407\n",
      "12/08 04:24:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 450/1221]  lr: 2.0000e-04  eta: 0:03:33  time: 0.2766  data_time: 0.0084  memory: 2343  grad_norm: 2.4134  loss: 0.4914  loss_rpn_cls: 0.0246  loss_rpn_bbox: 0.0178  s0.loss_cls: 0.1591  s0.acc: 92.4805  s0.loss_bbox: 0.0766  s1.loss_cls: 0.0713  s1.acc: 93.2053  s1.loss_bbox: 0.0682  s2.loss_cls: 0.0357  s2.acc: 92.7201  s2.loss_bbox: 0.0379\n",
      "12/08 04:24:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 500/1221]  lr: 2.0000e-04  eta: 0:03:20  time: 0.2756  data_time: 0.0088  memory: 2342  grad_norm: 2.2218  loss: 0.4107  loss_rpn_cls: 0.0196  loss_rpn_bbox: 0.0186  s0.loss_cls: 0.1373  s0.acc: 97.2168  s0.loss_bbox: 0.0570  s1.loss_cls: 0.0626  s1.acc: 97.5098  s1.loss_bbox: 0.0522  s2.loss_cls: 0.0310  s2.acc: 97.6562  s2.loss_bbox: 0.0323\n",
      "12/08 04:24:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 550/1221]  lr: 2.0000e-04  eta: 0:03:06  time: 0.2758  data_time: 0.0087  memory: 2342  grad_norm: 2.3555  loss: 0.4305  loss_rpn_cls: 0.0187  loss_rpn_bbox: 0.0156  s0.loss_cls: 0.1358  s0.acc: 96.4844  s0.loss_bbox: 0.0667  s1.loss_cls: 0.0611  s1.acc: 96.5312  s1.loss_bbox: 0.0628  s2.loss_cls: 0.0308  s2.acc: 96.7082  s2.loss_bbox: 0.0391\n",
      "12/08 04:25:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 600/1221]  lr: 2.0000e-04  eta: 0:02:52  time: 0.2793  data_time: 0.0087  memory: 2342  grad_norm: 2.6381  loss: 0.5189  loss_rpn_cls: 0.0237  loss_rpn_bbox: 0.0164  s0.loss_cls: 0.1663  s0.acc: 98.4863  s0.loss_bbox: 0.0792  s1.loss_cls: 0.0771  s1.acc: 98.7305  s1.loss_bbox: 0.0733  s2.loss_cls: 0.0385  s2.acc: 97.9492  s2.loss_bbox: 0.0443\n",
      "12/08 04:25:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 650/1221]  lr: 2.0000e-04  eta: 0:02:38  time: 0.2762  data_time: 0.0089  memory: 2342  grad_norm: 2.4087  loss: 0.4374  loss_rpn_cls: 0.0166  loss_rpn_bbox: 0.0163  s0.loss_cls: 0.1411  s0.acc: 90.3809  s0.loss_bbox: 0.0645  s1.loss_cls: 0.0666  s1.acc: 90.0000  s1.loss_bbox: 0.0618  s2.loss_cls: 0.0330  s2.acc: 89.8111  s2.loss_bbox: 0.0378\n",
      "12/08 04:25:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 700/1221]  lr: 2.0000e-04  eta: 0:02:24  time: 0.2753  data_time: 0.0086  memory: 2342  grad_norm: 2.4091  loss: 0.4432  loss_rpn_cls: 0.0204  loss_rpn_bbox: 0.0157  s0.loss_cls: 0.1414  s0.acc: 91.5039  s0.loss_bbox: 0.0664  s1.loss_cls: 0.0656  s1.acc: 90.8779  s1.loss_bbox: 0.0622  s2.loss_cls: 0.0322  s2.acc: 89.7109  s2.loss_bbox: 0.0392\n",
      "12/08 04:25:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 750/1221]  lr: 2.0000e-04  eta: 0:02:10  time: 0.2753  data_time: 0.0087  memory: 2342  grad_norm: 2.3878  loss: 0.4546  loss_rpn_cls: 0.0238  loss_rpn_bbox: 0.0202  s0.loss_cls: 0.1486  s0.acc: 96.5820  s0.loss_bbox: 0.0663  s1.loss_cls: 0.0680  s1.acc: 98.7757  s1.loss_bbox: 0.0588  s2.loss_cls: 0.0335  s2.acc: 99.3134  s2.loss_bbox: 0.0354\n",
      "12/08 04:26:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 800/1221]  lr: 2.0000e-04  eta: 0:01:56  time: 0.2730  data_time: 0.0083  memory: 2342  grad_norm: 2.3392  loss: 0.4024  loss_rpn_cls: 0.0176  loss_rpn_bbox: 0.0122  s0.loss_cls: 0.1325  s0.acc: 94.3848  s0.loss_bbox: 0.0580  s1.loss_cls: 0.0598  s1.acc: 93.9514  s1.loss_bbox: 0.0563  s2.loss_cls: 0.0305  s2.acc: 93.8583  s2.loss_bbox: 0.0353\n",
      "12/08 04:26:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 850/1221]  lr: 2.0000e-04  eta: 0:01:42  time: 0.2755  data_time: 0.0084  memory: 2342  grad_norm: 2.3675  loss: 0.4364  loss_rpn_cls: 0.0176  loss_rpn_bbox: 0.0170  s0.loss_cls: 0.1381  s0.acc: 98.6816  s0.loss_bbox: 0.0680  s1.loss_cls: 0.0649  s1.acc: 98.0957  s1.loss_bbox: 0.0607  s2.loss_cls: 0.0334  s2.acc: 98.2910  s2.loss_bbox: 0.0366\n",
      "12/08 04:26:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 900/1221]  lr: 2.0000e-04  eta: 0:01:29  time: 0.2763  data_time: 0.0086  memory: 2342  grad_norm: 2.3945  loss: 0.4599  loss_rpn_cls: 0.0184  loss_rpn_bbox: 0.0169  s0.loss_cls: 0.1490  s0.acc: 96.3867  s0.loss_bbox: 0.0704  s1.loss_cls: 0.0684  s1.acc: 96.1914  s1.loss_bbox: 0.0633  s2.loss_cls: 0.0336  s2.acc: 96.0449  s2.loss_bbox: 0.0397\n",
      "12/08 04:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 950/1221]  lr: 2.0000e-04  eta: 0:01:15  time: 0.2741  data_time: 0.0085  memory: 2342  grad_norm: 2.5989  loss: 0.5229  loss_rpn_cls: 0.0246  loss_rpn_bbox: 0.0224  s0.loss_cls: 0.1676  s0.acc: 94.0430  s0.loss_bbox: 0.0770  s1.loss_cls: 0.0771  s1.acc: 93.8284  s1.loss_bbox: 0.0713  s2.loss_cls: 0.0388  s2.acc: 92.5982  s2.loss_bbox: 0.0441\n",
      "12/08 04:27:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1000/1221]  lr: 2.0000e-04  eta: 0:01:01  time: 0.2779  data_time: 0.0088  memory: 2343  grad_norm: 2.5272  loss: 0.4808  loss_rpn_cls: 0.0211  loss_rpn_bbox: 0.0188  s0.loss_cls: 0.1562  s0.acc: 94.7754  s0.loss_bbox: 0.0739  s1.loss_cls: 0.0722  s1.acc: 95.1741  s1.loss_bbox: 0.0640  s2.loss_cls: 0.0356  s2.acc: 95.6630  s2.loss_bbox: 0.0388\n",
      "12/08 04:27:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1050/1221]  lr: 2.0000e-04  eta: 0:00:47  time: 0.2761  data_time: 0.0087  memory: 2342  grad_norm: 2.4581  loss: 0.4839  loss_rpn_cls: 0.0216  loss_rpn_bbox: 0.0183  s0.loss_cls: 0.1582  s0.acc: 91.6016  s0.loss_bbox: 0.0716  s1.loss_cls: 0.0743  s1.acc: 91.7647  s1.loss_bbox: 0.0646  s2.loss_cls: 0.0369  s2.acc: 92.2584  s2.loss_bbox: 0.0384\n",
      "12/08 04:27:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1100/1221]  lr: 2.0000e-04  eta: 0:00:33  time: 0.2754  data_time: 0.0088  memory: 2343  grad_norm: 2.6339  loss: 0.4943  loss_rpn_cls: 0.0216  loss_rpn_bbox: 0.0194  s0.loss_cls: 0.1622  s0.acc: 93.5547  s0.loss_bbox: 0.0715  s1.loss_cls: 0.0735  s1.acc: 94.2383  s1.loss_bbox: 0.0660  s2.loss_cls: 0.0381  s2.acc: 93.6523  s2.loss_bbox: 0.0421\n",
      "12/08 04:27:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1150/1221]  lr: 2.0000e-04  eta: 0:00:19  time: 0.2755  data_time: 0.0085  memory: 2342  grad_norm: 2.4459  loss: 0.4312  loss_rpn_cls: 0.0187  loss_rpn_bbox: 0.0142  s0.loss_cls: 0.1437  s0.acc: 97.3145  s0.loss_bbox: 0.0608  s1.loss_cls: 0.0652  s1.acc: 98.0469  s1.loss_bbox: 0.0586  s2.loss_cls: 0.0325  s2.acc: 97.5586  s2.loss_bbox: 0.0374\n",
      "12/08 04:27:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][1200/1221]  lr: 2.0000e-04  eta: 0:00:05  time: 0.2760  data_time: 0.0087  memory: 2342  grad_norm: 2.3649  loss: 0.4203  loss_rpn_cls: 0.0185  loss_rpn_bbox: 0.0144  s0.loss_cls: 0.1355  s0.acc: 94.1895  s0.loss_bbox: 0.0634  s1.loss_cls: 0.0625  s1.acc: 94.0826  s1.loss_bbox: 0.0593  s2.loss_cls: 0.0309  s2.acc: 94.3865  s2.loss_bbox: 0.0358\n",
      "12/08 04:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: cascade-rcnn_r50_fpn_1x_coco_20251208_024525\n",
      "12/08 04:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 18 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>data_time</td><td>▁▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂█▂▂▂▂▂▂▂▁▂▂▂▂█▁█▂▁▂▂▂▂▂▂</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇████</td></tr><tr><td>grad_norm</td><td>▃▃▂▅▄▃▄▂▂▅▂▃▄▅▅▅▅▃█▁▃▃▄▆▄▄▃▄▅▆▄▇█▅▆▅▅▇▅▅</td></tr><tr><td>iter</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>loss</td><td>▆█▇▆▆▅▆▅▅▅▅▅▅▅▆▄▅▅▅▄▄▅▃▃▃▂▂▂▂▂▂▂▁▁▂▂▂▂▁▂</td></tr><tr><td>loss_rpn_bbox</td><td>▇█▆▇▆▇▆▅▇▄▅▅▅▆▆▆▄▇▄▃▂▂▁▃▂▃▃▂▃▂▂▃▁▂▂▂▂▁▃▃</td></tr><tr><td>loss_rpn_cls</td><td>█▇▇▆▅▄▄▄▃▃▂▃▄▃▃▃▂▂▂▂▂▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>████████████████▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>memory</td><td>█▁▁█▁▁▁█▁▁▁▁▁▁▁▁▁█▁█▁▁█▁█▁▁█▁▁█▁▁▁█▁▁▁▁█</td></tr><tr><td>s0.acc</td><td>▇▇▃▂▅▃▃▄▇▁▆▇▆▆▅▇▄▅▅▆█▅▇▇▆▆▅▄▅▆▇▆▇█▇█▇▇▇▅</td></tr><tr><td>+9</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>data_time</td><td>0.0087</td></tr><tr><td>epoch</td><td>18</td></tr><tr><td>grad_norm</td><td>2.36488</td></tr><tr><td>iter</td><td>21957</td></tr><tr><td>loss</td><td>0.42028</td></tr><tr><td>loss_rpn_bbox</td><td>0.01441</td></tr><tr><td>loss_rpn_cls</td><td>0.01848</td></tr><tr><td>lr</td><td>0.0002</td></tr><tr><td>memory</td><td>2342</td></tr><tr><td>s0.acc</td><td>94.18945</td></tr><tr><td>+9</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cascade_rcnn_test</strong> at: <a href='https://wandb.ai/cv_11/cv_11_OD/runs/9fl39hxj' target=\"_blank\">https://wandb.ai/cv_11/cv_11_OD/runs/9fl39hxj</a><br> View project at: <a href='https://wandb.ai/cv_11/cv_11_OD' target=\"_blank\">https://wandb.ai/cv_11/cv_11_OD</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./work_dirs/cascade_rcnn_r50_fpn_1x_trash/20251208_024525/vis_data/wandb/run-20251208_024538-9fl39hxj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CascadeRCNN(\n",
       "  (data_preprocessor): DetDataPreprocessor()\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
       "  (neck): FPN(\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0-3): 4 x ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
       "  (rpn_head): RPNHead(\n",
       "    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (loss_bbox): SmoothL1Loss()\n",
       "    (rpn_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (rpn_cls): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (rpn_reg): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
       "  (roi_head): CascadeRoIHead(\n",
       "    (bbox_roi_extractor): ModuleList(\n",
       "      (0-2): 3 x SingleRoIExtractor(\n",
       "        (roi_layers): ModuleList(\n",
       "          (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "          (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "          (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "          (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bbox_head): ModuleList(\n",
       "      (0-2): 3 x Shared2FCBBoxHead(\n",
       "        (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
       "        (loss_bbox): SmoothL1Loss()\n",
       "        (fc_cls): Linear(in_features=1024, out_features=11, bias=True)\n",
       "        (fc_reg): Linear(in_features=1024, out_features=4, bias=True)\n",
       "        (shared_convs): ModuleList()\n",
       "        (shared_fcs): ModuleList(\n",
       "          (0): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "          (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cls_convs): ModuleList()\n",
       "        (cls_fcs): ModuleList()\n",
       "        (reg_convs): ModuleList()\n",
       "        (reg_fcs): ModuleList()\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "runner = Runner.from_cfg(cfg)\n",
    "runner.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
