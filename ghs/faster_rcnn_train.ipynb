{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: kkhs4988\n",
      "Teams: ['kkhs4988', 'cv_11']\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "me = api.viewer\n",
    "\n",
    "print(\"Username:\", me.username)\n",
    "print(\"Teams:\", me.teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 import\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "\n",
    "from mmengine.config import Config\n",
    "from mmengine.runner import Runner\n",
    "from mmdet.registry import DATASETS\n",
    "from mmdet.utils import register_all_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom 설정\n",
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\",\n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "root = \"../../dataset/\"\n",
    "train_ann = \"train_filtered.json\"\n",
    "test_ann  = \"test.json\"\n",
    "\n",
    "# config file 들고오기\n",
    "cfg = Config.fromfile(\"configs/faster_rcnn/faster-rcnn_r50_fpn_1x_coco.py\")\n",
    "register_all_modules(init_default_scope=True)\n",
    "cfg.default_scope = \"mmdet\"\n",
    "\n",
    "# dataset config 수정\n",
    "for ds_key in [\"train_dataloader\", \"test_dataloader\"]:\n",
    "    if ds_key not in cfg:\n",
    "        continue\n",
    "    ds = cfg[ds_key][\"dataset\"] if \"dataset\" in cfg[ds_key] else cfg[ds_key]\n",
    "    ds.metainfo = dict(classes=classes)\n",
    "    ds.data_root = root\n",
    "    ds.ann_file = train_ann if ds_key == \"train_dataloader\" else test_ann\n",
    "    ds.data_prefix = dict(img=\"\")\n",
    "\n",
    "cfg.train_dataloader.batch_size = 4\n",
    "cfg.train_dataloader.num_workers = max(2, cfg.train_dataloader.get(\"num_workers\", 2))\n",
    "\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(\n",
    "        type='PhotoMetricDistortion',\n",
    "        brightness_delta=20,\n",
    "        contrast_range=(0.8, 1.2),\n",
    "        saturation_range=(0.8, 1.2),\n",
    "        hue_delta=10\n",
    "    ),\n",
    "    dict(type='Resize', scale=(512, 512), keep_ratio=False),\n",
    "    dict(type='PackDetInputs')\n",
    "]\n",
    "\n",
    "cfg.train_dataloader.dataset.pipeline = train_pipeline\n",
    "\n",
    "\n",
    "cfg.test_dataloader.batch_size = 1\n",
    "cfg.test_dataloader.num_workers = max(2, cfg.test_dataloader.get(\"num_workers\", 2))\n",
    "cfg.test_dataloader.dataset.pipeline[1][\"scale\"] = (512, 512)\n",
    "\n",
    "# validate 비활성화\n",
    "for k in (\"val_dataloader\", \"val_evaluator\", \"val_cfg\", \"val_loop\"):\n",
    "    cfg.pop(k, None)\n",
    "cfg.train_cfg = cfg.get(\"train_cfg\", {})\n",
    "cfg.train_cfg[\"val_interval\"] = 0\n",
    "\n",
    "# 학습 config 수정\n",
    "cfg.device = \"cuda\"\n",
    "cfg.gpu_ids = [0]\n",
    "cfg.randomness = dict(seed=2025, deterministic=False)\n",
    "cfg.work_dir = \"./work_dirs/faster_rcnn_r50_fpn_1x_trash\"\n",
    "\n",
    "cfg.model.roi_head.bbox_head.num_classes = len(classes)\n",
    "cfg.optim_wrapper = {**cfg.get(\"optim_wrapper\", {}), \"clip_grad\": dict(max_norm=35, norm_type=2)}\n",
    "\n",
    "cfg.train_cfg.max_epochs = 12\n",
    "cfg.default_hooks[\"checkpoint\"][\"max_keep_ckpts\"] = 3\n",
    "cfg.default_hooks[\"checkpoint\"][\"interval\"] = 1\n",
    "\n",
    "\n",
    "vis_backends = [\n",
    "    dict(type='LocalVisBackend'),\n",
    "        dict(\n",
    "        type='WandbVisBackend',\n",
    "        init_kwargs=dict(\n",
    "            project='cv_11_OD',     # 너가 보고 싶은 프로젝트\n",
    "            entity='cv_11',      # 팀 이름\n",
    "            name='faster_rcnn_test'\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "cfg.visualizer = dict(\n",
    "    type='DetLocalVisualizer',\n",
    "    vis_backends=vis_backends,\n",
    "    name='visualizer'\n",
    ")\n",
    "\n",
    "cfg.log_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      " [Info] CocoDataset Train dataset with number of images 4537, and instance counts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 [General trash]</td>\n",
       "      <td>2955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 [Paper]</td>\n",
       "      <td>3605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 [Paper pack]</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 [Metal]</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 [Glass]</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5 [Plastic]</td>\n",
       "      <td>1829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6 [Styrofoam]</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7 [Plastic bag]</td>\n",
       "      <td>3557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8 [Battery]</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9 [Clothing]</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            category  count\n",
       "0  0 [General trash]   2955\n",
       "1          1 [Paper]   3605\n",
       "2     2 [Paper pack]    641\n",
       "3          3 [Metal]    709\n",
       "4          4 [Glass]    575\n",
       "5        5 [Plastic]   1829\n",
       "6      6 [Styrofoam]    722\n",
       "7    7 [Plastic bag]   3557\n",
       "8        8 [Battery]    139\n",
       "9       9 [Clothing]    381"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset summarization 확인\n",
    "train_ds_cfg = cfg.train_dataloader.dataset\n",
    "train_ds = DATASETS.build(train_ds_cfg)\n",
    "\n",
    "def summarize_dataset(ds):\n",
    "    ds.full_init()\n",
    "    num_images = len(ds)\n",
    "    classes = list(ds.metainfo.get(\"classes\", []))\n",
    "\n",
    "    counts = Counter()\n",
    "    for i in range(num_images):\n",
    "        info = ds.get_data_info(i)\n",
    "        for inst in info.get(\"instances\", []):\n",
    "            lbl = inst.get(\"bbox_label\", None)\n",
    "            if lbl is not None:\n",
    "                counts[lbl] += 1\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"category\": [f\"{i} [{c}]\" for i, c in enumerate(classes)],\n",
    "        \"count\": [counts.get(i, 0) for i in range(len(classes))]\n",
    "    })\n",
    "\n",
    "    print(f\"\\n [Info] CocoDataset Train dataset with number of images {num_images}, and instance counts:\")\n",
    "    display(df)\n",
    "\n",
    "summarize_dataset(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/07 21:30:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 2025\n",
      "    GPU 0: Tesla V100-SXM2-32GB\n",
      "    CUDA_HOME: None\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 2.1.0+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.0+cu118\n",
      "    OpenCV: 4.7.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 2025\n",
      "    deterministic: False\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "12/07 21:30:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backend_args = None\n",
      "data_root = 'data/coco/'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, max_keep_ckpts=3, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "device = 'cuda'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "gpu_ids = [\n",
      "    0,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=50,\n",
      "        frozen_stages=1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=10,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.05),\n",
      "        rpn=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=1000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=False,\n",
      "                min_pos_iou=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=35, norm_type=2),\n",
      "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=12,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            8,\n",
      "            11,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "randomness = dict(deterministic=False, seed=2025)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='test.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='../../dataset/',\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='data/coco/annotations/instances_val2017.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=12, type='EpochBasedTrainLoop', val_interval=0)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        ann_file='train_filtered.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img=''),\n",
      "        data_root='../../dataset/',\n",
      "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'General trash',\n",
      "                'Paper',\n",
      "                'Paper pack',\n",
      "                'Metal',\n",
      "                'Glass',\n",
      "                'Plastic',\n",
      "                'Styrofoam',\n",
      "                'Plastic bag',\n",
      "                'Battery',\n",
      "                'Clothing',\n",
      "            )),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                brightness_delta=20,\n",
      "                contrast_range=(\n",
      "                    0.8,\n",
      "                    1.2,\n",
      "                ),\n",
      "                hue_delta=10,\n",
      "                saturation_range=(\n",
      "                    0.8,\n",
      "                    1.2,\n",
      "                ),\n",
      "                type='PhotoMetricDistortion'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='CocoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "        dict(\n",
      "            init_kwargs=dict(\n",
      "                entity='cv_11', name='faster_rcnn_test', project='cv_11_OD'),\n",
      "            type='WandbVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/faster_rcnn_r50_fpn_1x_trash'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/kkhs/mmdetection/work_dirs/faster_rcnn_r50_fpn_1x_trash/20251207_213034/vis_data/wandb/run-20251207_213045-n4mecrsl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cv_11/cv_11_OD/runs/n4mecrsl' target=\"_blank\">faster_rcnn_test</a></strong> to <a href='https://wandb.ai/cv_11/cv_11_OD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cv_11/cv_11_OD' target=\"_blank\">https://wandb.ai/cv_11/cv_11_OD</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cv_11/cv_11_OD/runs/n4mecrsl' target=\"_blank\">https://wandb.ai/cv_11/cv_11_OD/runs/n4mecrsl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/07 21:30:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "12/07 21:30:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "12/07 21:30:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: torchvision://resnet50\n",
      "12/07 21:30:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by torchvision backend from path: torchvision://resnet50\n",
      "12/07 21:30:56 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "12/07 21:30:56 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "12/07 21:30:56 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "12/07 21:30:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /data/ephemeral/home/kkhs/mmdetection/work_dirs/faster_rcnn_r50_fpn_1x_trash.\n",
      "12/07 21:31:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][  50/1135]  lr: 1.9820e-03  eta: 0:47:56  time: 0.2120  data_time: 0.0152  memory: 2021  grad_norm: 6.9104  loss: 1.0338  loss_rpn_cls: 0.4041  loss_rpn_bbox: 0.0381  loss_cls: 0.5036  acc: 95.2637  loss_bbox: 0.0880\n",
      "12/07 21:31:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 100/1135]  lr: 3.9840e-03  eta: 0:46:01  time: 0.1965  data_time: 0.0086  memory: 2021  grad_norm: 2.4839  loss: 0.6227  loss_rpn_cls: 0.1150  loss_rpn_bbox: 0.0338  loss_cls: 0.2759  acc: 92.8223  loss_bbox: 0.1981\n",
      "12/07 21:31:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 150/1135]  lr: 5.9860e-03  eta: 0:45:23  time: 0.1981  data_time: 0.0086  memory: 2021  grad_norm: 2.1936  loss: 0.5988  loss_rpn_cls: 0.0939  loss_rpn_bbox: 0.0265  loss_cls: 0.2748  acc: 93.1641  loss_bbox: 0.2036\n",
      "12/07 21:31:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 200/1135]  lr: 7.9880e-03  eta: 0:44:43  time: 0.1933  data_time: 0.0087  memory: 2021  grad_norm: 2.8444  loss: 0.6893  loss_rpn_cls: 0.1201  loss_rpn_bbox: 0.0391  loss_cls: 0.3026  acc: 95.8008  loss_bbox: 0.2275\n",
      "12/07 21:31:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 250/1135]  lr: 9.9900e-03  eta: 0:44:14  time: 0.1927  data_time: 0.0083  memory: 2022  grad_norm: 2.4307  loss: 0.6930  loss_rpn_cls: 0.1061  loss_rpn_bbox: 0.0344  loss_cls: 0.3114  acc: 95.5566  loss_bbox: 0.2410\n",
      "12/07 21:31:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 300/1135]  lr: 1.1992e-02  eta: 0:43:46  time: 0.1904  data_time: 0.0085  memory: 2022  grad_norm: 2.3789  loss: 0.7072  loss_rpn_cls: 0.0987  loss_rpn_bbox: 0.0340  loss_cls: 0.3118  acc: 92.2852  loss_bbox: 0.2626\n",
      "12/07 21:32:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 350/1135]  lr: 1.3994e-02  eta: 0:43:31  time: 0.1948  data_time: 0.0089  memory: 2022  grad_norm: 2.0569  loss: 0.6170  loss_rpn_cls: 0.0880  loss_rpn_bbox: 0.0314  loss_cls: 0.2865  acc: 97.1680  loss_bbox: 0.2110\n",
      "12/07 21:32:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 400/1135]  lr: 1.5996e-02  eta: 0:43:13  time: 0.1916  data_time: 0.0084  memory: 2021  grad_norm: 1.9671  loss: 0.6167  loss_rpn_cls: 0.0754  loss_rpn_bbox: 0.0290  loss_cls: 0.2967  acc: 92.8711  loss_bbox: 0.2155\n",
      "12/07 21:32:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 450/1135]  lr: 1.7998e-02  eta: 0:42:58  time: 0.1928  data_time: 0.0083  memory: 2022  grad_norm: 2.1231  loss: 0.7000  loss_rpn_cls: 0.0941  loss_rpn_bbox: 0.0364  loss_cls: 0.3276  acc: 93.9941  loss_bbox: 0.2419\n",
      "12/07 21:32:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 500/1135]  lr: 2.0000e-02  eta: 0:42:46  time: 0.1935  data_time: 0.0087  memory: 2022  grad_norm: 2.3327  loss: 0.7035  loss_rpn_cls: 0.1079  loss_rpn_bbox: 0.0387  loss_cls: 0.3258  acc: 89.4531  loss_bbox: 0.2311\n",
      "12/07 21:32:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 550/1135]  lr: 2.0000e-02  eta: 0:42:34  time: 0.1942  data_time: 0.0085  memory: 2022  grad_norm: 1.9453  loss: 0.6768  loss_rpn_cls: 0.0772  loss_rpn_bbox: 0.0338  loss_cls: 0.3347  acc: 93.0664  loss_bbox: 0.2311\n",
      "12/07 21:32:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 600/1135]  lr: 2.0000e-02  eta: 0:42:21  time: 0.1925  data_time: 0.0088  memory: 2022  grad_norm: 2.2457  loss: 0.7119  loss_rpn_cls: 0.0929  loss_rpn_bbox: 0.0367  loss_cls: 0.3388  acc: 92.0898  loss_bbox: 0.2435\n",
      "12/07 21:33:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 650/1135]  lr: 2.0000e-02  eta: 0:42:07  time: 0.1910  data_time: 0.0086  memory: 2022  grad_norm: 1.9557  loss: 0.6157  loss_rpn_cls: 0.0722  loss_rpn_bbox: 0.0317  loss_cls: 0.3018  acc: 96.5332  loss_bbox: 0.2100\n",
      "12/07 21:33:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 700/1135]  lr: 2.0000e-02  eta: 0:41:55  time: 0.1920  data_time: 0.0085  memory: 2022  grad_norm: 1.7310  loss: 0.6100  loss_rpn_cls: 0.0675  loss_rpn_bbox: 0.0289  loss_cls: 0.3048  acc: 91.2598  loss_bbox: 0.2089\n",
      "12/07 21:33:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 750/1135]  lr: 2.0000e-02  eta: 0:41:43  time: 0.1923  data_time: 0.0087  memory: 2022  grad_norm: 1.8780  loss: 0.6202  loss_rpn_cls: 0.0718  loss_rpn_bbox: 0.0324  loss_cls: 0.2990  acc: 93.9941  loss_bbox: 0.2171\n",
      "12/07 21:33:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 800/1135]  lr: 2.0000e-02  eta: 0:41:33  time: 0.1945  data_time: 0.0085  memory: 2022  grad_norm: 1.9245  loss: 0.6316  loss_rpn_cls: 0.0674  loss_rpn_bbox: 0.0364  loss_cls: 0.3109  acc: 89.6484  loss_bbox: 0.2168\n",
      "12/07 21:33:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 850/1135]  lr: 2.0000e-02  eta: 0:41:22  time: 0.1924  data_time: 0.0084  memory: 2022  grad_norm: 1.8258  loss: 0.6443  loss_rpn_cls: 0.0709  loss_rpn_bbox: 0.0378  loss_cls: 0.3137  acc: 91.5039  loss_bbox: 0.2219\n",
      "12/07 21:33:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 900/1135]  lr: 2.0000e-02  eta: 0:41:11  time: 0.1932  data_time: 0.0085  memory: 2022  grad_norm: 1.7914  loss: 0.5600  loss_rpn_cls: 0.0726  loss_rpn_bbox: 0.0339  loss_cls: 0.2656  acc: 94.0918  loss_bbox: 0.1880\n",
      "12/07 21:34:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 950/1135]  lr: 2.0000e-02  eta: 0:41:00  time: 0.1912  data_time: 0.0086  memory: 2022  grad_norm: 1.9056  loss: 0.6825  loss_rpn_cls: 0.0688  loss_rpn_bbox: 0.0353  loss_cls: 0.3360  acc: 92.3828  loss_bbox: 0.2424\n",
      "12/07 21:34:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:34:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1000/1135]  lr: 2.0000e-02  eta: 0:40:49  time: 0.1924  data_time: 0.0086  memory: 2022  grad_norm: 1.7893  loss: 0.5940  loss_rpn_cls: 0.0575  loss_rpn_bbox: 0.0284  loss_cls: 0.2980  acc: 93.3105  loss_bbox: 0.2100\n",
      "12/07 21:34:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1050/1135]  lr: 2.0000e-02  eta: 0:40:39  time: 0.1932  data_time: 0.0086  memory: 2022  grad_norm: 1.8572  loss: 0.6380  loss_rpn_cls: 0.0684  loss_rpn_bbox: 0.0311  loss_cls: 0.3155  acc: 92.3340  loss_bbox: 0.2230\n",
      "12/07 21:34:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][1100/1135]  lr: 2.0000e-02  eta: 0:40:28  time: 0.1929  data_time: 0.0087  memory: 2022  grad_norm: 1.6760  loss: 0.6163  loss_rpn_cls: 0.0703  loss_rpn_bbox: 0.0278  loss_cls: 0.3061  acc: 89.7949  loss_bbox: 0.2121\n",
      "12/07 21:34:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:34:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "12/07 21:34:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][  50/1135]  lr: 2.0000e-02  eta: 0:40:11  time: 0.1958  data_time: 0.0122  memory: 2022  grad_norm: 1.7587  loss: 0.5870  loss_rpn_cls: 0.0615  loss_rpn_bbox: 0.0277  loss_cls: 0.2908  acc: 86.4746  loss_bbox: 0.2070\n",
      "12/07 21:34:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 100/1135]  lr: 2.0000e-02  eta: 0:39:59  time: 0.1896  data_time: 0.0082  memory: 2022  grad_norm: 1.7426  loss: 0.6021  loss_rpn_cls: 0.0537  loss_rpn_bbox: 0.0272  loss_cls: 0.3038  acc: 86.3770  loss_bbox: 0.2174\n",
      "12/07 21:35:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 150/1135]  lr: 2.0000e-02  eta: 0:39:48  time: 0.1898  data_time: 0.0082  memory: 2022  grad_norm: 1.7776  loss: 0.5612  loss_rpn_cls: 0.0535  loss_rpn_bbox: 0.0241  loss_cls: 0.2856  acc: 92.7246  loss_bbox: 0.1981\n",
      "12/07 21:35:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 200/1135]  lr: 2.0000e-02  eta: 0:39:37  time: 0.1917  data_time: 0.0090  memory: 2022  grad_norm: 1.7411  loss: 0.5740  loss_rpn_cls: 0.0586  loss_rpn_bbox: 0.0296  loss_cls: 0.2924  acc: 90.2344  loss_bbox: 0.1935\n",
      "12/07 21:35:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 250/1135]  lr: 2.0000e-02  eta: 0:39:27  time: 0.1922  data_time: 0.0086  memory: 2022  grad_norm: 1.8734  loss: 0.6677  loss_rpn_cls: 0.0732  loss_rpn_bbox: 0.0331  loss_cls: 0.3280  acc: 90.7715  loss_bbox: 0.2334\n",
      "12/07 21:35:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 300/1135]  lr: 2.0000e-02  eta: 0:39:17  time: 0.1925  data_time: 0.0090  memory: 2022  grad_norm: 1.6675  loss: 0.5807  loss_rpn_cls: 0.0614  loss_rpn_bbox: 0.0297  loss_cls: 0.2846  acc: 95.3125  loss_bbox: 0.2051\n",
      "12/07 21:35:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 350/1135]  lr: 2.0000e-02  eta: 0:39:06  time: 0.1914  data_time: 0.0083  memory: 2022  grad_norm: 1.7573  loss: 0.5763  loss_rpn_cls: 0.0487  loss_rpn_bbox: 0.0266  loss_cls: 0.2930  acc: 93.3105  loss_bbox: 0.2082\n",
      "12/07 21:35:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 400/1135]  lr: 2.0000e-02  eta: 0:38:56  time: 0.1924  data_time: 0.0087  memory: 2022  grad_norm: 1.7266  loss: 0.5635  loss_rpn_cls: 0.0510  loss_rpn_bbox: 0.0242  loss_cls: 0.2918  acc: 95.0684  loss_bbox: 0.1965\n",
      "12/07 21:36:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 450/1135]  lr: 2.0000e-02  eta: 0:38:46  time: 0.1920  data_time: 0.0085  memory: 2022  grad_norm: 1.7606  loss: 0.5634  loss_rpn_cls: 0.0513  loss_rpn_bbox: 0.0249  loss_cls: 0.2866  acc: 91.3086  loss_bbox: 0.2008\n",
      "12/07 21:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 500/1135]  lr: 2.0000e-02  eta: 0:38:35  time: 0.1906  data_time: 0.0081  memory: 2022  grad_norm: 1.8580  loss: 0.6210  loss_rpn_cls: 0.0606  loss_rpn_bbox: 0.0334  loss_cls: 0.3023  acc: 89.8438  loss_bbox: 0.2247\n",
      "12/07 21:36:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 550/1135]  lr: 2.0000e-02  eta: 0:38:25  time: 0.1914  data_time: 0.0086  memory: 2022  grad_norm: 1.6264  loss: 0.5415  loss_rpn_cls: 0.0541  loss_rpn_bbox: 0.0263  loss_cls: 0.2720  acc: 97.3633  loss_bbox: 0.1891\n",
      "12/07 21:36:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 600/1135]  lr: 2.0000e-02  eta: 0:38:15  time: 0.1923  data_time: 0.0083  memory: 2022  grad_norm: 1.8135  loss: 0.5732  loss_rpn_cls: 0.0534  loss_rpn_bbox: 0.0283  loss_cls: 0.2892  acc: 90.5762  loss_bbox: 0.2023\n",
      "12/07 21:36:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 650/1135]  lr: 2.0000e-02  eta: 0:38:05  time: 0.1911  data_time: 0.0083  memory: 2021  grad_norm: 1.6408  loss: 0.6486  loss_rpn_cls: 0.0636  loss_rpn_bbox: 0.0337  loss_cls: 0.3280  acc: 89.4043  loss_bbox: 0.2233\n",
      "12/07 21:36:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 700/1135]  lr: 2.0000e-02  eta: 0:37:54  time: 0.1904  data_time: 0.0088  memory: 2022  grad_norm: 1.8613  loss: 0.6109  loss_rpn_cls: 0.0682  loss_rpn_bbox: 0.0313  loss_cls: 0.2997  acc: 94.5312  loss_bbox: 0.2116\n",
      "12/07 21:37:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 750/1135]  lr: 2.0000e-02  eta: 0:37:44  time: 0.1930  data_time: 0.0086  memory: 2022  grad_norm: 1.7221  loss: 0.6276  loss_rpn_cls: 0.0692  loss_rpn_bbox: 0.0354  loss_cls: 0.3022  acc: 91.8945  loss_bbox: 0.2208\n",
      "12/07 21:37:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 800/1135]  lr: 2.0000e-02  eta: 0:37:35  time: 0.1928  data_time: 0.0089  memory: 2022  grad_norm: 1.5567  loss: 0.4906  loss_rpn_cls: 0.0459  loss_rpn_bbox: 0.0239  loss_cls: 0.2545  acc: 95.5566  loss_bbox: 0.1664\n",
      "12/07 21:37:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 850/1135]  lr: 2.0000e-02  eta: 0:37:25  time: 0.1925  data_time: 0.0084  memory: 2022  grad_norm: 1.7656  loss: 0.6315  loss_rpn_cls: 0.0566  loss_rpn_bbox: 0.0284  loss_cls: 0.3174  acc: 95.5078  loss_bbox: 0.2290\n",
      "12/07 21:37:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:37:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 900/1135]  lr: 2.0000e-02  eta: 0:37:15  time: 0.1921  data_time: 0.0084  memory: 2022  grad_norm: 1.7454  loss: 0.6017  loss_rpn_cls: 0.0527  loss_rpn_bbox: 0.0290  loss_cls: 0.2988  acc: 92.6758  loss_bbox: 0.2212\n",
      "12/07 21:37:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 950/1135]  lr: 2.0000e-02  eta: 0:37:05  time: 0.1930  data_time: 0.0085  memory: 2022  grad_norm: 1.7292  loss: 0.5580  loss_rpn_cls: 0.0482  loss_rpn_bbox: 0.0292  loss_cls: 0.2789  acc: 89.9902  loss_bbox: 0.2017\n",
      "12/07 21:37:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1000/1135]  lr: 2.0000e-02  eta: 0:36:55  time: 0.1919  data_time: 0.0085  memory: 2022  grad_norm: 1.6931  loss: 0.5838  loss_rpn_cls: 0.0525  loss_rpn_bbox: 0.0258  loss_cls: 0.2960  acc: 95.4102  loss_bbox: 0.2095\n",
      "12/07 21:38:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1050/1135]  lr: 2.0000e-02  eta: 0:36:46  time: 0.1931  data_time: 0.0084  memory: 2022  grad_norm: 1.8704  loss: 0.5946  loss_rpn_cls: 0.0536  loss_rpn_bbox: 0.0318  loss_cls: 0.2937  acc: 91.3574  loss_bbox: 0.2155\n",
      "12/07 21:38:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][1100/1135]  lr: 2.0000e-02  eta: 0:36:36  time: 0.1902  data_time: 0.0085  memory: 2022  grad_norm: 1.6381  loss: 0.5427  loss_rpn_cls: 0.0501  loss_rpn_bbox: 0.0257  loss_cls: 0.2746  acc: 90.0391  loss_bbox: 0.1923\n",
      "12/07 21:38:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:38:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "12/07 21:38:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][  50/1135]  lr: 2.0000e-02  eta: 0:36:19  time: 0.1966  data_time: 0.0127  memory: 2022  grad_norm: 1.6492  loss: 0.5022  loss_rpn_cls: 0.0344  loss_rpn_bbox: 0.0251  loss_cls: 0.2618  acc: 88.9160  loss_bbox: 0.1808\n",
      "12/07 21:38:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 100/1135]  lr: 2.0000e-02  eta: 0:36:09  time: 0.1909  data_time: 0.0085  memory: 2022  grad_norm: 1.7530  loss: 0.5807  loss_rpn_cls: 0.0507  loss_rpn_bbox: 0.0279  loss_cls: 0.2888  acc: 95.8984  loss_bbox: 0.2134\n",
      "12/07 21:38:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 150/1135]  lr: 2.0000e-02  eta: 0:35:59  time: 0.1916  data_time: 0.0087  memory: 2021  grad_norm: 1.6802  loss: 0.5203  loss_rpn_cls: 0.0477  loss_rpn_bbox: 0.0229  loss_cls: 0.2596  acc: 95.0684  loss_bbox: 0.1901\n",
      "12/07 21:38:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 200/1135]  lr: 2.0000e-02  eta: 0:35:49  time: 0.1925  data_time: 0.0087  memory: 2022  grad_norm: 1.6735  loss: 0.5538  loss_rpn_cls: 0.0529  loss_rpn_bbox: 0.0297  loss_cls: 0.2744  acc: 91.9922  loss_bbox: 0.1968\n",
      "12/07 21:39:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 250/1135]  lr: 2.0000e-02  eta: 0:35:41  time: 0.1983  data_time: 0.0085  memory: 2022  grad_norm: 1.6374  loss: 0.5246  loss_rpn_cls: 0.0413  loss_rpn_bbox: 0.0244  loss_cls: 0.2700  acc: 93.1641  loss_bbox: 0.1889\n",
      "12/07 21:39:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 300/1135]  lr: 2.0000e-02  eta: 0:35:31  time: 0.1909  data_time: 0.0087  memory: 2021  grad_norm: 1.8162  loss: 0.5901  loss_rpn_cls: 0.0425  loss_rpn_bbox: 0.0329  loss_cls: 0.2987  acc: 86.5723  loss_bbox: 0.2159\n",
      "12/07 21:39:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 350/1135]  lr: 2.0000e-02  eta: 0:35:21  time: 0.1923  data_time: 0.0087  memory: 2022  grad_norm: 1.7212  loss: 0.5341  loss_rpn_cls: 0.0486  loss_rpn_bbox: 0.0251  loss_cls: 0.2694  acc: 90.6250  loss_bbox: 0.1911\n",
      "12/07 21:39:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 400/1135]  lr: 2.0000e-02  eta: 0:35:11  time: 0.1921  data_time: 0.0086  memory: 2022  grad_norm: 1.6969  loss: 0.5362  loss_rpn_cls: 0.0508  loss_rpn_bbox: 0.0244  loss_cls: 0.2694  acc: 95.7031  loss_bbox: 0.1916\n",
      "12/07 21:39:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 450/1135]  lr: 2.0000e-02  eta: 0:35:01  time: 0.1898  data_time: 0.0085  memory: 2021  grad_norm: 1.6511  loss: 0.4933  loss_rpn_cls: 0.0465  loss_rpn_bbox: 0.0225  loss_cls: 0.2513  acc: 95.2637  loss_bbox: 0.1730\n",
      "12/07 21:39:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 500/1135]  lr: 2.0000e-02  eta: 0:34:51  time: 0.1912  data_time: 0.0084  memory: 2022  grad_norm: 1.6678  loss: 0.5287  loss_rpn_cls: 0.0426  loss_rpn_bbox: 0.0234  loss_cls: 0.2745  acc: 90.1367  loss_bbox: 0.1883\n",
      "12/07 21:40:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 550/1135]  lr: 2.0000e-02  eta: 0:34:41  time: 0.1916  data_time: 0.0086  memory: 2022  grad_norm: 1.6707  loss: 0.5521  loss_rpn_cls: 0.0488  loss_rpn_bbox: 0.0279  loss_cls: 0.2769  acc: 89.4531  loss_bbox: 0.1986\n",
      "12/07 21:40:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 600/1135]  lr: 2.0000e-02  eta: 0:34:31  time: 0.1918  data_time: 0.0086  memory: 2022  grad_norm: 1.7120  loss: 0.5874  loss_rpn_cls: 0.0445  loss_rpn_bbox: 0.0277  loss_cls: 0.2944  acc: 95.7031  loss_bbox: 0.2208\n",
      "12/07 21:40:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 650/1135]  lr: 2.0000e-02  eta: 0:34:21  time: 0.1915  data_time: 0.0086  memory: 2021  grad_norm: 1.7418  loss: 0.5358  loss_rpn_cls: 0.0504  loss_rpn_bbox: 0.0268  loss_cls: 0.2641  acc: 92.7734  loss_bbox: 0.1945\n",
      "12/07 21:40:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 700/1135]  lr: 2.0000e-02  eta: 0:34:12  time: 0.1913  data_time: 0.0086  memory: 2021  grad_norm: 1.6045  loss: 0.5263  loss_rpn_cls: 0.0541  loss_rpn_bbox: 0.0272  loss_cls: 0.2645  acc: 93.1152  loss_bbox: 0.1805\n",
      "12/07 21:40:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:40:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 750/1135]  lr: 2.0000e-02  eta: 0:34:01  time: 0.1893  data_time: 0.0085  memory: 2022  grad_norm: 1.6848  loss: 0.5284  loss_rpn_cls: 0.0455  loss_rpn_bbox: 0.0244  loss_cls: 0.2707  acc: 90.6250  loss_bbox: 0.1879\n",
      "12/07 21:40:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 800/1135]  lr: 2.0000e-02  eta: 0:33:52  time: 0.1914  data_time: 0.0086  memory: 2021  grad_norm: 1.7778  loss: 0.5985  loss_rpn_cls: 0.0488  loss_rpn_bbox: 0.0256  loss_cls: 0.3040  acc: 95.1660  loss_bbox: 0.2201\n",
      "12/07 21:41:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 850/1135]  lr: 2.0000e-02  eta: 0:33:42  time: 0.1913  data_time: 0.0084  memory: 2022  grad_norm: 1.6879  loss: 0.5465  loss_rpn_cls: 0.0442  loss_rpn_bbox: 0.0295  loss_cls: 0.2725  acc: 93.2129  loss_bbox: 0.2003\n",
      "12/07 21:41:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 900/1135]  lr: 2.0000e-02  eta: 0:33:32  time: 0.1916  data_time: 0.0087  memory: 2022  grad_norm: 1.7690  loss: 0.5018  loss_rpn_cls: 0.0440  loss_rpn_bbox: 0.0253  loss_cls: 0.2515  acc: 91.1133  loss_bbox: 0.1810\n",
      "12/07 21:41:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 950/1135]  lr: 2.0000e-02  eta: 0:33:22  time: 0.1898  data_time: 0.0084  memory: 2022  grad_norm: 1.6730  loss: 0.5252  loss_rpn_cls: 0.0441  loss_rpn_bbox: 0.0258  loss_cls: 0.2660  acc: 94.5312  loss_bbox: 0.1893\n",
      "12/07 21:41:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1000/1135]  lr: 2.0000e-02  eta: 0:33:12  time: 0.1916  data_time: 0.0088  memory: 2022  grad_norm: 1.7700  loss: 0.6114  loss_rpn_cls: 0.0548  loss_rpn_bbox: 0.0294  loss_cls: 0.3059  acc: 94.4336  loss_bbox: 0.2214\n",
      "12/07 21:41:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1050/1135]  lr: 2.0000e-02  eta: 0:33:02  time: 0.1918  data_time: 0.0086  memory: 2022  grad_norm: 1.7289  loss: 0.5587  loss_rpn_cls: 0.0504  loss_rpn_bbox: 0.0310  loss_cls: 0.2800  acc: 92.9199  loss_bbox: 0.1973\n",
      "12/07 21:41:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][1100/1135]  lr: 2.0000e-02  eta: 0:32:52  time: 0.1908  data_time: 0.0088  memory: 2022  grad_norm: 1.7841  loss: 0.5747  loss_rpn_cls: 0.0512  loss_rpn_bbox: 0.0282  loss_cls: 0.2848  acc: 95.5566  loss_bbox: 0.2105\n",
      "12/07 21:41:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:41:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "12/07 21:42:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][  50/1135]  lr: 2.0000e-02  eta: 0:32:36  time: 0.1945  data_time: 0.0124  memory: 2022  grad_norm: 1.5612  loss: 0.4739  loss_rpn_cls: 0.0405  loss_rpn_bbox: 0.0226  loss_cls: 0.2389  acc: 92.9199  loss_bbox: 0.1719\n",
      "12/07 21:42:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 100/1135]  lr: 2.0000e-02  eta: 0:32:26  time: 0.1917  data_time: 0.0089  memory: 2021  grad_norm: 1.4859  loss: 0.4421  loss_rpn_cls: 0.0354  loss_rpn_bbox: 0.0263  loss_cls: 0.2203  acc: 96.3867  loss_bbox: 0.1600\n",
      "12/07 21:42:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 150/1135]  lr: 2.0000e-02  eta: 0:32:16  time: 0.1917  data_time: 0.0086  memory: 2022  grad_norm: 1.7420  loss: 0.5308  loss_rpn_cls: 0.0473  loss_rpn_bbox: 0.0276  loss_cls: 0.2689  acc: 90.8691  loss_bbox: 0.1870\n",
      "12/07 21:42:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 200/1135]  lr: 2.0000e-02  eta: 0:32:07  time: 0.1916  data_time: 0.0086  memory: 2022  grad_norm: 1.6348  loss: 0.5012  loss_rpn_cls: 0.0401  loss_rpn_bbox: 0.0232  loss_cls: 0.2573  acc: 96.2891  loss_bbox: 0.1805\n",
      "12/07 21:42:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 250/1135]  lr: 2.0000e-02  eta: 0:31:57  time: 0.1915  data_time: 0.0087  memory: 2022  grad_norm: 1.6507  loss: 0.4946  loss_rpn_cls: 0.0381  loss_rpn_bbox: 0.0220  loss_cls: 0.2471  acc: 85.2539  loss_bbox: 0.1875\n",
      "12/07 21:42:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 300/1135]  lr: 2.0000e-02  eta: 0:31:47  time: 0.1909  data_time: 0.0085  memory: 2021  grad_norm: 1.5760  loss: 0.4779  loss_rpn_cls: 0.0377  loss_rpn_bbox: 0.0233  loss_cls: 0.2428  acc: 97.4121  loss_bbox: 0.1740\n",
      "12/07 21:43:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 350/1135]  lr: 2.0000e-02  eta: 0:31:38  time: 0.1925  data_time: 0.0085  memory: 2022  grad_norm: 1.8127  loss: 0.5305  loss_rpn_cls: 0.0456  loss_rpn_bbox: 0.0257  loss_cls: 0.2607  acc: 96.8750  loss_bbox: 0.1985\n",
      "12/07 21:43:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 400/1135]  lr: 2.0000e-02  eta: 0:31:28  time: 0.1929  data_time: 0.0085  memory: 2022  grad_norm: 1.8029  loss: 0.5362  loss_rpn_cls: 0.0390  loss_rpn_bbox: 0.0220  loss_cls: 0.2732  acc: 89.7949  loss_bbox: 0.2020\n",
      "12/07 21:43:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 450/1135]  lr: 2.0000e-02  eta: 0:31:18  time: 0.1925  data_time: 0.0088  memory: 2022  grad_norm: 1.7382  loss: 0.5175  loss_rpn_cls: 0.0448  loss_rpn_bbox: 0.0238  loss_cls: 0.2620  acc: 92.7734  loss_bbox: 0.1870\n",
      "12/07 21:43:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 500/1135]  lr: 2.0000e-02  eta: 0:31:09  time: 0.1959  data_time: 0.0087  memory: 2021  grad_norm: 1.8892  loss: 0.5621  loss_rpn_cls: 0.0461  loss_rpn_bbox: 0.0279  loss_cls: 0.2800  acc: 94.6289  loss_bbox: 0.2080\n",
      "12/07 21:43:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 550/1135]  lr: 2.0000e-02  eta: 0:31:00  time: 0.1923  data_time: 0.0088  memory: 2021  grad_norm: 1.6658  loss: 0.5268  loss_rpn_cls: 0.0474  loss_rpn_bbox: 0.0238  loss_cls: 0.2637  acc: 92.5781  loss_bbox: 0.1918\n",
      "12/07 21:43:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:43:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 600/1135]  lr: 2.0000e-02  eta: 0:30:50  time: 0.1918  data_time: 0.0086  memory: 2022  grad_norm: 1.7302  loss: 0.5152  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0282  loss_cls: 0.2595  acc: 87.8906  loss_bbox: 0.1872\n",
      "12/07 21:44:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 650/1135]  lr: 2.0000e-02  eta: 0:30:40  time: 0.1925  data_time: 0.0085  memory: 2022  grad_norm: 1.6579  loss: 0.5506  loss_rpn_cls: 0.0410  loss_rpn_bbox: 0.0263  loss_cls: 0.2830  acc: 91.2598  loss_bbox: 0.2004\n",
      "12/07 21:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 700/1135]  lr: 2.0000e-02  eta: 0:30:31  time: 0.1945  data_time: 0.0089  memory: 2022  grad_norm: 1.8147  loss: 0.5792  loss_rpn_cls: 0.0461  loss_rpn_bbox: 0.0264  loss_cls: 0.2913  acc: 92.3340  loss_bbox: 0.2153\n",
      "12/07 21:44:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 750/1135]  lr: 2.0000e-02  eta: 0:30:21  time: 0.1926  data_time: 0.0091  memory: 2021  grad_norm: 1.8646  loss: 0.5662  loss_rpn_cls: 0.0454  loss_rpn_bbox: 0.0271  loss_cls: 0.2918  acc: 92.7734  loss_bbox: 0.2019\n",
      "12/07 21:44:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 800/1135]  lr: 2.0000e-02  eta: 0:30:12  time: 0.1922  data_time: 0.0089  memory: 2022  grad_norm: 1.7915  loss: 0.5952  loss_rpn_cls: 0.0522  loss_rpn_bbox: 0.0299  loss_cls: 0.2919  acc: 93.5059  loss_bbox: 0.2211\n",
      "12/07 21:44:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 850/1135]  lr: 2.0000e-02  eta: 0:30:02  time: 0.1922  data_time: 0.0088  memory: 2022  grad_norm: 1.6141  loss: 0.5020  loss_rpn_cls: 0.0480  loss_rpn_bbox: 0.0245  loss_cls: 0.2524  acc: 95.6055  loss_bbox: 0.1770\n",
      "12/07 21:44:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 900/1135]  lr: 2.0000e-02  eta: 0:29:52  time: 0.1917  data_time: 0.0091  memory: 2022  grad_norm: 1.6393  loss: 0.4876  loss_rpn_cls: 0.0431  loss_rpn_bbox: 0.0223  loss_cls: 0.2414  acc: 96.2891  loss_bbox: 0.1807\n",
      "12/07 21:45:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 950/1135]  lr: 2.0000e-02  eta: 0:29:43  time: 0.1926  data_time: 0.0081  memory: 2021  grad_norm: 1.7141  loss: 0.4930  loss_rpn_cls: 0.0396  loss_rpn_bbox: 0.0223  loss_cls: 0.2541  acc: 93.7012  loss_bbox: 0.1769\n",
      "12/07 21:45:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1000/1135]  lr: 2.0000e-02  eta: 0:29:33  time: 0.1908  data_time: 0.0088  memory: 2022  grad_norm: 1.7120  loss: 0.5256  loss_rpn_cls: 0.0450  loss_rpn_bbox: 0.0249  loss_cls: 0.2606  acc: 87.7930  loss_bbox: 0.1952\n",
      "12/07 21:45:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1050/1135]  lr: 2.0000e-02  eta: 0:29:23  time: 0.1938  data_time: 0.0090  memory: 2022  grad_norm: 1.6571  loss: 0.4965  loss_rpn_cls: 0.0418  loss_rpn_bbox: 0.0232  loss_cls: 0.2442  acc: 93.7988  loss_bbox: 0.1871\n",
      "12/07 21:45:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][1100/1135]  lr: 2.0000e-02  eta: 0:29:13  time: 0.1902  data_time: 0.0085  memory: 2022  grad_norm: 1.7783  loss: 0.5236  loss_rpn_cls: 0.0453  loss_rpn_bbox: 0.0250  loss_cls: 0.2634  acc: 91.5527  loss_bbox: 0.1899\n",
      "12/07 21:45:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:45:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
      "12/07 21:45:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][  50/1135]  lr: 2.0000e-02  eta: 0:28:57  time: 0.1954  data_time: 0.0125  memory: 2022  grad_norm: 1.6232  loss: 0.4992  loss_rpn_cls: 0.0357  loss_rpn_bbox: 0.0270  loss_cls: 0.2421  acc: 92.4316  loss_bbox: 0.1944\n",
      "12/07 21:45:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 100/1135]  lr: 2.0000e-02  eta: 0:28:48  time: 0.1938  data_time: 0.0088  memory: 2022  grad_norm: 1.7019  loss: 0.5140  loss_rpn_cls: 0.0338  loss_rpn_bbox: 0.0257  loss_cls: 0.2525  acc: 93.9453  loss_bbox: 0.2019\n",
      "12/07 21:46:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 150/1135]  lr: 2.0000e-02  eta: 0:28:38  time: 0.1901  data_time: 0.0088  memory: 2022  grad_norm: 1.7843  loss: 0.5145  loss_rpn_cls: 0.0311  loss_rpn_bbox: 0.0230  loss_cls: 0.2628  acc: 97.0215  loss_bbox: 0.1976\n",
      "12/07 21:46:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 200/1135]  lr: 2.0000e-02  eta: 0:28:28  time: 0.1919  data_time: 0.0087  memory: 2022  grad_norm: 1.6798  loss: 0.5097  loss_rpn_cls: 0.0443  loss_rpn_bbox: 0.0275  loss_cls: 0.2531  acc: 95.2148  loss_bbox: 0.1848\n",
      "12/07 21:46:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 250/1135]  lr: 2.0000e-02  eta: 0:28:18  time: 0.1909  data_time: 0.0085  memory: 2022  grad_norm: 1.7903  loss: 0.4919  loss_rpn_cls: 0.0437  loss_rpn_bbox: 0.0247  loss_cls: 0.2438  acc: 96.0449  loss_bbox: 0.1797\n",
      "12/07 21:46:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 300/1135]  lr: 2.0000e-02  eta: 0:28:09  time: 0.1910  data_time: 0.0086  memory: 2021  grad_norm: 1.6748  loss: 0.4986  loss_rpn_cls: 0.0430  loss_rpn_bbox: 0.0240  loss_cls: 0.2499  acc: 93.7988  loss_bbox: 0.1817\n",
      "12/07 21:46:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 350/1135]  lr: 2.0000e-02  eta: 0:27:59  time: 0.1900  data_time: 0.0088  memory: 2022  grad_norm: 1.7326  loss: 0.4929  loss_rpn_cls: 0.0411  loss_rpn_bbox: 0.0219  loss_cls: 0.2546  acc: 95.3125  loss_bbox: 0.1752\n",
      "12/07 21:46:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 400/1135]  lr: 2.0000e-02  eta: 0:27:49  time: 0.1950  data_time: 0.0086  memory: 2022  grad_norm: 1.8063  loss: 0.4980  loss_rpn_cls: 0.0329  loss_rpn_bbox: 0.0222  loss_cls: 0.2549  acc: 90.8691  loss_bbox: 0.1880\n",
      "12/07 21:47:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 450/1135]  lr: 2.0000e-02  eta: 0:27:40  time: 0.1935  data_time: 0.0085  memory: 2022  grad_norm: 1.7867  loss: 0.5096  loss_rpn_cls: 0.0393  loss_rpn_bbox: 0.0230  loss_cls: 0.2587  acc: 86.6211  loss_bbox: 0.1886\n",
      "12/07 21:47:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:47:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 500/1135]  lr: 2.0000e-02  eta: 0:27:30  time: 0.1908  data_time: 0.0084  memory: 2022  grad_norm: 1.7232  loss: 0.5094  loss_rpn_cls: 0.0412  loss_rpn_bbox: 0.0246  loss_cls: 0.2512  acc: 96.0449  loss_bbox: 0.1925\n",
      "12/07 21:47:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 550/1135]  lr: 2.0000e-02  eta: 0:27:20  time: 0.1919  data_time: 0.0087  memory: 2021  grad_norm: 1.5914  loss: 0.4672  loss_rpn_cls: 0.0322  loss_rpn_bbox: 0.0214  loss_cls: 0.2396  acc: 93.7500  loss_bbox: 0.1739\n",
      "12/07 21:47:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 600/1135]  lr: 2.0000e-02  eta: 0:27:11  time: 0.1910  data_time: 0.0085  memory: 2022  grad_norm: 1.6734  loss: 0.5069  loss_rpn_cls: 0.0392  loss_rpn_bbox: 0.0239  loss_cls: 0.2537  acc: 97.1680  loss_bbox: 0.1901\n",
      "12/07 21:47:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 650/1135]  lr: 2.0000e-02  eta: 0:27:01  time: 0.1911  data_time: 0.0083  memory: 2022  grad_norm: 1.8117  loss: 0.5578  loss_rpn_cls: 0.0469  loss_rpn_bbox: 0.0299  loss_cls: 0.2788  acc: 90.4297  loss_bbox: 0.2022\n",
      "12/07 21:47:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 700/1135]  lr: 2.0000e-02  eta: 0:26:51  time: 0.1922  data_time: 0.0084  memory: 2022  grad_norm: 1.6463  loss: 0.5089  loss_rpn_cls: 0.0377  loss_rpn_bbox: 0.0250  loss_cls: 0.2536  acc: 91.4062  loss_bbox: 0.1926\n",
      "12/07 21:48:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 750/1135]  lr: 2.0000e-02  eta: 0:26:42  time: 0.1944  data_time: 0.0086  memory: 2022  grad_norm: 1.7201  loss: 0.5117  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0254  loss_cls: 0.2589  acc: 89.1602  loss_bbox: 0.1871\n",
      "12/07 21:48:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 800/1135]  lr: 2.0000e-02  eta: 0:26:32  time: 0.1927  data_time: 0.0087  memory: 2022  grad_norm: 1.7214  loss: 0.4766  loss_rpn_cls: 0.0283  loss_rpn_bbox: 0.0196  loss_cls: 0.2487  acc: 96.6797  loss_bbox: 0.1801\n",
      "12/07 21:48:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 850/1135]  lr: 2.0000e-02  eta: 0:26:23  time: 0.1928  data_time: 0.0088  memory: 2022  grad_norm: 1.7758  loss: 0.4639  loss_rpn_cls: 0.0346  loss_rpn_bbox: 0.0220  loss_cls: 0.2429  acc: 95.2637  loss_bbox: 0.1643\n",
      "12/07 21:48:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 900/1135]  lr: 2.0000e-02  eta: 0:26:13  time: 0.1926  data_time: 0.0085  memory: 2022  grad_norm: 1.8185  loss: 0.5218  loss_rpn_cls: 0.0427  loss_rpn_bbox: 0.0289  loss_cls: 0.2546  acc: 91.9434  loss_bbox: 0.1957\n",
      "12/07 21:48:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 950/1135]  lr: 2.0000e-02  eta: 0:26:03  time: 0.1915  data_time: 0.0088  memory: 2022  grad_norm: 1.7886  loss: 0.4983  loss_rpn_cls: 0.0451  loss_rpn_bbox: 0.0244  loss_cls: 0.2440  acc: 94.3359  loss_bbox: 0.1848\n",
      "12/07 21:48:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1000/1135]  lr: 2.0000e-02  eta: 0:25:54  time: 0.1887  data_time: 0.0084  memory: 2021  grad_norm: 1.7707  loss: 0.5241  loss_rpn_cls: 0.0424  loss_rpn_bbox: 0.0253  loss_cls: 0.2702  acc: 95.2637  loss_bbox: 0.1863\n",
      "12/07 21:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1050/1135]  lr: 2.0000e-02  eta: 0:25:44  time: 0.1914  data_time: 0.0086  memory: 2022  grad_norm: 1.7132  loss: 0.4861  loss_rpn_cls: 0.0330  loss_rpn_bbox: 0.0206  loss_cls: 0.2503  acc: 90.4297  loss_bbox: 0.1821\n",
      "12/07 21:49:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][1100/1135]  lr: 2.0000e-02  eta: 0:25:34  time: 0.1894  data_time: 0.0079  memory: 2021  grad_norm: 1.7418  loss: 0.5275  loss_rpn_cls: 0.0406  loss_rpn_bbox: 0.0241  loss_cls: 0.2612  acc: 93.0176  loss_bbox: 0.2016\n",
      "12/07 21:49:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:49:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
      "12/07 21:49:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][  50/1135]  lr: 2.0000e-02  eta: 0:25:18  time: 0.1954  data_time: 0.0131  memory: 2022  grad_norm: 1.6578  loss: 0.4223  loss_rpn_cls: 0.0258  loss_rpn_bbox: 0.0179  loss_cls: 0.2196  acc: 95.8008  loss_bbox: 0.1590\n",
      "12/07 21:49:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 100/1135]  lr: 2.0000e-02  eta: 0:25:08  time: 0.1941  data_time: 0.0089  memory: 2022  grad_norm: 1.6632  loss: 0.4439  loss_rpn_cls: 0.0262  loss_rpn_bbox: 0.0197  loss_cls: 0.2304  acc: 92.3828  loss_bbox: 0.1676\n",
      "12/07 21:49:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 150/1135]  lr: 2.0000e-02  eta: 0:24:59  time: 0.1896  data_time: 0.0085  memory: 2021  grad_norm: 1.8451  loss: 0.5214  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0227  loss_cls: 0.2589  acc: 95.7031  loss_bbox: 0.2080\n",
      "12/07 21:49:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 200/1135]  lr: 2.0000e-02  eta: 0:24:49  time: 0.1899  data_time: 0.0086  memory: 2022  grad_norm: 1.7418  loss: 0.4994  loss_rpn_cls: 0.0393  loss_rpn_bbox: 0.0264  loss_cls: 0.2485  acc: 94.1406  loss_bbox: 0.1853\n",
      "12/07 21:50:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 250/1135]  lr: 2.0000e-02  eta: 0:24:39  time: 0.1912  data_time: 0.0084  memory: 2021  grad_norm: 1.8984  loss: 0.5019  loss_rpn_cls: 0.0385  loss_rpn_bbox: 0.0231  loss_cls: 0.2520  acc: 92.4316  loss_bbox: 0.1883\n",
      "12/07 21:50:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 300/1135]  lr: 2.0000e-02  eta: 0:24:29  time: 0.1909  data_time: 0.0087  memory: 2022  grad_norm: 1.8700  loss: 0.5403  loss_rpn_cls: 0.0415  loss_rpn_bbox: 0.0299  loss_cls: 0.2692  acc: 91.8945  loss_bbox: 0.1998\n",
      "12/07 21:50:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:50:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 350/1135]  lr: 2.0000e-02  eta: 0:24:20  time: 0.1917  data_time: 0.0087  memory: 2021  grad_norm: 1.7172  loss: 0.4948  loss_rpn_cls: 0.0342  loss_rpn_bbox: 0.0240  loss_cls: 0.2410  acc: 94.2383  loss_bbox: 0.1956\n",
      "12/07 21:50:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 400/1135]  lr: 2.0000e-02  eta: 0:24:10  time: 0.1909  data_time: 0.0086  memory: 2022  grad_norm: 1.8949  loss: 0.5303  loss_rpn_cls: 0.0322  loss_rpn_bbox: 0.0240  loss_cls: 0.2717  acc: 96.8750  loss_bbox: 0.2024\n",
      "12/07 21:50:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 450/1135]  lr: 2.0000e-02  eta: 0:24:00  time: 0.1902  data_time: 0.0083  memory: 2022  grad_norm: 1.9064  loss: 0.5220  loss_rpn_cls: 0.0393  loss_rpn_bbox: 0.0272  loss_cls: 0.2596  acc: 97.1191  loss_bbox: 0.1960\n",
      "12/07 21:50:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 500/1135]  lr: 2.0000e-02  eta: 0:23:51  time: 0.1900  data_time: 0.0085  memory: 2022  grad_norm: 1.6136  loss: 0.4169  loss_rpn_cls: 0.0266  loss_rpn_bbox: 0.0205  loss_cls: 0.2109  acc: 88.4277  loss_bbox: 0.1589\n",
      "12/07 21:51:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 550/1135]  lr: 2.0000e-02  eta: 0:23:41  time: 0.1891  data_time: 0.0086  memory: 2022  grad_norm: 1.7070  loss: 0.4851  loss_rpn_cls: 0.0359  loss_rpn_bbox: 0.0207  loss_cls: 0.2492  acc: 88.2324  loss_bbox: 0.1793\n",
      "12/07 21:51:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 600/1135]  lr: 2.0000e-02  eta: 0:23:31  time: 0.1895  data_time: 0.0085  memory: 2022  grad_norm: 1.7254  loss: 0.4751  loss_rpn_cls: 0.0349  loss_rpn_bbox: 0.0240  loss_cls: 0.2323  acc: 90.6738  loss_bbox: 0.1839\n",
      "12/07 21:51:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 650/1135]  lr: 2.0000e-02  eta: 0:23:21  time: 0.1921  data_time: 0.0086  memory: 2022  grad_norm: 1.9189  loss: 0.5138  loss_rpn_cls: 0.0344  loss_rpn_bbox: 0.0289  loss_cls: 0.2576  acc: 92.7246  loss_bbox: 0.1929\n",
      "12/07 21:51:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 700/1135]  lr: 2.0000e-02  eta: 0:23:12  time: 0.1919  data_time: 0.0087  memory: 2022  grad_norm: 1.7297  loss: 0.4916  loss_rpn_cls: 0.0377  loss_rpn_bbox: 0.0238  loss_cls: 0.2519  acc: 94.6777  loss_bbox: 0.1781\n",
      "12/07 21:51:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 750/1135]  lr: 2.0000e-02  eta: 0:23:02  time: 0.1928  data_time: 0.0090  memory: 2022  grad_norm: 1.6994  loss: 0.4495  loss_rpn_cls: 0.0341  loss_rpn_bbox: 0.0234  loss_cls: 0.2329  acc: 91.9434  loss_bbox: 0.1592\n",
      "12/07 21:51:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 800/1135]  lr: 2.0000e-02  eta: 0:22:52  time: 0.1909  data_time: 0.0085  memory: 2022  grad_norm: 1.6705  loss: 0.4491  loss_rpn_cls: 0.0291  loss_rpn_bbox: 0.0234  loss_cls: 0.2281  acc: 94.7266  loss_bbox: 0.1685\n",
      "12/07 21:52:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 850/1135]  lr: 2.0000e-02  eta: 0:22:43  time: 0.1902  data_time: 0.0086  memory: 2021  grad_norm: 1.7747  loss: 0.5197  loss_rpn_cls: 0.0372  loss_rpn_bbox: 0.0231  loss_cls: 0.2653  acc: 91.4551  loss_bbox: 0.1940\n",
      "12/07 21:52:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 900/1135]  lr: 2.0000e-02  eta: 0:22:33  time: 0.1917  data_time: 0.0087  memory: 2022  grad_norm: 1.8493  loss: 0.4743  loss_rpn_cls: 0.0427  loss_rpn_bbox: 0.0251  loss_cls: 0.2333  acc: 95.4102  loss_bbox: 0.1732\n",
      "12/07 21:52:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 950/1135]  lr: 2.0000e-02  eta: 0:22:23  time: 0.1909  data_time: 0.0086  memory: 2022  grad_norm: 1.7338  loss: 0.4929  loss_rpn_cls: 0.0398  loss_rpn_bbox: 0.0225  loss_cls: 0.2432  acc: 96.9238  loss_bbox: 0.1875\n",
      "12/07 21:52:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1000/1135]  lr: 2.0000e-02  eta: 0:22:14  time: 0.1932  data_time: 0.0085  memory: 2021  grad_norm: 1.5345  loss: 0.4222  loss_rpn_cls: 0.0323  loss_rpn_bbox: 0.0194  loss_cls: 0.2123  acc: 97.1191  loss_bbox: 0.1581\n",
      "12/07 21:52:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1050/1135]  lr: 2.0000e-02  eta: 0:22:04  time: 0.1906  data_time: 0.0085  memory: 2021  grad_norm: 1.7116  loss: 0.4591  loss_rpn_cls: 0.0325  loss_rpn_bbox: 0.0206  loss_cls: 0.2354  acc: 91.9922  loss_bbox: 0.1705\n",
      "12/07 21:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][1100/1135]  lr: 2.0000e-02  eta: 0:21:55  time: 0.1908  data_time: 0.0086  memory: 2022  grad_norm: 1.6636  loss: 0.4609  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0240  loss_cls: 0.2279  acc: 92.8711  loss_bbox: 0.1701\n",
      "12/07 21:52:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:52:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
      "12/07 21:53:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][  50/1135]  lr: 2.0000e-02  eta: 0:21:38  time: 0.1967  data_time: 0.0129  memory: 2022  grad_norm: 1.7912  loss: 0.4732  loss_rpn_cls: 0.0334  loss_rpn_bbox: 0.0222  loss_cls: 0.2296  acc: 83.6914  loss_bbox: 0.1880\n",
      "12/07 21:53:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 100/1135]  lr: 2.0000e-02  eta: 0:21:28  time: 0.1890  data_time: 0.0085  memory: 2022  grad_norm: 1.6109  loss: 0.4260  loss_rpn_cls: 0.0250  loss_rpn_bbox: 0.0188  loss_cls: 0.2172  acc: 96.5332  loss_bbox: 0.1650\n",
      "12/07 21:53:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 150/1135]  lr: 2.0000e-02  eta: 0:21:19  time: 0.1904  data_time: 0.0083  memory: 2021  grad_norm: 1.6797  loss: 0.4652  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0228  loss_cls: 0.2338  acc: 95.3125  loss_bbox: 0.1766\n",
      "12/07 21:53:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:53:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 200/1135]  lr: 2.0000e-02  eta: 0:21:09  time: 0.1916  data_time: 0.0088  memory: 2022  grad_norm: 1.7405  loss: 0.4519  loss_rpn_cls: 0.0299  loss_rpn_bbox: 0.0209  loss_cls: 0.2282  acc: 92.7734  loss_bbox: 0.1729\n",
      "12/07 21:53:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 250/1135]  lr: 2.0000e-02  eta: 0:20:59  time: 0.1904  data_time: 0.0089  memory: 2022  grad_norm: 1.7608  loss: 0.4408  loss_rpn_cls: 0.0297  loss_rpn_bbox: 0.0224  loss_cls: 0.2235  acc: 87.7930  loss_bbox: 0.1651\n",
      "12/07 21:53:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 300/1135]  lr: 2.0000e-02  eta: 0:20:50  time: 0.1913  data_time: 0.0084  memory: 2021  grad_norm: 1.7977  loss: 0.4880  loss_rpn_cls: 0.0305  loss_rpn_bbox: 0.0215  loss_cls: 0.2445  acc: 95.0195  loss_bbox: 0.1916\n",
      "12/07 21:54:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 350/1135]  lr: 2.0000e-02  eta: 0:20:40  time: 0.1910  data_time: 0.0087  memory: 2022  grad_norm: 1.7611  loss: 0.4780  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0228  loss_cls: 0.2402  acc: 96.2402  loss_bbox: 0.1831\n",
      "12/07 21:54:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 400/1135]  lr: 2.0000e-02  eta: 0:20:31  time: 0.1913  data_time: 0.0088  memory: 2022  grad_norm: 1.7812  loss: 0.4885  loss_rpn_cls: 0.0379  loss_rpn_bbox: 0.0265  loss_cls: 0.2427  acc: 96.9727  loss_bbox: 0.1814\n",
      "12/07 21:54:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 450/1135]  lr: 2.0000e-02  eta: 0:20:21  time: 0.1921  data_time: 0.0082  memory: 2022  grad_norm: 1.7080  loss: 0.4497  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0208  loss_cls: 0.2273  acc: 96.0449  loss_bbox: 0.1699\n",
      "12/07 21:54:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 500/1135]  lr: 2.0000e-02  eta: 0:20:11  time: 0.1904  data_time: 0.0082  memory: 2021  grad_norm: 1.9007  loss: 0.5006  loss_rpn_cls: 0.0327  loss_rpn_bbox: 0.0230  loss_cls: 0.2494  acc: 98.5352  loss_bbox: 0.1955\n",
      "12/07 21:54:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 550/1135]  lr: 2.0000e-02  eta: 0:20:02  time: 0.1910  data_time: 0.0085  memory: 2021  grad_norm: 1.8844  loss: 0.4694  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0207  loss_cls: 0.2339  acc: 89.8926  loss_bbox: 0.1745\n",
      "12/07 21:54:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 600/1135]  lr: 2.0000e-02  eta: 0:19:52  time: 0.1907  data_time: 0.0082  memory: 2021  grad_norm: 1.6891  loss: 0.4518  loss_rpn_cls: 0.0364  loss_rpn_bbox: 0.0227  loss_cls: 0.2269  acc: 90.9668  loss_bbox: 0.1658\n",
      "12/07 21:55:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 650/1135]  lr: 2.0000e-02  eta: 0:19:42  time: 0.1911  data_time: 0.0085  memory: 2022  grad_norm: 1.6456  loss: 0.4565  loss_rpn_cls: 0.0291  loss_rpn_bbox: 0.0230  loss_cls: 0.2326  acc: 96.9238  loss_bbox: 0.1718\n",
      "12/07 21:55:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 700/1135]  lr: 2.0000e-02  eta: 0:19:33  time: 0.1908  data_time: 0.0087  memory: 2021  grad_norm: 1.7134  loss: 0.4558  loss_rpn_cls: 0.0258  loss_rpn_bbox: 0.0198  loss_cls: 0.2366  acc: 93.9453  loss_bbox: 0.1736\n",
      "12/07 21:55:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 750/1135]  lr: 2.0000e-02  eta: 0:19:23  time: 0.1910  data_time: 0.0085  memory: 2021  grad_norm: 1.8519  loss: 0.5173  loss_rpn_cls: 0.0348  loss_rpn_bbox: 0.0253  loss_cls: 0.2599  acc: 97.0703  loss_bbox: 0.1973\n",
      "12/07 21:55:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 800/1135]  lr: 2.0000e-02  eta: 0:19:13  time: 0.1913  data_time: 0.0088  memory: 2021  grad_norm: 1.8053  loss: 0.4527  loss_rpn_cls: 0.0294  loss_rpn_bbox: 0.0222  loss_cls: 0.2330  acc: 91.4551  loss_bbox: 0.1681\n",
      "12/07 21:55:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 850/1135]  lr: 2.0000e-02  eta: 0:19:04  time: 0.1898  data_time: 0.0084  memory: 2022  grad_norm: 1.8840  loss: 0.4881  loss_rpn_cls: 0.0384  loss_rpn_bbox: 0.0249  loss_cls: 0.2422  acc: 90.3809  loss_bbox: 0.1827\n",
      "12/07 21:55:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 900/1135]  lr: 2.0000e-02  eta: 0:18:54  time: 0.1930  data_time: 0.0089  memory: 2021  grad_norm: 1.6818  loss: 0.4350  loss_rpn_cls: 0.0329  loss_rpn_bbox: 0.0214  loss_cls: 0.2127  acc: 95.0195  loss_bbox: 0.1681\n",
      "12/07 21:55:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 950/1135]  lr: 2.0000e-02  eta: 0:18:45  time: 0.1913  data_time: 0.0087  memory: 2022  grad_norm: 1.7704  loss: 0.4414  loss_rpn_cls: 0.0305  loss_rpn_bbox: 0.0186  loss_cls: 0.2245  acc: 97.1680  loss_bbox: 0.1678\n",
      "12/07 21:56:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1000/1135]  lr: 2.0000e-02  eta: 0:18:35  time: 0.1909  data_time: 0.0084  memory: 2022  grad_norm: 1.6574  loss: 0.4112  loss_rpn_cls: 0.0270  loss_rpn_bbox: 0.0180  loss_cls: 0.2102  acc: 96.1914  loss_bbox: 0.1560\n",
      "12/07 21:56:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1050/1135]  lr: 2.0000e-02  eta: 0:18:25  time: 0.1913  data_time: 0.0084  memory: 2021  grad_norm: 1.8294  loss: 0.4848  loss_rpn_cls: 0.0374  loss_rpn_bbox: 0.0258  loss_cls: 0.2414  acc: 96.6797  loss_bbox: 0.1803\n",
      "12/07 21:56:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][1100/1135]  lr: 2.0000e-02  eta: 0:18:16  time: 0.1912  data_time: 0.0091  memory: 2022  grad_norm: 1.8246  loss: 0.5054  loss_rpn_cls: 0.0371  loss_rpn_bbox: 0.0302  loss_cls: 0.2416  acc: 92.7734  loss_bbox: 0.1964\n",
      "12/07 21:56:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:56:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 7 epochs\n",
      "12/07 21:56:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][  50/1135]  lr: 2.0000e-02  eta: 0:17:59  time: 0.1944  data_time: 0.0123  memory: 2022  grad_norm: 1.7460  loss: 0.4636  loss_rpn_cls: 0.0315  loss_rpn_bbox: 0.0285  loss_cls: 0.2294  acc: 92.4805  loss_bbox: 0.1742\n",
      "12/07 21:56:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 21:56:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 100/1135]  lr: 2.0000e-02  eta: 0:17:50  time: 0.1934  data_time: 0.0090  memory: 2022  grad_norm: 1.7036  loss: 0.4543  loss_rpn_cls: 0.0277  loss_rpn_bbox: 0.0229  loss_cls: 0.2237  acc: 94.3848  loss_bbox: 0.1801\n",
      "12/07 21:57:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 150/1135]  lr: 2.0000e-02  eta: 0:17:40  time: 0.1901  data_time: 0.0090  memory: 2021  grad_norm: 1.8297  loss: 0.4432  loss_rpn_cls: 0.0293  loss_rpn_bbox: 0.0241  loss_cls: 0.2197  acc: 93.7988  loss_bbox: 0.1701\n",
      "12/07 21:57:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 200/1135]  lr: 2.0000e-02  eta: 0:17:30  time: 0.1923  data_time: 0.0087  memory: 2021  grad_norm: 1.7848  loss: 0.4238  loss_rpn_cls: 0.0281  loss_rpn_bbox: 0.0197  loss_cls: 0.2175  acc: 94.0430  loss_bbox: 0.1585\n",
      "12/07 21:57:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 250/1135]  lr: 2.0000e-02  eta: 0:17:21  time: 0.1913  data_time: 0.0086  memory: 2021  grad_norm: 1.7103  loss: 0.4719  loss_rpn_cls: 0.0277  loss_rpn_bbox: 0.0276  loss_cls: 0.2371  acc: 90.9668  loss_bbox: 0.1795\n",
      "12/07 21:57:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 300/1135]  lr: 2.0000e-02  eta: 0:17:11  time: 0.1908  data_time: 0.0085  memory: 2022  grad_norm: 1.7780  loss: 0.4204  loss_rpn_cls: 0.0271  loss_rpn_bbox: 0.0179  loss_cls: 0.2156  acc: 97.1191  loss_bbox: 0.1598\n",
      "12/07 21:57:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 350/1135]  lr: 2.0000e-02  eta: 0:17:02  time: 0.1927  data_time: 0.0088  memory: 2022  grad_norm: 1.7620  loss: 0.4246  loss_rpn_cls: 0.0260  loss_rpn_bbox: 0.0184  loss_cls: 0.2181  acc: 93.3594  loss_bbox: 0.1621\n",
      "12/07 21:57:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 400/1135]  lr: 2.0000e-02  eta: 0:16:52  time: 0.1916  data_time: 0.0086  memory: 2022  grad_norm: 1.8725  loss: 0.4445  loss_rpn_cls: 0.0243  loss_rpn_bbox: 0.0216  loss_cls: 0.2274  acc: 96.0938  loss_bbox: 0.1713\n",
      "12/07 21:58:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 450/1135]  lr: 2.0000e-02  eta: 0:16:42  time: 0.1925  data_time: 0.0087  memory: 2022  grad_norm: 1.9106  loss: 0.5072  loss_rpn_cls: 0.0334  loss_rpn_bbox: 0.0271  loss_cls: 0.2487  acc: 93.7988  loss_bbox: 0.1980\n",
      "12/07 21:58:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 500/1135]  lr: 2.0000e-02  eta: 0:16:33  time: 0.1920  data_time: 0.0084  memory: 2022  grad_norm: 1.7891  loss: 0.4585  loss_rpn_cls: 0.0265  loss_rpn_bbox: 0.0195  loss_cls: 0.2313  acc: 93.9941  loss_bbox: 0.1812\n",
      "12/07 21:58:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 550/1135]  lr: 2.0000e-02  eta: 0:16:23  time: 0.1929  data_time: 0.0086  memory: 2022  grad_norm: 1.6982  loss: 0.4587  loss_rpn_cls: 0.0261  loss_rpn_bbox: 0.0199  loss_cls: 0.2330  acc: 95.5566  loss_bbox: 0.1796\n",
      "12/07 21:58:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 600/1135]  lr: 2.0000e-02  eta: 0:16:14  time: 0.1898  data_time: 0.0085  memory: 2021  grad_norm: 1.7929  loss: 0.4399  loss_rpn_cls: 0.0319  loss_rpn_bbox: 0.0207  loss_cls: 0.2196  acc: 95.4102  loss_bbox: 0.1677\n",
      "12/07 21:58:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 650/1135]  lr: 2.0000e-02  eta: 0:16:04  time: 0.1912  data_time: 0.0089  memory: 2022  grad_norm: 1.8324  loss: 0.4724  loss_rpn_cls: 0.0350  loss_rpn_bbox: 0.0277  loss_cls: 0.2315  acc: 96.5820  loss_bbox: 0.1782\n",
      "12/07 21:58:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 700/1135]  lr: 2.0000e-02  eta: 0:15:54  time: 0.1909  data_time: 0.0090  memory: 2022  grad_norm: 1.7999  loss: 0.4543  loss_rpn_cls: 0.0258  loss_rpn_bbox: 0.0200  loss_cls: 0.2303  acc: 94.0918  loss_bbox: 0.1782\n",
      "12/07 21:58:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 750/1135]  lr: 2.0000e-02  eta: 0:15:45  time: 0.1909  data_time: 0.0090  memory: 2021  grad_norm: 1.6655  loss: 0.4100  loss_rpn_cls: 0.0214  loss_rpn_bbox: 0.0220  loss_cls: 0.2027  acc: 94.8242  loss_bbox: 0.1639\n",
      "12/07 21:59:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 800/1135]  lr: 2.0000e-02  eta: 0:15:35  time: 0.1907  data_time: 0.0087  memory: 2022  grad_norm: 1.7666  loss: 0.4357  loss_rpn_cls: 0.0285  loss_rpn_bbox: 0.0200  loss_cls: 0.2180  acc: 95.4102  loss_bbox: 0.1691\n",
      "12/07 21:59:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 850/1135]  lr: 2.0000e-02  eta: 0:15:25  time: 0.1896  data_time: 0.0083  memory: 2022  grad_norm: 1.7794  loss: 0.4175  loss_rpn_cls: 0.0362  loss_rpn_bbox: 0.0204  loss_cls: 0.2089  acc: 93.6523  loss_bbox: 0.1520\n",
      "12/07 21:59:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 900/1135]  lr: 2.0000e-02  eta: 0:15:16  time: 0.1906  data_time: 0.0088  memory: 2021  grad_norm: 1.8187  loss: 0.4251  loss_rpn_cls: 0.0280  loss_rpn_bbox: 0.0231  loss_cls: 0.2113  acc: 87.2559  loss_bbox: 0.1627\n",
      "12/07 21:59:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 950/1135]  lr: 2.0000e-02  eta: 0:15:06  time: 0.1889  data_time: 0.0086  memory: 2022  grad_norm: 1.8067  loss: 0.4728  loss_rpn_cls: 0.0338  loss_rpn_bbox: 0.0261  loss_cls: 0.2297  acc: 89.7949  loss_bbox: 0.1832\n",
      "12/07 21:59:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1000/1135]  lr: 2.0000e-02  eta: 0:14:57  time: 0.1925  data_time: 0.0088  memory: 2022  grad_norm: 1.8760  loss: 0.4654  loss_rpn_cls: 0.0305  loss_rpn_bbox: 0.0224  loss_cls: 0.2358  acc: 92.1875  loss_bbox: 0.1767\n",
      "12/07 21:59:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1050/1135]  lr: 2.0000e-02  eta: 0:14:47  time: 0.1916  data_time: 0.0085  memory: 2022  grad_norm: 1.8409  loss: 0.4426  loss_rpn_cls: 0.0274  loss_rpn_bbox: 0.0197  loss_cls: 0.2247  acc: 92.6270  loss_bbox: 0.1708\n",
      "12/07 21:59:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 22:00:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][1100/1135]  lr: 2.0000e-02  eta: 0:14:37  time: 0.1923  data_time: 0.0089  memory: 2021  grad_norm: 1.8891  loss: 0.4817  loss_rpn_cls: 0.0357  loss_rpn_bbox: 0.0224  loss_cls: 0.2426  acc: 92.8711  loss_bbox: 0.1811\n",
      "12/07 22:00:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 22:00:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 8 epochs\n",
      "12/07 22:00:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][  50/1135]  lr: 2.0000e-03  eta: 0:14:21  time: 0.1975  data_time: 0.0129  memory: 2022  grad_norm: 1.5130  loss: 0.4033  loss_rpn_cls: 0.0231  loss_rpn_bbox: 0.0184  loss_cls: 0.1993  acc: 97.4121  loss_bbox: 0.1625\n",
      "12/07 22:00:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 100/1135]  lr: 2.0000e-03  eta: 0:14:12  time: 0.1939  data_time: 0.0086  memory: 2022  grad_norm: 1.5470  loss: 0.3953  loss_rpn_cls: 0.0182  loss_rpn_bbox: 0.0170  loss_cls: 0.2003  acc: 98.7793  loss_bbox: 0.1598\n",
      "12/07 22:00:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 150/1135]  lr: 2.0000e-03  eta: 0:14:02  time: 0.1928  data_time: 0.0085  memory: 2022  grad_norm: 1.6387  loss: 0.4274  loss_rpn_cls: 0.0244  loss_rpn_bbox: 0.0228  loss_cls: 0.2039  acc: 96.3379  loss_bbox: 0.1763\n",
      "12/07 22:00:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 200/1135]  lr: 2.0000e-03  eta: 0:13:52  time: 0.1936  data_time: 0.0084  memory: 2022  grad_norm: 1.6664  loss: 0.4336  loss_rpn_cls: 0.0200  loss_rpn_bbox: 0.0182  loss_cls: 0.2152  acc: 96.2891  loss_bbox: 0.1802\n",
      "12/07 22:01:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 250/1135]  lr: 2.0000e-03  eta: 0:13:43  time: 0.1925  data_time: 0.0087  memory: 2022  grad_norm: 1.5027  loss: 0.3392  loss_rpn_cls: 0.0153  loss_rpn_bbox: 0.0136  loss_cls: 0.1679  acc: 93.1641  loss_bbox: 0.1424\n",
      "12/07 22:01:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 300/1135]  lr: 2.0000e-03  eta: 0:13:33  time: 0.1942  data_time: 0.0090  memory: 2022  grad_norm: 1.5413  loss: 0.3461  loss_rpn_cls: 0.0133  loss_rpn_bbox: 0.0141  loss_cls: 0.1718  acc: 97.9492  loss_bbox: 0.1469\n",
      "12/07 22:01:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 350/1135]  lr: 2.0000e-03  eta: 0:13:24  time: 0.1901  data_time: 0.0086  memory: 2022  grad_norm: 1.7391  loss: 0.4282  loss_rpn_cls: 0.0238  loss_rpn_bbox: 0.0208  loss_cls: 0.2102  acc: 95.0684  loss_bbox: 0.1733\n",
      "12/07 22:01:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 400/1135]  lr: 2.0000e-03  eta: 0:13:14  time: 0.1907  data_time: 0.0085  memory: 2022  grad_norm: 1.5151  loss: 0.3714  loss_rpn_cls: 0.0187  loss_rpn_bbox: 0.0170  loss_cls: 0.1824  acc: 92.2852  loss_bbox: 0.1532\n",
      "12/07 22:01:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 450/1135]  lr: 2.0000e-03  eta: 0:13:04  time: 0.1932  data_time: 0.0085  memory: 2022  grad_norm: 1.6768  loss: 0.4252  loss_rpn_cls: 0.0235  loss_rpn_bbox: 0.0218  loss_cls: 0.2022  acc: 93.7988  loss_bbox: 0.1777\n",
      "12/07 22:01:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 500/1135]  lr: 2.0000e-03  eta: 0:12:55  time: 0.1918  data_time: 0.0083  memory: 2022  grad_norm: 1.6967  loss: 0.3936  loss_rpn_cls: 0.0194  loss_rpn_bbox: 0.0209  loss_cls: 0.1897  acc: 95.4102  loss_bbox: 0.1635\n",
      "12/07 22:01:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 550/1135]  lr: 2.0000e-03  eta: 0:12:45  time: 0.1926  data_time: 0.0087  memory: 2022  grad_norm: 1.5366  loss: 0.3740  loss_rpn_cls: 0.0157  loss_rpn_bbox: 0.0170  loss_cls: 0.1844  acc: 92.9688  loss_bbox: 0.1569\n",
      "12/07 22:02:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 600/1135]  lr: 2.0000e-03  eta: 0:12:36  time: 0.1919  data_time: 0.0086  memory: 2021  grad_norm: 1.6494  loss: 0.3471  loss_rpn_cls: 0.0160  loss_rpn_bbox: 0.0154  loss_cls: 0.1726  acc: 93.5547  loss_bbox: 0.1430\n",
      "12/07 22:02:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 650/1135]  lr: 2.0000e-03  eta: 0:12:26  time: 0.1920  data_time: 0.0085  memory: 2021  grad_norm: 1.7369  loss: 0.3828  loss_rpn_cls: 0.0189  loss_rpn_bbox: 0.0198  loss_cls: 0.1851  acc: 96.6797  loss_bbox: 0.1589\n",
      "12/07 22:02:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 700/1135]  lr: 2.0000e-03  eta: 0:12:17  time: 0.1914  data_time: 0.0084  memory: 2022  grad_norm: 1.7937  loss: 0.4389  loss_rpn_cls: 0.0214  loss_rpn_bbox: 0.0221  loss_cls: 0.2132  acc: 93.1641  loss_bbox: 0.1821\n",
      "12/07 22:02:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 750/1135]  lr: 2.0000e-03  eta: 0:12:07  time: 0.1918  data_time: 0.0088  memory: 2022  grad_norm: 1.5146  loss: 0.3254  loss_rpn_cls: 0.0148  loss_rpn_bbox: 0.0155  loss_cls: 0.1622  acc: 95.2148  loss_bbox: 0.1330\n",
      "12/07 22:02:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 800/1135]  lr: 2.0000e-03  eta: 0:11:57  time: 0.1935  data_time: 0.0085  memory: 2022  grad_norm: 1.6046  loss: 0.3578  loss_rpn_cls: 0.0196  loss_rpn_bbox: 0.0171  loss_cls: 0.1739  acc: 90.7715  loss_bbox: 0.1472\n",
      "12/07 22:02:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 850/1135]  lr: 2.0000e-03  eta: 0:11:48  time: 0.1928  data_time: 0.0084  memory: 2022  grad_norm: 1.6542  loss: 0.3767  loss_rpn_cls: 0.0185  loss_rpn_bbox: 0.0178  loss_cls: 0.1821  acc: 95.0684  loss_bbox: 0.1583\n",
      "12/07 22:03:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 900/1135]  lr: 2.0000e-03  eta: 0:11:38  time: 0.1930  data_time: 0.0089  memory: 2022  grad_norm: 1.6588  loss: 0.3811  loss_rpn_cls: 0.0169  loss_rpn_bbox: 0.0204  loss_cls: 0.1803  acc: 89.9902  loss_bbox: 0.1636\n",
      "12/07 22:03:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 22:03:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 950/1135]  lr: 2.0000e-03  eta: 0:11:29  time: 0.1914  data_time: 0.0088  memory: 2022  grad_norm: 1.6873  loss: 0.3881  loss_rpn_cls: 0.0186  loss_rpn_bbox: 0.0172  loss_cls: 0.1862  acc: 94.0918  loss_bbox: 0.1662\n",
      "12/07 22:03:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1000/1135]  lr: 2.0000e-03  eta: 0:11:19  time: 0.1922  data_time: 0.0086  memory: 2022  grad_norm: 1.4468  loss: 0.2861  loss_rpn_cls: 0.0115  loss_rpn_bbox: 0.0135  loss_cls: 0.1386  acc: 97.0215  loss_bbox: 0.1226\n",
      "12/07 22:03:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1050/1135]  lr: 2.0000e-03  eta: 0:11:09  time: 0.1921  data_time: 0.0084  memory: 2022  grad_norm: 1.7435  loss: 0.3844  loss_rpn_cls: 0.0179  loss_rpn_bbox: 0.0188  loss_cls: 0.1930  acc: 92.3340  loss_bbox: 0.1547\n",
      "12/07 22:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][1100/1135]  lr: 2.0000e-03  eta: 0:11:00  time: 0.1900  data_time: 0.0085  memory: 2021  grad_norm: 1.6337  loss: 0.3468  loss_rpn_cls: 0.0145  loss_rpn_bbox: 0.0149  loss_cls: 0.1709  acc: 97.3145  loss_bbox: 0.1464\n",
      "12/07 22:03:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 22:03:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
      "12/07 22:04:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][  50/1135]  lr: 2.0000e-03  eta: 0:10:43  time: 0.1950  data_time: 0.0117  memory: 2022  grad_norm: 1.6855  loss: 0.3692  loss_rpn_cls: 0.0160  loss_rpn_bbox: 0.0188  loss_cls: 0.1804  acc: 97.8516  loss_bbox: 0.1540\n",
      "12/07 22:04:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 100/1135]  lr: 2.0000e-03  eta: 0:10:34  time: 0.1920  data_time: 0.0087  memory: 2022  grad_norm: 1.7242  loss: 0.3922  loss_rpn_cls: 0.0168  loss_rpn_bbox: 0.0197  loss_cls: 0.1869  acc: 96.4844  loss_bbox: 0.1688\n",
      "12/07 22:04:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 150/1135]  lr: 2.0000e-03  eta: 0:10:24  time: 0.1915  data_time: 0.0087  memory: 2022  grad_norm: 1.6110  loss: 0.3575  loss_rpn_cls: 0.0170  loss_rpn_bbox: 0.0180  loss_cls: 0.1700  acc: 93.4570  loss_bbox: 0.1525\n",
      "12/07 22:04:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 200/1135]  lr: 2.0000e-03  eta: 0:10:15  time: 0.1910  data_time: 0.0090  memory: 2021  grad_norm: 1.6131  loss: 0.3478  loss_rpn_cls: 0.0150  loss_rpn_bbox: 0.0162  loss_cls: 0.1710  acc: 94.2871  loss_bbox: 0.1457\n",
      "12/07 22:04:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 250/1135]  lr: 2.0000e-03  eta: 0:10:05  time: 0.1915  data_time: 0.0087  memory: 2022  grad_norm: 1.6402  loss: 0.3698  loss_rpn_cls: 0.0170  loss_rpn_bbox: 0.0182  loss_cls: 0.1742  acc: 92.8711  loss_bbox: 0.1604\n",
      "12/07 22:04:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 300/1135]  lr: 2.0000e-03  eta: 0:09:55  time: 0.1919  data_time: 0.0086  memory: 2022  grad_norm: 1.6432  loss: 0.3405  loss_rpn_cls: 0.0140  loss_rpn_bbox: 0.0164  loss_cls: 0.1577  acc: 97.8027  loss_bbox: 0.1523\n",
      "12/07 22:05:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 350/1135]  lr: 2.0000e-03  eta: 0:09:46  time: 0.1939  data_time: 0.0086  memory: 2022  grad_norm: 1.8253  loss: 0.4046  loss_rpn_cls: 0.0173  loss_rpn_bbox: 0.0186  loss_cls: 0.1964  acc: 95.8008  loss_bbox: 0.1722\n",
      "12/07 22:05:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 400/1135]  lr: 2.0000e-03  eta: 0:09:36  time: 0.1911  data_time: 0.0088  memory: 2022  grad_norm: 1.6644  loss: 0.3503  loss_rpn_cls: 0.0149  loss_rpn_bbox: 0.0175  loss_cls: 0.1708  acc: 92.6758  loss_bbox: 0.1472\n",
      "12/07 22:05:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 450/1135]  lr: 2.0000e-03  eta: 0:09:27  time: 0.1932  data_time: 0.0086  memory: 2022  grad_norm: 1.6215  loss: 0.3469  loss_rpn_cls: 0.0158  loss_rpn_bbox: 0.0165  loss_cls: 0.1709  acc: 95.6543  loss_bbox: 0.1436\n",
      "12/07 22:05:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 500/1135]  lr: 2.0000e-03  eta: 0:09:17  time: 0.1917  data_time: 0.0088  memory: 2022  grad_norm: 1.8011  loss: 0.3589  loss_rpn_cls: 0.0144  loss_rpn_bbox: 0.0161  loss_cls: 0.1701  acc: 93.0176  loss_bbox: 0.1582\n",
      "12/07 22:05:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 550/1135]  lr: 2.0000e-03  eta: 0:09:07  time: 0.1931  data_time: 0.0088  memory: 2022  grad_norm: 1.6593  loss: 0.3510  loss_rpn_cls: 0.0161  loss_rpn_bbox: 0.0188  loss_cls: 0.1640  acc: 95.1172  loss_bbox: 0.1521\n",
      "12/07 22:05:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 600/1135]  lr: 2.0000e-03  eta: 0:08:58  time: 0.1918  data_time: 0.0085  memory: 2022  grad_norm: 1.7386  loss: 0.3680  loss_rpn_cls: 0.0164  loss_rpn_bbox: 0.0170  loss_cls: 0.1784  acc: 91.1621  loss_bbox: 0.1561\n",
      "12/07 22:05:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 650/1135]  lr: 2.0000e-03  eta: 0:08:48  time: 0.1908  data_time: 0.0087  memory: 2022  grad_norm: 1.8077  loss: 0.3702  loss_rpn_cls: 0.0153  loss_rpn_bbox: 0.0161  loss_cls: 0.1857  acc: 85.1074  loss_bbox: 0.1532\n",
      "12/07 22:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 700/1135]  lr: 2.0000e-03  eta: 0:08:39  time: 0.1927  data_time: 0.0083  memory: 2022  grad_norm: 1.6665  loss: 0.3142  loss_rpn_cls: 0.0133  loss_rpn_bbox: 0.0129  loss_cls: 0.1553  acc: 96.2891  loss_bbox: 0.1326\n",
      "12/07 22:06:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 750/1135]  lr: 2.0000e-03  eta: 0:08:29  time: 0.1934  data_time: 0.0091  memory: 2022  grad_norm: 1.7053  loss: 0.3497  loss_rpn_cls: 0.0162  loss_rpn_bbox: 0.0183  loss_cls: 0.1709  acc: 92.4316  loss_bbox: 0.1443\n",
      "12/07 22:06:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 22:06:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 800/1135]  lr: 2.0000e-03  eta: 0:08:20  time: 0.1945  data_time: 0.0089  memory: 2022  grad_norm: 1.6741  loss: 0.3455  loss_rpn_cls: 0.0151  loss_rpn_bbox: 0.0180  loss_cls: 0.1633  acc: 97.4121  loss_bbox: 0.1491\n",
      "12/07 22:06:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 850/1135]  lr: 2.0000e-03  eta: 0:08:10  time: 0.1921  data_time: 0.0089  memory: 2022  grad_norm: 1.7404  loss: 0.3254  loss_rpn_cls: 0.0126  loss_rpn_bbox: 0.0176  loss_cls: 0.1544  acc: 94.4336  loss_bbox: 0.1408\n",
      "12/07 22:06:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 900/1135]  lr: 2.0000e-03  eta: 0:08:00  time: 0.1936  data_time: 0.0090  memory: 2022  grad_norm: 1.7353  loss: 0.3449  loss_rpn_cls: 0.0137  loss_rpn_bbox: 0.0144  loss_cls: 0.1691  acc: 90.7715  loss_bbox: 0.1478\n",
      "12/07 22:06:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 950/1135]  lr: 2.0000e-03  eta: 0:07:51  time: 0.1922  data_time: 0.0092  memory: 2022  grad_norm: 1.7378  loss: 0.3235  loss_rpn_cls: 0.0141  loss_rpn_bbox: 0.0146  loss_cls: 0.1585  acc: 95.9473  loss_bbox: 0.1362\n",
      "12/07 22:07:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1000/1135]  lr: 2.0000e-03  eta: 0:07:41  time: 0.1925  data_time: 0.0087  memory: 2022  grad_norm: 1.7280  loss: 0.3383  loss_rpn_cls: 0.0156  loss_rpn_bbox: 0.0155  loss_cls: 0.1659  acc: 90.8691  loss_bbox: 0.1413\n",
      "12/07 22:07:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1050/1135]  lr: 2.0000e-03  eta: 0:07:32  time: 0.1905  data_time: 0.0085  memory: 2022  grad_norm: 1.7586  loss: 0.3190  loss_rpn_cls: 0.0151  loss_rpn_bbox: 0.0159  loss_cls: 0.1562  acc: 96.1426  loss_bbox: 0.1318\n",
      "12/07 22:07:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][1100/1135]  lr: 2.0000e-03  eta: 0:07:22  time: 0.1923  data_time: 0.0084  memory: 2022  grad_norm: 1.8107  loss: 0.3827  loss_rpn_cls: 0.0172  loss_rpn_bbox: 0.0183  loss_cls: 0.1834  acc: 96.5332  loss_bbox: 0.1639\n",
      "12/07 22:07:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 22:07:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\n",
      "12/07 22:07:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][  50/1135]  lr: 2.0000e-03  eta: 0:07:06  time: 0.1976  data_time: 0.0127  memory: 2022  grad_norm: 1.7089  loss: 0.3601  loss_rpn_cls: 0.0152  loss_rpn_bbox: 0.0180  loss_cls: 0.1698  acc: 96.1914  loss_bbox: 0.1571\n",
      "12/07 22:07:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 100/1135]  lr: 2.0000e-03  eta: 0:06:56  time: 0.1910  data_time: 0.0086  memory: 2021  grad_norm: 1.7243  loss: 0.3476  loss_rpn_cls: 0.0149  loss_rpn_bbox: 0.0172  loss_cls: 0.1688  acc: 94.4824  loss_bbox: 0.1467\n",
      "12/07 22:08:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 150/1135]  lr: 2.0000e-03  eta: 0:06:46  time: 0.1912  data_time: 0.0083  memory: 2021  grad_norm: 1.7407  loss: 0.3569  loss_rpn_cls: 0.0124  loss_rpn_bbox: 0.0173  loss_cls: 0.1671  acc: 97.9492  loss_bbox: 0.1601\n",
      "12/07 22:08:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 200/1135]  lr: 2.0000e-03  eta: 0:06:37  time: 0.1939  data_time: 0.0085  memory: 2022  grad_norm: 1.7970  loss: 0.3593  loss_rpn_cls: 0.0153  loss_rpn_bbox: 0.0169  loss_cls: 0.1736  acc: 91.3574  loss_bbox: 0.1535\n",
      "12/07 22:08:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 250/1135]  lr: 2.0000e-03  eta: 0:06:27  time: 0.1934  data_time: 0.0087  memory: 2022  grad_norm: 1.6628  loss: 0.3122  loss_rpn_cls: 0.0124  loss_rpn_bbox: 0.0148  loss_cls: 0.1509  acc: 96.5820  loss_bbox: 0.1341\n",
      "12/07 22:08:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 300/1135]  lr: 2.0000e-03  eta: 0:06:18  time: 0.1947  data_time: 0.0088  memory: 2022  grad_norm: 1.7095  loss: 0.3307  loss_rpn_cls: 0.0141  loss_rpn_bbox: 0.0164  loss_cls: 0.1600  acc: 94.5801  loss_bbox: 0.1401\n",
      "12/07 22:08:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 350/1135]  lr: 2.0000e-03  eta: 0:06:08  time: 0.1912  data_time: 0.0085  memory: 2022  grad_norm: 1.6613  loss: 0.2904  loss_rpn_cls: 0.0115  loss_rpn_bbox: 0.0126  loss_cls: 0.1442  acc: 88.8184  loss_bbox: 0.1220\n",
      "12/07 22:08:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 400/1135]  lr: 2.0000e-03  eta: 0:05:59  time: 0.1914  data_time: 0.0087  memory: 2022  grad_norm: 1.8122  loss: 0.3528  loss_rpn_cls: 0.0140  loss_rpn_bbox: 0.0159  loss_cls: 0.1712  acc: 95.8008  loss_bbox: 0.1517\n",
      "12/07 22:08:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 450/1135]  lr: 2.0000e-03  eta: 0:05:49  time: 0.1919  data_time: 0.0087  memory: 2022  grad_norm: 1.8841  loss: 0.3456  loss_rpn_cls: 0.0160  loss_rpn_bbox: 0.0163  loss_cls: 0.1717  acc: 97.1191  loss_bbox: 0.1416\n",
      "12/07 22:09:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 500/1135]  lr: 2.0000e-03  eta: 0:05:39  time: 0.1925  data_time: 0.0087  memory: 2022  grad_norm: 1.7918  loss: 0.3535  loss_rpn_cls: 0.0159  loss_rpn_bbox: 0.0198  loss_cls: 0.1673  acc: 94.9707  loss_bbox: 0.1505\n",
      "12/07 22:09:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 550/1135]  lr: 2.0000e-03  eta: 0:05:30  time: 0.1928  data_time: 0.0088  memory: 2022  grad_norm: 1.7386  loss: 0.3519  loss_rpn_cls: 0.0131  loss_rpn_bbox: 0.0171  loss_cls: 0.1627  acc: 94.3359  loss_bbox: 0.1591\n",
      "12/07 22:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 600/1135]  lr: 2.0000e-03  eta: 0:05:20  time: 0.1905  data_time: 0.0088  memory: 2022  grad_norm: 1.7776  loss: 0.3169  loss_rpn_cls: 0.0118  loss_rpn_bbox: 0.0160  loss_cls: 0.1518  acc: 94.8730  loss_bbox: 0.1374\n",
      "12/07 22:09:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 22:09:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 650/1135]  lr: 2.0000e-03  eta: 0:05:11  time: 0.1922  data_time: 0.0088  memory: 2022  grad_norm: 1.8476  loss: 0.3695  loss_rpn_cls: 0.0162  loss_rpn_bbox: 0.0173  loss_cls: 0.1726  acc: 96.6797  loss_bbox: 0.1634\n",
      "12/07 22:09:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 700/1135]  lr: 2.0000e-03  eta: 0:05:01  time: 0.1932  data_time: 0.0088  memory: 2021  grad_norm: 1.7332  loss: 0.3244  loss_rpn_cls: 0.0129  loss_rpn_bbox: 0.0154  loss_cls: 0.1547  acc: 95.5078  loss_bbox: 0.1414\n",
      "12/07 22:09:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 750/1135]  lr: 2.0000e-03  eta: 0:04:51  time: 0.1951  data_time: 0.0086  memory: 2022  grad_norm: 1.7857  loss: 0.3512  loss_rpn_cls: 0.0141  loss_rpn_bbox: 0.0172  loss_cls: 0.1648  acc: 95.8984  loss_bbox: 0.1552\n",
      "12/07 22:10:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 800/1135]  lr: 2.0000e-03  eta: 0:04:42  time: 0.1905  data_time: 0.0083  memory: 2021  grad_norm: 1.8635  loss: 0.3541  loss_rpn_cls: 0.0115  loss_rpn_bbox: 0.0157  loss_cls: 0.1716  acc: 92.0898  loss_bbox: 0.1553\n",
      "12/07 22:10:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 850/1135]  lr: 2.0000e-03  eta: 0:04:32  time: 0.1921  data_time: 0.0086  memory: 2022  grad_norm: 1.8367  loss: 0.3330  loss_rpn_cls: 0.0126  loss_rpn_bbox: 0.0175  loss_cls: 0.1582  acc: 97.7539  loss_bbox: 0.1446\n",
      "12/07 22:10:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 900/1135]  lr: 2.0000e-03  eta: 0:04:23  time: 0.1939  data_time: 0.0083  memory: 2022  grad_norm: 1.7655  loss: 0.3333  loss_rpn_cls: 0.0137  loss_rpn_bbox: 0.0163  loss_cls: 0.1617  acc: 94.0918  loss_bbox: 0.1416\n",
      "12/07 22:10:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 950/1135]  lr: 2.0000e-03  eta: 0:04:13  time: 0.1915  data_time: 0.0086  memory: 2021  grad_norm: 1.8617  loss: 0.3403  loss_rpn_cls: 0.0131  loss_rpn_bbox: 0.0172  loss_cls: 0.1651  acc: 93.1641  loss_bbox: 0.1449\n",
      "12/07 22:10:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1000/1135]  lr: 2.0000e-03  eta: 0:04:03  time: 0.1914  data_time: 0.0088  memory: 2021  grad_norm: 1.8943  loss: 0.3400  loss_rpn_cls: 0.0160  loss_rpn_bbox: 0.0183  loss_cls: 0.1611  acc: 92.3828  loss_bbox: 0.1446\n",
      "12/07 22:10:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1050/1135]  lr: 2.0000e-03  eta: 0:03:54  time: 0.1907  data_time: 0.0084  memory: 2022  grad_norm: 1.8345  loss: 0.3533  loss_rpn_cls: 0.0162  loss_rpn_bbox: 0.0158  loss_cls: 0.1643  acc: 95.1172  loss_bbox: 0.1570\n",
      "12/07 22:11:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][1100/1135]  lr: 2.0000e-03  eta: 0:03:44  time: 0.1920  data_time: 0.0085  memory: 2022  grad_norm: 1.7746  loss: 0.3236  loss_rpn_cls: 0.0147  loss_rpn_bbox: 0.0160  loss_cls: 0.1566  acc: 96.1426  loss_bbox: 0.1363\n",
      "12/07 22:11:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 22:11:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 11 epochs\n",
      "12/07 22:11:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][  50/1135]  lr: 2.0000e-04  eta: 0:03:28  time: 0.1943  data_time: 0.0121  memory: 2022  grad_norm: 1.7021  loss: 0.3243  loss_rpn_cls: 0.0130  loss_rpn_bbox: 0.0170  loss_cls: 0.1513  acc: 94.7266  loss_bbox: 0.1430\n",
      "12/07 22:11:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 100/1135]  lr: 2.0000e-04  eta: 0:03:18  time: 0.1925  data_time: 0.0090  memory: 2022  grad_norm: 1.7110  loss: 0.3309  loss_rpn_cls: 0.0114  loss_rpn_bbox: 0.0174  loss_cls: 0.1529  acc: 93.2617  loss_bbox: 0.1493\n",
      "12/07 22:11:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 150/1135]  lr: 2.0000e-04  eta: 0:03:09  time: 0.1919  data_time: 0.0082  memory: 2022  grad_norm: 1.6174  loss: 0.2842  loss_rpn_cls: 0.0083  loss_rpn_bbox: 0.0133  loss_cls: 0.1368  acc: 96.0449  loss_bbox: 0.1257\n",
      "12/07 22:11:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 200/1135]  lr: 2.0000e-04  eta: 0:02:59  time: 0.1912  data_time: 0.0089  memory: 2022  grad_norm: 1.6932  loss: 0.3087  loss_rpn_cls: 0.0141  loss_rpn_bbox: 0.0153  loss_cls: 0.1454  acc: 95.5566  loss_bbox: 0.1340\n",
      "12/07 22:12:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 250/1135]  lr: 2.0000e-04  eta: 0:02:49  time: 0.1903  data_time: 0.0088  memory: 2022  grad_norm: 1.5777  loss: 0.2695  loss_rpn_cls: 0.0097  loss_rpn_bbox: 0.0127  loss_cls: 0.1295  acc: 96.1914  loss_bbox: 0.1176\n",
      "12/07 22:12:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 300/1135]  lr: 2.0000e-04  eta: 0:02:40  time: 0.1911  data_time: 0.0085  memory: 2022  grad_norm: 1.6001  loss: 0.2847  loss_rpn_cls: 0.0092  loss_rpn_bbox: 0.0141  loss_cls: 0.1384  acc: 96.2891  loss_bbox: 0.1230\n",
      "12/07 22:12:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 350/1135]  lr: 2.0000e-04  eta: 0:02:30  time: 0.1912  data_time: 0.0085  memory: 2021  grad_norm: 1.7184  loss: 0.3338  loss_rpn_cls: 0.0134  loss_rpn_bbox: 0.0165  loss_cls: 0.1542  acc: 97.0703  loss_bbox: 0.1496\n",
      "12/07 22:12:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 400/1135]  lr: 2.0000e-04  eta: 0:02:21  time: 0.1925  data_time: 0.0083  memory: 2021  grad_norm: 1.7223  loss: 0.3128  loss_rpn_cls: 0.0105  loss_rpn_bbox: 0.0142  loss_cls: 0.1530  acc: 94.2383  loss_bbox: 0.1352\n",
      "12/07 22:12:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 450/1135]  lr: 2.0000e-04  eta: 0:02:11  time: 0.1900  data_time: 0.0087  memory: 2022  grad_norm: 1.7989  loss: 0.3228  loss_rpn_cls: 0.0139  loss_rpn_bbox: 0.0152  loss_cls: 0.1561  acc: 96.4355  loss_bbox: 0.1376\n",
      "12/07 22:12:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 500/1135]  lr: 2.0000e-04  eta: 0:02:01  time: 0.1912  data_time: 0.0086  memory: 2022  grad_norm: 1.7684  loss: 0.3362  loss_rpn_cls: 0.0135  loss_rpn_bbox: 0.0185  loss_cls: 0.1521  acc: 93.5547  loss_bbox: 0.1521\n",
      "12/07 22:12:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 22:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 550/1135]  lr: 2.0000e-04  eta: 0:01:52  time: 0.1944  data_time: 0.0087  memory: 2022  grad_norm: 1.7133  loss: 0.3335  loss_rpn_cls: 0.0123  loss_rpn_bbox: 0.0194  loss_cls: 0.1532  acc: 89.5508  loss_bbox: 0.1486\n",
      "12/07 22:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 600/1135]  lr: 2.0000e-04  eta: 0:01:42  time: 0.1914  data_time: 0.0082  memory: 2022  grad_norm: 1.8162  loss: 0.3386  loss_rpn_cls: 0.0118  loss_rpn_bbox: 0.0173  loss_cls: 0.1605  acc: 98.8770  loss_bbox: 0.1491\n",
      "12/07 22:13:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 650/1135]  lr: 2.0000e-04  eta: 0:01:33  time: 0.1919  data_time: 0.0086  memory: 2022  grad_norm: 1.6449  loss: 0.3080  loss_rpn_cls: 0.0113  loss_rpn_bbox: 0.0152  loss_cls: 0.1437  acc: 97.0703  loss_bbox: 0.1379\n",
      "12/07 22:13:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 700/1135]  lr: 2.0000e-04  eta: 0:01:23  time: 0.1934  data_time: 0.0087  memory: 2022  grad_norm: 1.6956  loss: 0.3205  loss_rpn_cls: 0.0136  loss_rpn_bbox: 0.0169  loss_cls: 0.1415  acc: 98.3887  loss_bbox: 0.1485\n",
      "12/07 22:13:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 750/1135]  lr: 2.0000e-04  eta: 0:01:13  time: 0.1926  data_time: 0.0086  memory: 2021  grad_norm: 1.8063  loss: 0.3258  loss_rpn_cls: 0.0134  loss_rpn_bbox: 0.0157  loss_cls: 0.1531  acc: 94.7266  loss_bbox: 0.1436\n",
      "12/07 22:13:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 800/1135]  lr: 2.0000e-04  eta: 0:01:04  time: 0.1901  data_time: 0.0085  memory: 2021  grad_norm: 1.7335  loss: 0.3193  loss_rpn_cls: 0.0108  loss_rpn_bbox: 0.0145  loss_cls: 0.1494  acc: 96.3379  loss_bbox: 0.1446\n",
      "12/07 22:13:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 850/1135]  lr: 2.0000e-04  eta: 0:00:54  time: 0.1941  data_time: 0.0084  memory: 2022  grad_norm: 1.7761  loss: 0.3476  loss_rpn_cls: 0.0133  loss_rpn_bbox: 0.0170  loss_cls: 0.1635  acc: 93.4082  loss_bbox: 0.1538\n",
      "12/07 22:14:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 900/1135]  lr: 2.0000e-04  eta: 0:00:45  time: 0.1904  data_time: 0.0089  memory: 2022  grad_norm: 1.8497  loss: 0.3564  loss_rpn_cls: 0.0152  loss_rpn_bbox: 0.0169  loss_cls: 0.1702  acc: 92.6270  loss_bbox: 0.1541\n",
      "12/07 22:14:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 950/1135]  lr: 2.0000e-04  eta: 0:00:35  time: 0.1924  data_time: 0.0085  memory: 2021  grad_norm: 1.7782  loss: 0.3307  loss_rpn_cls: 0.0126  loss_rpn_bbox: 0.0179  loss_cls: 0.1586  acc: 94.8730  loss_bbox: 0.1417\n",
      "12/07 22:14:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1000/1135]  lr: 2.0000e-04  eta: 0:00:25  time: 0.1903  data_time: 0.0083  memory: 2022  grad_norm: 1.7681  loss: 0.3446  loss_rpn_cls: 0.0137  loss_rpn_bbox: 0.0171  loss_cls: 0.1592  acc: 93.8477  loss_bbox: 0.1546\n",
      "12/07 22:14:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1050/1135]  lr: 2.0000e-04  eta: 0:00:16  time: 0.1918  data_time: 0.0086  memory: 2022  grad_norm: 1.7117  loss: 0.3170  loss_rpn_cls: 0.0144  loss_rpn_bbox: 0.0146  loss_cls: 0.1446  acc: 92.4805  loss_bbox: 0.1434\n",
      "12/07 22:14:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][1100/1135]  lr: 2.0000e-04  eta: 0:00:06  time: 0.1923  data_time: 0.0086  memory: 2021  grad_norm: 1.6393  loss: 0.2975  loss_rpn_cls: 0.0115  loss_rpn_bbox: 0.0147  loss_cls: 0.1396  acc: 95.5566  loss_bbox: 0.1316\n",
      "12/07 22:14:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_1x_coco_20251207_213034\n",
      "12/07 22:14:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▅▁▇▆▅▄▆▅▇▅▂▅▆▅▄▄▆▇▄▆▇▇▇▆▅▇▇▆▅▄█▇▇▆▇█▆▇▇▆</td></tr><tr><td>data_time</td><td>▂▁▁▂▂▂▂▂▁▂▂▂▂█▂▂▂▂▂▂▂▂▂█▂▂▂▂▁▂▂▃▃▂▂▂▂▁▂▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇██</td></tr><tr><td>grad_norm</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>iter</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>loss</td><td>█▄▅▅▅▄▄▄▃▄▄▃▄▃▃▃▃▃▃▃▃▂▂▂▃▂▂▃▂▂▂▂▁▂▂▁▂▂▂▂</td></tr><tr><td>loss_bbox</td><td>▁▇▇██▇▆▆▇▅▅▅▄▆▄▅▅▆▅▄▅▅▄▅▅▃▄▅▄▃▃▄▄▄▅▄▄▄▃▄</td></tr><tr><td>loss_cls</td><td>█▇▇▆▇█▅▇▇▆▆▅▅▅▅▆▆▅▅▅▄▅▅▄▅▄▅▄▄▅▄▃▄▃▂▂▁▂▂▁</td></tr><tr><td>loss_rpn_bbox</td><td>▅█▇█▇▅▆▄▅▄▄▅▃▄▅▄▆▃▃▄▄▄▃▂▂▂▂▂▁▁▂▁▂▂▂▂▂▂▃▂</td></tr><tr><td>loss_rpn_cls</td><td>█▇▅▆▆▄▆▆▄▄▄▅▅▄▄▅▄▄▅▃▄▄▃▃▄▂▂▂▂▂▂▁▁▂▁▂▁▁▁▂</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>95.55664</td></tr><tr><td>data_time</td><td>0.00865</td></tr><tr><td>epoch</td><td>12</td></tr><tr><td>grad_norm</td><td>1.63928</td></tr><tr><td>iter</td><td>13585</td></tr><tr><td>loss</td><td>0.29749</td></tr><tr><td>loss_bbox</td><td>0.13165</td></tr><tr><td>loss_cls</td><td>0.13963</td></tr><tr><td>loss_rpn_bbox</td><td>0.01475</td></tr><tr><td>loss_rpn_cls</td><td>0.01146</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faster_rcnn_test</strong> at: <a href='https://wandb.ai/cv_11/cv_11_OD/runs/n4mecrsl' target=\"_blank\">https://wandb.ai/cv_11/cv_11_OD/runs/n4mecrsl</a><br> View project at: <a href='https://wandb.ai/cv_11/cv_11_OD' target=\"_blank\">https://wandb.ai/cv_11/cv_11_OD</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./work_dirs/faster_rcnn_r50_fpn_1x_trash/20251207_213034/vis_data/wandb/run-20251207_213045-n4mecrsl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (data_preprocessor): DetDataPreprocessor()\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): ResLayer(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
       "  (neck): FPN(\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0-3): 4 x ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
       "  (rpn_head): RPNHead(\n",
       "    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (loss_bbox): L1Loss()\n",
       "    (rpn_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (rpn_cls): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (rpn_reg): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
       "  (roi_head): StandardRoIHead(\n",
       "    (bbox_roi_extractor): SingleRoIExtractor(\n",
       "      (roi_layers): ModuleList(\n",
       "        (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "        (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "        (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "        (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
       "      )\n",
       "    )\n",
       "    (bbox_head): Shared2FCBBoxHead(\n",
       "      (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
       "      (loss_bbox): L1Loss()\n",
       "      (fc_cls): Linear(in_features=1024, out_features=11, bias=True)\n",
       "      (fc_reg): Linear(in_features=1024, out_features=40, bias=True)\n",
       "      (shared_convs): ModuleList()\n",
       "      (shared_fcs): ModuleList(\n",
       "        (0): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "        (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (cls_convs): ModuleList()\n",
       "      (cls_fcs): ModuleList()\n",
       "      (reg_convs): ModuleList()\n",
       "      (reg_fcs): ModuleList()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "runner = Runner.from_cfg(cfg)\n",
    "runner.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
